:github_url: https://github.com/pytorch/pytorch


.. _program_listing_file_torch_csrc_api_include_torch_nn_options_conv.h:

Program Listing for File conv.h
===============================

|exhale_lsh| :ref:`Return to documentation for file <file_torch_csrc_api_include_torch_nn_options_conv.h>` (``torch/csrc/api/include/torch/nn/options/conv.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   #pragma once
   
   #include <torch/arg.h>
   #include <torch/enum.h>
   #include <torch/csrc/WindowsTorchApiMacro.h>
   #include <torch/expanding_array.h>
   #include <torch/types.h>
   
   namespace torch {
   namespace nn {
   
   template <size_t D>
   struct ConvOptions {
     typedef c10::variant<enumtype::kZeros, enumtype::kCircular> padding_mode_t;
   
     ConvOptions(
         int64_t in_channels,
         int64_t out_channels,
         ExpandingArray<D> kernel_size) :
                   in_channels_(in_channels),
                   out_channels_(out_channels),
                   kernel_size_(std::move(kernel_size)) {}
   
     TORCH_ARG(int64_t, in_channels);
   
     TORCH_ARG(int64_t, out_channels);
   
     TORCH_ARG(ExpandingArray<D>, kernel_size);
   
     TORCH_ARG(ExpandingArray<D>, stride) = 1;
   
     TORCH_ARG(ExpandingArray<D>, padding) = 0;
   
     TORCH_ARG(ExpandingArray<D>, dilation) = 1;
   
     TORCH_ARG(bool, transposed) = false;
   
     TORCH_ARG(ExpandingArray<D>, output_padding) = 0;
   
     TORCH_ARG(int64_t, groups) = 1;
   
     TORCH_ARG(bool, bias) = true;
   
     TORCH_ARG(padding_mode_t, padding_mode) = torch::kZeros;
   
     // FIXME: The following methods are added so that we can merge PR #28917
     // without breaking torchvision builds in CI. After PR #28917 is merged
     // and a new PyTorch nightly is built, @yf225 will open a PR to torchvision
     // to change the following:
     //
     // 1. `with_bias` -> `bias`
     // 2. `input_channels` -> `in_channels`
     // 3. `output_channels` -> `out_channels`
     //
     // and then he will open a PR to PyTorch to remove the methods below.
    public:
     inline auto input_channels(const int64_t& new_input_channels)->decltype(*this) {
       this->in_channels_ = new_input_channels;
       return *this;
     }
   
     inline auto input_channels(int64_t&& new_input_channels)->decltype(*this) {
       this->in_channels_ = std::move(new_input_channels);
       return *this;
     }
   
     inline const int64_t& input_channels() const noexcept {
       return this->in_channels_;
     }
   
     inline auto output_channels(const int64_t& new_output_channels)->decltype(*this) {
       this->out_channels_ = new_output_channels;
       return *this;
     }
   
     inline auto output_channels(int64_t&& new_output_channels)->decltype(*this) {
       this->out_channels_ = std::move(new_output_channels);
       return *this;
     }
   
     inline const int64_t& output_channels() const noexcept {
       return this->out_channels_;
     }
   
     inline auto with_bias(const bool& new_with_bias)->decltype(*this) {
       this->bias_ = new_with_bias;
       return *this;
     }
   
     inline auto with_bias(bool&& new_with_bias)->decltype(*this) {
       this->bias_ = std::move(new_with_bias);
       return *this;
     }
   
     inline const bool& with_bias() const noexcept {
       return this->bias_;
     }
   };
   
   using Conv1dOptions = ConvOptions<1>;
   
   using Conv2dOptions = ConvOptions<2>;
   
   using Conv3dOptions = ConvOptions<3>;
   
   // ============================================================================
   
   namespace functional {
   
   template <size_t D>
   struct ConvFuncOptions {
     TORCH_ARG(torch::Tensor, bias) = Tensor();
   
     TORCH_ARG(ExpandingArray<D>, stride) = 1;
   
     TORCH_ARG(ExpandingArray<D>, padding) = 0;
   
     TORCH_ARG(ExpandingArray<D>, dilation) = 1;
   
     TORCH_ARG(int64_t, groups) = 1;
   };
   
   using Conv1dFuncOptions = ConvFuncOptions<1>;
   
   using Conv2dFuncOptions = ConvFuncOptions<2>;
   
   using Conv3dFuncOptions = ConvFuncOptions<3>;
   
   } // namespace functional
   
   } // namespace nn
   } // namespace torch
