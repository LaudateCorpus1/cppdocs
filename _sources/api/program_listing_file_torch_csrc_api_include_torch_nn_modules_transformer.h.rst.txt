:github_url: https://github.com/pytorch/pytorch


.. _program_listing_file_torch_csrc_api_include_torch_nn_modules_transformer.h:

Program Listing for File transformer.h
======================================

|exhale_lsh| :ref:`Return to documentation for file <file_torch_csrc_api_include_torch_nn_modules_transformer.h>` (``torch/csrc/api/include/torch/nn/modules/transformer.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   #pragma once
   
   #include <torch/nn/cloneable.h>
   #include <torch/nn/module.h>
   #include <torch/nn/options/transformer.h>
   #include <torch/nn/pimpl.h>
   #include <torch/nn/modules/linear.h>
   #include <torch/nn/modules/dropout.h>
   #include <torch/nn/modules/normalization.h>
   #include <torch/nn/modules/activation.h>
   #include <torch/nn/modules/common.h>
   
   #include <torch/types.h>
   
   #include <ostream>
   
   namespace torch {
   namespace nn {
   
   // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ TransformerEncoderLayer ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   
   class TORCH_API TransformerEncoderLayerImpl : public Cloneable<TransformerEncoderLayerImpl> {
   
     public:
       explicit TransformerEncoderLayerImpl(const TransformerEncoderLayerOptions& options_);
   
       Tensor forward(
         const Tensor& src,
         const Tensor& src_mask = {},
         const Tensor& src_key_padding_mask = {});
   
       void reset() override;
   
       void reset_parameters();
   
     protected:
       FORWARD_HAS_DEFAULT_ARGS(
         {1, AnyValue(Tensor())},
         {2, AnyValue(Tensor())})
   
     public:
       TransformerEncoderLayerOptions options;
   
       MultiheadAttention self_attn = nullptr;
   
       Linear linear1 = nullptr;
   
       Dropout dropout = nullptr;
   
       Linear linear2 = nullptr;
   
       LayerNorm norm1 = nullptr;
       LayerNorm norm2 = nullptr;;
   
       Dropout dropout1 = nullptr;
       Dropout dropout2 = nullptr;
   };
   
   TORCH_MODULE(TransformerEncoderLayer);
   
   } // namespace nn
   } // namespace torch
