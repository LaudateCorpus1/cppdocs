:github_url: https://github.com/pytorch/pytorch


.. _program_listing_file_torch_csrc_api_include_torch_nn_modules_transformercoder.h:

Program Listing for File transformercoder.h
===========================================

|exhale_lsh| :ref:`Return to documentation for file <file_torch_csrc_api_include_torch_nn_modules_transformercoder.h>` (``torch/csrc/api/include/torch/nn/modules/transformercoder.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   #pragma once
   
   #include <torch/nn/cloneable.h>
   #include <torch/nn/module.h>
   #include <torch/nn/modules/container/any.h>
   #include <torch/nn/modules/container/modulelist.h>
   #include <torch/nn/options/transformercoder.h>
   #include <torch/nn/pimpl.h>
   #include <torch/nn/modules/common.h>
   
   #include <torch/types.h>
   
   #include <ostream>
   
   namespace torch {
   namespace nn {
   
   // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ TransformerEncoder ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   
   //  TransformerEncoder encoder(TransformerEncoderOptions(encoderLayer, 6).norm(LayerNorm(LayerNormOptions({2}))));
   class TORCH_API TransformerEncoderImpl : public Cloneable<TransformerEncoderImpl> {
   
     public:
       explicit TransformerEncoderImpl(TransformerEncoderOptions options_);
   
       Tensor forward(
         const Tensor& src,
         const Tensor& src_mask = {},
         const Tensor& src_key_padding_mask = {});
   
       void reset() override;
   
       void reset_parameters();
   
     protected:
       FORWARD_HAS_DEFAULT_ARGS(
           {1, AnyValue(Tensor())},
           {2, AnyValue(Tensor())})
   
     public:
       TransformerEncoderOptions options;
   
       ModuleList layers = nullptr;
   
       AnyModule norm;
   };
   
   TORCH_MODULE(TransformerEncoder);
   
   } // namespace nn
   } // namespace torch
