:github_url: https://github.com/pytorch/pytorch

.. _exhale_function_namespacetorch_1_1nn_1_1functional_1_1detail_1a664df85d5a86bf3c0f7f52b337ab56de:

Function torch::nn::functional::detail::multi_head_attention_forward
====================================================================

- Defined in :ref:`file_torch_csrc_api_include_torch_nn_functional_activation.h`


Function Documentation
----------------------


.. doxygenfunction:: torch::nn::functional::detail::multi_head_attention_forward(const Tensor&, const Tensor&, const Tensor&, int64_t, int64_t, const Tensor&, const Tensor&, const Tensor&, const Tensor&, bool, double, const Tensor&, const Tensor&, bool, const Tensor&, bool, const Tensor&, bool, const Tensor&, const Tensor&, const Tensor&, const Tensor&, const Tensor&)
