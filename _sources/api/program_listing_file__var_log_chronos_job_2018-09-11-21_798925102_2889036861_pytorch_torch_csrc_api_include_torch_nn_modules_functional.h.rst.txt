:github_url: https://github.com/pytorch/pytorch


.. _program_listing_file__var_log_chronos_job_2018-09-11-21_798925102_2889036861_pytorch_torch_csrc_api_include_torch_nn_modules_functional.h:

Program Listing for File functional.h
=====================================

- Return to documentation for :ref:`file__var_log_chronos_job_2018-09-11-21_798925102_2889036861_pytorch_torch_csrc_api_include_torch_nn_modules_functional.h`

.. code-block:: cpp

   #pragma once
   
   #include <torch/csrc/utils/variadic.h>
   #include <torch/nn/cloneable.h>
   #include <torch/nn/pimpl.h>
   #include <torch/tensor.h>
   
   #include <functional>
   #include <utility>
   
   namespace torch {
   namespace nn {
   
   class FunctionalImpl : public torch::nn::Cloneable<FunctionalImpl> {
    public:
     using Function = std::function<Tensor(Tensor)>;
   
     explicit FunctionalImpl(Function function);
   
     template <
         typename SomeFunction,
         typename... Args,
         typename = torch::enable_if_t<(sizeof...(Args) > 0)>>
     explicit FunctionalImpl(SomeFunction original_function, Args&&... args)
         : function_(std::bind(
               original_function,
               /*input=*/std::placeholders::_1,
               std::forward<Args>(args)...)) {
       // std::bind is normally evil, but (1) gcc is broken w.r.t. handling
       // parameter pack expansion in lambdas and (2) moving parameter packs into
       // a lambda only works with C++14, so std::bind is the more move-aware
       // solution here.
     }
   
     void reset() override;
   
     Tensor forward(Tensor input);
   
     Tensor operator()(Tensor input);
   
    private:
     Function function_;
   };
   
   TORCH_MODULE(Functional);
   
   } // namespace nn
   } // namespace torch
