:github_url: https://github.com/pytorch/pytorch


.. _program_listing_file_aten_src_ATen_DeviceGuard.h:

Program Listing for File DeviceGuard.h
======================================

|exhale_lsh| :ref:`Return to documentation for file <file_aten_src_ATen_DeviceGuard.h>` (``aten/src/ATen/DeviceGuard.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: none

   #pragma once
   
   #include <ATen/Tensor.h>
   #include <c10/Device.h>
   #include <ATen/core/ScalarType.h>
   #include <ATen/detail/CUDAHooksInterface.h>
   #include <c10/util/Exception.h>
   #include "c10/util/Optional.h"
   
   #include <cstddef>
   
   namespace at {
   struct DeviceGuard {
     DeviceGuard() = default;
   
     explicit DeviceGuard(Device device) {
       set_device(device);
     }
   
     explicit DeviceGuard(c10::optional<Device> device_opt) {
       if (device_opt.has_value()) {
         set_device(device_opt.value());
       }
     }
   
     explicit DeviceGuard(const Tensor& tensor) {
       set_device_from(tensor);
     }
   
     explicit DeviceGuard(const TensorList& tensors) {
       if (!tensors.empty()) {
         set_device_from(tensors.front());
       }
     }
   
     DeviceGuard(const DeviceGuard&) = delete;
     DeviceGuard& operator=(const DeviceGuard&) = delete;
   
     DeviceGuard(DeviceGuard&& other) noexcept {
       *this = std::move(other);
     }
   
     DeviceGuard& operator=(DeviceGuard&& other) noexcept {
       this->original_index_ = other.original_index_;
       this->last_index_ = other.last_index_;
       // Set other's original index to the unspecified/default state, so that it
       // doesn't also reset the device in its constructor.
       other.original_index_ = -1;
       return *this;
     }
   
     ~DeviceGuard() {
       // It should only not have a value if an index was never actually set.
       if (original_index_ != -1) {
         // Unchecked because we don't want to throw in the destructor.
         detail::DynamicCUDAInterface::unchecked_set_device(original_index_);
       }
     }
   
     void set_device(at::Device device) {
       if (device.type() == at::kCPU) {
         return;
       }
       AT_ASSERT(device.type() == at::kCUDA);
       auto index = device.index();
       if (index == -1) {
         return;
       }
       AT_ASSERT(index >= 0);
       if (original_index_ == -1) {
         int32_t previous_index = -123;
         detail::DynamicCUDAInterface::get_device(&previous_index);
         original_index_ = previous_index;
         if (index != original_index_) {
           detail::DynamicCUDAInterface::set_device(index);
         }
       } else {
         detail::DynamicCUDAInterface::set_device(index);
       }
       last_index_ = index;
     }
   
     void set_device_from(const Tensor& tensor) {
       if (tensor.defined()) {
         set_device(tensor.device());
       }
     }
   
     at::Device original_device() const noexcept {
       return original_index_ == -1 ? at::kCPU : at::Device(at::kCUDA, original_index_);
     }
   
     at::Device last_device() const noexcept {
       return last_index_ == -1 ? at::kCPU : at::Device(at::kCUDA, last_index_);
     }
   
    private:
     // This representation only works under the assumption that the DeviceType
     // is only CUDA.  I think a reasonable invariant to assert for DeviceGuard
     // is that once you've "picked" a device type, you can't mix set_device
     // with other device types.
   
     int16_t original_index_ = -1;
     int16_t last_index_ = -1;
   };
   } // namespace at
