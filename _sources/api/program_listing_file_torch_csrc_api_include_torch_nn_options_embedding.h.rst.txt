:github_url: https://github.com/pytorch/pytorch


.. _program_listing_file_torch_csrc_api_include_torch_nn_options_embedding.h:

Program Listing for File embedding.h
====================================

|exhale_lsh| :ref:`Return to documentation for file <file_torch_csrc_api_include_torch_nn_options_embedding.h>` (``torch/csrc/api/include/torch/nn/options/embedding.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   #pragma once
   
   #include <torch/arg.h>
   #include <torch/csrc/WindowsTorchApiMacro.h>
   #include <torch/types.h>
   #include <torch/enum.h>
   
   namespace torch {
   namespace nn {
     struct TORCH_API EmbeddingOptions {
       EmbeddingOptions();
       EmbeddingOptions(int64_t num_embeddings, int64_t embedding_dim);
       TORCH_ARG(c10::optional<int64_t>, num_embeddings) = c10::nullopt;
       TORCH_ARG(c10::optional<int64_t>, embedding_dim) = c10::nullopt;
       TORCH_ARG(c10::optional<int64_t>, padding_idx) = c10::nullopt;
       TORCH_ARG(c10::optional<double>, max_norm) = c10::nullopt;
       TORCH_ARG(double, norm_type) = 2.;
       TORCH_ARG(bool, scale_grad_by_freq) = false;
       TORCH_ARG(bool, sparse) = false;
       TORCH_ARG(torch::Tensor, _weight) = Tensor();
     };
   
     struct TORCH_API EmbeddingBagOptions {
       typedef c10::variant<enumtype::kSum, enumtype::kMean, enumtype::kMax> mode_t;
       EmbeddingBagOptions();
       EmbeddingBagOptions(int64_t num_embeddings, int64_t embedding_dim);
       TORCH_ARG(c10::optional<int64_t>, num_embeddings) = c10::nullopt;
       TORCH_ARG(c10::optional<int64_t>, embedding_dim) = c10::nullopt;
       TORCH_ARG(c10::optional<double>, max_norm) = c10::nullopt;
       TORCH_ARG(double, norm_type) = 2.;
       TORCH_ARG(bool, scale_grad_by_freq) = false;
       TORCH_ARG(mode_t, mode) = torch::kMean;
       TORCH_ARG(bool, sparse) = false;
       TORCH_ARG(torch::Tensor, _weight) = Tensor();
     };
   } // namespace nn
   } // namespace torch
