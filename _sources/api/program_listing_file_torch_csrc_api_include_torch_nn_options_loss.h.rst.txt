:github_url: https://github.com/pytorch/pytorch


.. _program_listing_file_torch_csrc_api_include_torch_nn_options_loss.h:

Program Listing for File loss.h
===============================

|exhale_lsh| :ref:`Return to documentation for file <file_torch_csrc_api_include_torch_nn_options_loss.h>` (``torch/csrc/api/include/torch/nn/options/loss.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   #pragma once
   
   #include <torch/arg.h>
   #include <torch/enum.h>
   #include <torch/csrc/WindowsTorchApiMacro.h>
   #include <torch/nn/options/common.h>
   #include <torch/types.h>
   
   namespace torch {
   namespace nn {
   
   struct TORCH_API L1LossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_OPTIONS_CTOR_VARIANT_ARG3(L1LossOptions, reduction, kNone, kMean, kSum)
   
     
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(L1Loss, L1LossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API KLDivLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kBatchMean, enumtype::kSum, enumtype::kMean> reduction_t;
   
     TORCH_OPTIONS_CTOR_VARIANT_ARG4(KLDivLossOptions, reduction, kNone, kBatchMean, kSum, kMean)
   
     
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(KLDivLoss, KLDivLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API MSELossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_OPTIONS_CTOR_VARIANT_ARG3(MSELossOptions, reduction, kNone, kMean, kSum)
   
     
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(MSELoss, MSELossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API BCELossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(Tensor, weight) = {};
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(BCELoss, BCELossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API HingeEmbeddingLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(double, margin) = 1.0;
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(HingeEmbeddingLoss, HingeEmbeddingLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API MultiMarginLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(int64_t, p) = 1;
     TORCH_ARG(double, margin) = 1.0;
     TORCH_ARG(Tensor, weight) = Tensor();
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(MultiMarginLoss, MultiMarginLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API CosineEmbeddingLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(double, margin) = 0.0;
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(CosineEmbeddingLoss, CosineEmbeddingLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API MultiLabelMarginLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_OPTIONS_CTOR_VARIANT_ARG3(MultiLabelMarginLossOptions, reduction, kNone, kMean, kSum)
   
     
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(MultiLabelMarginLoss, MultiLabelMarginLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API SoftMarginLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_OPTIONS_CTOR_VARIANT_ARG3(SoftMarginLossOptions, reduction, kNone, kMean, kSum)
   
     
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(SoftMarginLoss, SoftMarginLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API MultiLabelSoftMarginLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(Tensor, weight) = Tensor();
   
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(MultiLabelSoftMarginLoss, MultiLabelSoftMarginLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API TripletMarginLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(double, margin) = 1.0;
     TORCH_ARG(double, p) = 2.0;
     TORCH_ARG(double, eps) = 1e-6;
     TORCH_ARG(bool, swap) = false;
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(TripletMarginLoss, TripletMarginLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API CTCLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(int64_t, blank) = 0;
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
     TORCH_ARG(bool, zero_infinity) = false;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(CTCLoss, CTCLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API SmoothL1LossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_OPTIONS_CTOR_VARIANT_ARG3(SmoothL1LossOptions, reduction, kNone, kMean, kSum)
   
     
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(SmoothL1Loss, SmoothL1LossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API PoissonNLLLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(bool, log_input) = true;
     TORCH_ARG(bool, full) = false;
     TORCH_ARG(double, eps) = 1e-8;
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(PoissonNLLLoss, PoissonNLLLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API MarginRankingLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(double, margin) = 0;
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(MarginRankingLoss, MarginRankingLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API NLLLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(Tensor, weight) = {};
     TORCH_ARG(int64_t, ignore_index) = -100;
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(NLLLoss, NLLLossFuncOptions)
   
   // ============================================================================
   
   struct TORCH_API CrossEntropyLossOptions {
     typedef c10::variant<enumtype::kNone, enumtype::kMean, enumtype::kSum> reduction_t;
   
     TORCH_ARG(Tensor, weight) = {};
     TORCH_ARG(int64_t, ignore_index) = -100;
     TORCH_ARG(reduction_t, reduction) = torch::kMean;
   };
   
   TORCH_NN_FUNCTIONAL_USE_MODULE_OPTIONS(CrossEntropyLoss, CrossEntropyFuncOptions)
   
   } // namespace nn
   } // namespace torch
