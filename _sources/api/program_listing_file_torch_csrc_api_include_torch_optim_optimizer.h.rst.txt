:github_url: https://github.com/pytorch/pytorch


.. _program_listing_file_torch_csrc_api_include_torch_optim_optimizer.h:

Program Listing for File optimizer.h
====================================

|exhale_lsh| :ref:`Return to documentation for file <file_torch_csrc_api_include_torch_optim_optimizer.h>` (``torch/csrc/api/include/torch/optim/optimizer.h``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   #pragma once
   
   #include <ATen/Tensor.h>
   #include <c10/util/flat_hash_map.h>
   #include <c10/util/Exception.h>
   
   #include <torch/csrc/WindowsTorchApiMacro.h>
   
   #include <algorithm>
   #include <functional>
   #include <iterator>
   #include <memory>
   #include <string>
   #include <vector>
   
   // Forward declarations confuse Doxygen
   #ifndef DOXYGEN_SHOULD_SKIP_THIS
   namespace at {
   class Tensor;
   } // namespace at
   
   namespace torch {
   using at::Tensor;
   namespace serialize {
   class OutputArchive;
   class InputArchive;
   } // namespace serialize
   } // namespace torch
   #endif // DOXYGEN_SHOULD_SKIP_THIS
   
   namespace torch {
   namespace optim {
   
   class TORCH_API OptimizerParamState {
    public:
     virtual std::unique_ptr<OptimizerParamState> clone() const;
     virtual void serialize(torch::serialize::InputArchive& archive);
     virtual void serialize(torch::serialize::OutputArchive& archive) const;
     virtual ~OptimizerParamState() = default;
   };
   
   template <typename Derived>
   class TORCH_API OptimizerCloneableParamState : public OptimizerParamState {
     std::unique_ptr<OptimizerParamState> clone() const override {
       return std::make_unique<Derived>(static_cast<const Derived&>(*this));
     }
   };
   
   class TORCH_API OptimizerOptions {
    public:
     virtual std::unique_ptr<OptimizerOptions> clone() const;
     virtual void serialize(torch::serialize::InputArchive& archive);
     virtual void serialize(torch::serialize::OutputArchive& archive) const;
     virtual ~OptimizerOptions() = default;
   };
   
   template <typename Derived>
   class TORCH_API OptimizerCloneableOptions : public OptimizerOptions {
     std::unique_ptr<OptimizerOptions> clone() const override {
       return std::make_unique<Derived>(static_cast<const Derived&>(*this));
     }
   };
   
   class TORCH_API OptimizerParamGroup {
    public:
     // NOTE: In order to store `OptimizerParamGroup` in a `std::vector`, it has to be copy-constructible.
     OptimizerParamGroup(const OptimizerParamGroup& param_group) : params_(param_group.params()), options_(param_group.has_options() ? param_group.options().clone() : nullptr) {}
     OptimizerParamGroup(std::vector<Tensor> params) : params_(std::move(params)) {}
     OptimizerParamGroup(std::vector<Tensor> params, std::unique_ptr<OptimizerOptions> options) : params_(std::move(params)), options_(std::move(options)) {}
   
     bool has_options() const;
     OptimizerOptions& options();
     const OptimizerOptions& options() const;
     void set_options(std::unique_ptr<OptimizerOptions> options);
     std::vector<Tensor>& params();
     const std::vector<Tensor>& params() const;
   
    protected:
     std::vector<Tensor> params_;
     std::unique_ptr<OptimizerOptions> options_;
   };
   
   namespace detail {
   
   class TORCH_API OptimizerBase {
    public:
     // The copy constructor is deleted, because the user should use the
     // `state_dict` / `load_state_dict` API to copy an optimizer instead.
     OptimizerBase(const OptimizerBase& optimizer_base) = delete;
     OptimizerBase(OptimizerBase&& optimizer_base) = default;
   
     explicit OptimizerBase(std::vector<Tensor> parameters);
   
     explicit OptimizerBase(std::vector<OptimizerParamGroup> param_groups, std::unique_ptr<OptimizerOptions> defaults) : defaults_(std::move(defaults)) {
       for (const auto& param_group : param_groups) {
         add_param_group(param_group);
       }
     }
   
     void add_param_group(const OptimizerParamGroup& param_group);
   
     virtual ~OptimizerBase() = default;
   
     // TODO: when all optimizers use the new design, we can devirtualize some of the following methods
     // such as add_parameters() / parameters() / size()
   
     virtual void add_parameters(const std::vector<Tensor>& parameters);
   
     virtual void _add_parameters_new_design(const std::vector<Tensor>& parameters);
   
     virtual void zero_grad();
   
     virtual const std::vector<Tensor>& parameters() const noexcept;
   
     virtual const std::vector<Tensor>& _parameters_new_design() const noexcept;
   
     virtual std::vector<Tensor>& parameters() noexcept;
   
     virtual std::vector<Tensor>& _parameters_new_design() noexcept;
   
     virtual size_t size() const noexcept;
   
     virtual size_t _size_new_design() const noexcept;
   
     OptimizerOptions& defaults() noexcept;
   
     const OptimizerOptions& defaults() const noexcept;
   
     std::vector<OptimizerParamGroup>& param_groups() noexcept;
   
     const std::vector<OptimizerParamGroup>& param_groups() const noexcept;
   
     ska::flat_hash_map<std::string, std::unique_ptr<OptimizerParamState>>& state() noexcept;
   
     const ska::flat_hash_map<std::string, std::unique_ptr<OptimizerParamState>>& state() const noexcept;
   
     virtual void save(serialize::OutputArchive& archive) const;
   
     virtual void load(serialize::InputArchive& archive);
   
    protected:
      std::vector<OptimizerParamGroup> param_groups_;
      ska::flat_hash_map<std::string, std::unique_ptr<OptimizerParamState>> state_;
      std::unique_ptr<OptimizerOptions> defaults_;
      OptimizerBase() = default;
   
     template <typename T>
     T& buffer_at(std::vector<T>& buffers, size_t index) {
       if (buffers.size() <= index) {
         const auto old_size = buffers.size();
         buffers.resize(index + 1);
         std::fill(buffers.begin() + old_size, buffers.end(), T{0});
       }
       return buffers[index];
     }
   
     Tensor& buffer_at(std::vector<Tensor>& buffers, size_t index);
   
     std::vector<Tensor> parameters_;
   };
   
   TORCH_API serialize::OutputArchive& operator<<(
       serialize::OutputArchive& archive,
       const OptimizerBase& optimizer);
   
   TORCH_API serialize::InputArchive& operator>>(
       serialize::InputArchive& archive,
       OptimizerBase& optimizer);
   } // namespace detail
   
   class Optimizer : public detail::OptimizerBase {
    public:
     using detail::OptimizerBase::OptimizerBase;
     virtual void step() = 0;
   };
   
   class LossClosureOptimizer : public detail::OptimizerBase {
    public:
     using LossClosure = std::function<Tensor()>;
     using detail::OptimizerBase::OptimizerBase;
     virtual Tensor step(LossClosure closure) = 0;
   };
   
   } // namespace optim
   } // namespace torch
