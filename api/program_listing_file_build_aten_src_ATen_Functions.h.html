


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Program Listing for File Functions.h &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/api/program_listing_file_build_aten_src_ATen_Functions.h.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/cpp_theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/elastic/">
                  <span class="dropdown-title">TorchElastic</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">Installing C++ Distributions of PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend.html">The C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="library_root.html">Library API</a></li>
</ul>
<p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/inference_mode.html">Inference Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/tensor_basics.html">Tensor Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/tensor_creation.html">Tensor Creation API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/tensor_cuda_stream.html">Tensor CUDA Stream API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/tensor_indexing.html">Tensor Indexing API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/versioning.html">Library Versioning</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Program Listing for File Functions.h</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            
              <!-- User defined GitHub URL -->
              <a href="https://github.com/pytorch/pytorch" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="program-listing-for-file-functions-h">
<span id="program-listing-file-build-aten-src-aten-functions-h"></span><h1>Program Listing for File Functions.h<a class="headerlink" href="#program-listing-for-file-functions-h" title="Permalink to this headline">Â¶</a></h1>
<p>â†° <a class="reference internal" href="file_build_aten_src_ATen_Functions.h.html#file-build-aten-src-aten-functions-h"><span class="std std-ref">Return to documentation for file</span></a> (<code class="docutils literal notranslate"><span class="pre">build/aten/src/ATen/Functions.h</span></code>)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma once</span>

<span class="c1">// @generated by tools/codegen/gen.py from Functions.h</span>

<span class="cp">#include</span> <span class="cpf">&lt;c10/core/Scalar.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;ATen/Tensor.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;c10/core/Storage.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;ATen/core/Generator.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;c10/util/Deprecated.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;ATen/DeviceGuard.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;c10/core/TensorOptions.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;ATen/core/Reduction.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;c10/util/Optional.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;ATen/TensorUtils.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;ATen/Context.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;ATen/TracerMode.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;ATen/Operators.h&gt;</span><span class="cp"></span>



<span class="k">namespace</span> <span class="nn">at</span> <span class="p">{</span>

<span class="c1">// These functions are defined in ATen/Utils.cpp.</span>
<span class="cp">#define TENSOR(T, S)                                                          \</span>
<span class="cp">  TORCH_API Tensor tensor(ArrayRef&lt;T&gt; values, const TensorOptions&amp; options); \</span>
<span class="cp">  inline Tensor tensor(                                                       \</span>
<span class="cp">      std::initializer_list&lt;T&gt; values, const TensorOptions&amp; options) {        \</span>
<span class="cp">    return at::tensor(ArrayRef&lt;T&gt;(values), options);                          \</span>
<span class="cp">  }                                                                           \</span>
<span class="cp">  inline Tensor tensor(T value, const TensorOptions&amp; options) {               \</span>
<span class="cp">    return at::tensor(ArrayRef&lt;T&gt;(value), options);                           \</span>
<span class="cp">  }                                                                           \</span>
<span class="cp">  inline Tensor tensor(ArrayRef&lt;T&gt; values) {                                  \</span>
<span class="cp">    return at::tensor(std::move(values), at::dtype(k##S));                    \</span>
<span class="cp">  }                                                                           \</span>
<span class="cp">  inline Tensor tensor(std::initializer_list&lt;T&gt; values) {                     \</span>
<span class="cp">    return at::tensor(ArrayRef&lt;T&gt;(values));                                   \</span>
<span class="cp">  }                                                                           \</span>
<span class="cp">  inline Tensor tensor(T value) {                                             \</span>
<span class="cp">    return at::tensor(ArrayRef&lt;T&gt;(value));                                    \</span>
<span class="cp">  }</span>
<span class="n">AT_FORALL_SCALAR_TYPES_AND3</span><span class="p">(</span><span class="n">Bool</span><span class="p">,</span> <span class="n">Half</span><span class="p">,</span> <span class="n">BFloat16</span><span class="p">,</span> <span class="n">TENSOR</span><span class="p">)</span>
<span class="n">AT_FORALL_COMPLEX_TYPES</span><span class="p">(</span><span class="n">TENSOR</span><span class="p">)</span>
<span class="cp">#undef TENSOR</span>


<span class="c1">// aten::_cast_Byte(Tensor self, bool non_blocking=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cast_Byte</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cast_Byte</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cast_Char(Tensor self, bool non_blocking=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cast_Char</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cast_Char</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cast_Double(Tensor self, bool non_blocking=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cast_Double</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cast_Double</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cast_Float(Tensor self, bool non_blocking=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cast_Float</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cast_Float</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cast_Int(Tensor self, bool non_blocking=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cast_Int</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cast_Int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cast_Long(Tensor self, bool non_blocking=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cast_Long</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cast_Long</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cast_Short(Tensor self, bool non_blocking=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cast_Short</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cast_Short</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cast_Half(Tensor self, bool non_blocking=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cast_Half</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cast_Half</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_make_dual(Tensor(a) primal, Tensor tangent, int level) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_make_dual</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">primal</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tangent</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">level</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_make_dual</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">primal</span><span class="p">,</span> <span class="n">tangent</span><span class="p">,</span> <span class="n">level</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_unpack_dual(Tensor(a) dual, int level) -&gt; (Tensor(a) primal, Tensor tangent)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_unpack_dual</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dual</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">level</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_unpack_dual</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">dual</span><span class="p">,</span> <span class="n">level</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::align_tensors(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">align_tensors</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">align_tensors</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_assert_async(Tensor self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_assert_async</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_assert_async</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_use_cudnn_ctc_loss(Tensor log_probs, Tensor targets, int[] input_lengths, int[] target_lengths, int blank) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">_use_cudnn_ctc_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_probs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">targets</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">blank</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_use_cudnn_ctc_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cudnn_ctc_loss(Tensor log_probs, Tensor targets, int[] input_lengths, int[] target_lengths, int blank, bool deterministic, bool zero_infinity) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_cudnn_ctc_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_probs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">targets</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">blank</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">zero_infinity</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cudnn_ctc_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">zero_infinity</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_use_cudnn_rnn_flatten_weight() -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">_use_cudnn_rnn_flatten_weight</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_use_cudnn_rnn_flatten_weight</span><span class="o">::</span><span class="n">call</span><span class="p">();</span>
<span class="p">}</span>

<span class="c1">// aten::_cudnn_rnn_flatten_weight(Tensor[] weight_arr, int weight_stride0, int input_size, int mode, int hidden_size, int proj_size, int num_layers, bool batch_first, bool bidirectional) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cudnn_rnn_flatten_weight</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">weight_arr</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">proj_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cudnn_rnn_flatten_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight_arr</span><span class="p">,</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">proj_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cudnn_rnn(Tensor input, Tensor[] weight, int weight_stride0, Tensor? weight_buf, Tensor hx, Tensor? cx, int mode, int hidden_size, int proj_size, int num_layers, bool batch_first, float dropout, bool train, bool bidirectional, int[] batch_sizes, Tensor? dropout_state) -&gt; (Tensor, Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_cudnn_rnn</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight_buf</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">cx</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">proj_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">dropout_state</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cudnn_rnn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="n">weight_buf</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">proj_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">dropout_state</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cudnn_rnn_backward(Tensor input, Tensor[] weight, int weight_stride0, Tensor weight_buf, Tensor hx, Tensor? cx, Tensor output, Tensor? grad_output, Tensor? grad_hy, Tensor? grad_cy, int mode, int hidden_size, int proj_size, int num_layers, bool batch_first, float dropout, bool train, bool bidirectional, int[] batch_sizes, Tensor? dropout_state, Tensor reserve, bool[4] output_mask) -&gt; (Tensor, Tensor, Tensor, Tensor[])</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span> <span class="n">_cudnn_rnn_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight_buf</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">cx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_hy</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_cy</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">proj_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">dropout_state</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reserve</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">4</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cudnn_rnn_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="n">weight_buf</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">grad_hy</span><span class="p">,</span> <span class="n">grad_cy</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">proj_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">dropout_state</span><span class="p">,</span> <span class="n">reserve</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cudnn_init_dropout_state(float dropout, bool train, int dropout_seed, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cudnn_init_dropout_state</span><span class="p">(</span><span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dropout_seed</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cudnn_init_dropout_state</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">dropout_seed</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::_cudnn_init_dropout_state(float dropout, bool train, int dropout_seed, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cudnn_init_dropout_state</span><span class="p">(</span><span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dropout_seed</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cudnn_init_dropout_state</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">dropout_seed</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_debug_has_internal_overlap(Tensor self) -&gt; int</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">_debug_has_internal_overlap</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_debug_has_internal_overlap</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fused_dropout(Tensor self, float p, Generator? generator=None) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_fused_dropout</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fused_dropout</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_masked_scale(Tensor self, Tensor mask, float scale) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_masked_scale</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">,</span> <span class="kt">double</span> <span class="n">scale</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_masked_scale</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">scale</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sobol_engine_draw(Tensor quasi, int n, Tensor sobolstate, int dimension, int num_generated, ScalarType? dtype) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_sobol_engine_draw</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">quasi</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sobolstate</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dimension</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_generated</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sobol_engine_draw</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">quasi</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sobolstate</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">num_generated</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sobol_engine_ff_(Tensor(a!) self, int n, Tensor sobolstate, int dimension, int num_generated) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_sobol_engine_ff_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sobolstate</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dimension</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_generated</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sobol_engine_ff_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sobolstate</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">num_generated</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sobol_engine_scramble_(Tensor(a!) self, Tensor ltm, int dimension) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_sobol_engine_scramble_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ltm</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dimension</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sobol_engine_scramble_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ltm</span><span class="p">,</span> <span class="n">dimension</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sobol_engine_initialize_state_(Tensor(a!) self, int dimension) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_sobol_engine_initialize_state_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dimension</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sobol_engine_initialize_state_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dimension</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_reshape_from_tensor(Tensor self, Tensor shape) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_reshape_from_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">shape</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_reshape_from_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_shape_as_tensor(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_shape_as_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_shape_as_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dropout(Tensor input, float p, bool train) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">dropout</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dropout</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dropout_(Tensor(a!) self, float p, bool train) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dropout_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dropout_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::feature_dropout(Tensor input, float p, bool train) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">feature_dropout</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">feature_dropout</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::feature_dropout_(Tensor(a!) self, float p, bool train) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">feature_dropout_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">feature_dropout_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::alpha_dropout(Tensor input, float p, bool train) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">alpha_dropout</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">alpha_dropout</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::alpha_dropout_(Tensor(a!) self, float p, bool train) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">alpha_dropout_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">alpha_dropout_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::feature_alpha_dropout(Tensor input, float p, bool train) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">feature_alpha_dropout</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">feature_alpha_dropout</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::feature_alpha_dropout_(Tensor(a!) self, float p, bool train) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">feature_alpha_dropout_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">feature_alpha_dropout_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::abs(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">abs</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">abs</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::abs_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">abs_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">abs_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::abs.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">abs_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">abs_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::abs.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">abs_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">abs_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::absolute(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">absolute</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">absolute</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::absolute.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">absolute_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">absolute_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::absolute.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">absolute_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">absolute_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::angle(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">angle</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">angle</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::angle.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">angle_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">angle_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::angle.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">angle_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">angle_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::view_as_real(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">view_as_real</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">view_as_real</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::view_as_complex(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">view_as_complex</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">view_as_complex</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sgn(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sgn</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sgn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sgn.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sgn_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sgn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sgn.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sgn_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sgn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::real(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">real</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">real</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::imag(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">imag</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">imag</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_conj(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_conj</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_conj</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conj(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__dispatch_conj</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conj</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_conj_physical(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_conj_physical</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_conj_physical</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conj_physical(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conj_physical</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conj_physical</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conj_physical.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">conj_physical_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conj_physical_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conj_physical.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">conj_physical_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conj_physical_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conj_physical_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">conj_physical_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conj_physical_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::resolve_conj(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">resolve_conj</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resolve_conj</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::resolve_neg(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">resolve_neg</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resolve_neg</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_neg_view(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_neg_view</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_neg_view</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::acos(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">acos</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acos</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::acos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">acos_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acos_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::acos.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">acos_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acos_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::acos.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">acos_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acos_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arccos(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arccos</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccos</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arccos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arccos_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccos_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arccos.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arccos_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccos_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arccos.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arccos_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccos_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool1d(Tensor self, int[1] kernel_size, int[1] stride=[], int[1] padding=0, bool ceil_mode=False, bool count_include_pad=True) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">avg_pool1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_avg_pool1d(Tensor self, int[1] output_size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">adaptive_avg_pool1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_avg_pool1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool1d(Tensor self, int[1] output_size) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">adaptive_max_pool1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">add</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">add_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::add.out(Tensor self, Tensor other, *, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">add_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">add_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::add.out(Tensor self, Tensor other, *, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">add_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">add_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_add_relu.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_add_relu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_add_relu_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_add_relu_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_add_relu_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_add_relu__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_add_relu.out(Tensor self, Tensor other, *, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_add_relu_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_add_relu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_add_relu.out(Tensor self, Tensor other, *, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_add_relu_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_add_relu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_add_relu.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_add_relu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_add_relu_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_add_relu_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_add_relu_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_add_relu__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">add</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">add_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmv(Tensor self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">addmv</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmv_(Tensor(a!) self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addmv_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmv_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmv.out(Tensor self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addmv_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmv.out(Tensor self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addmv_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addr(Tensor self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">addr</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addr.out(Tensor self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addr_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addr.out(Tensor self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addr_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::affine_grid_generator(Tensor theta, int[] size, bool align_corners) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">affine_grid_generator</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">theta</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">affine_grid_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::affine_grid_generator_backward(Tensor grad, int[] size, bool align_corners) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">affine_grid_generator_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">affine_grid_generator_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all.dim(Tensor self, int dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">all</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all.out(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">all_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all.out(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">all_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">all</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all.dimname_out(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">all_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all.dimname_out(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">all_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::allclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">allclose</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="kt">double</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="kt">double</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">equal_nan</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">allclose</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="p">,</span> <span class="n">equal_nan</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any.dim(Tensor self, int dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">any</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any.out(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">any_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any.out(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">any_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">any</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any.dimname_out(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">any_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any.dimname_out(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">any_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arange(Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arange</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::arange(Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arange</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arange.start(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arange</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange_start</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::arange.start(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arange</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange_start</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arange.start_step(Scalar start, Scalar end, Scalar step, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arange</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">step</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange_start_step</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::arange.start_step(Scalar start, Scalar end, Scalar step, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arange</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">step</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange_start_step</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arange.out(Scalar end, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arange_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arange.out(Scalar end, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arange_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">end</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arange_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange_start_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arange_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">step</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arange_start_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_dim_arange(Tensor like, int dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_dim_arange</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">like</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_dim_arange</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">like</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argmax(Tensor self, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">argmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argmax.out(Tensor self, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">argmax_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argmax_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argmax.out(Tensor self, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">argmax_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argmax_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argmin(Tensor self, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">argmin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argmin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argmin.out(Tensor self, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">argmin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argmin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argmin.out(Tensor self, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">argmin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argmin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::acosh(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">acosh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acosh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::acosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">acosh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acosh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::acosh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">acosh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acosh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::acosh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">acosh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acosh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arccosh(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arccosh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccosh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arccosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arccosh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccosh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arccosh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arccosh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccosh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arccosh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arccosh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccosh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::asinh(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">asinh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asinh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::asinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">asinh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asinh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::asinh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">asinh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asinh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::asinh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">asinh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asinh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arcsinh(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arcsinh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsinh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arcsinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arcsinh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsinh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arcsinh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arcsinh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsinh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arcsinh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arcsinh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsinh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atanh(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">atanh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atanh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">atanh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atanh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atanh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">atanh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atanh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atanh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">atanh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atanh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctanh(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arctanh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctanh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arctanh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctanh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctanh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arctanh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctanh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctanh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arctanh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctanh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::as_strided(Tensor(a) self, int[] size, int[] stride, int? storage_offset=None) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">as_strided</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">storage_offset</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">as_strided</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">storage_offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::as_strided_(Tensor(a!) self, int[] size, int[] stride, int? storage_offset=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">as_strided_</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">storage_offset</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">as_strided_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">storage_offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::asin(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">asin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::asin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">asin_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asin_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::asin.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">asin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::asin.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">asin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arcsin(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arcsin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arcsin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arcsin_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsin_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arcsin.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arcsin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arcsin.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arcsin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atan(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">atan</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">atan_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atan.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">atan_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atan.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">atan_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctan(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">arctan</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arctan_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctan_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctan.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arctan_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctan_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctan.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">arctan_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctan_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atleast_1d(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">atleast_1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atleast_1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atleast_1d.Sequence(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">atleast_1d</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atleast_1d_Sequence</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atleast_2d(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">atleast_2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atleast_2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atleast_2d.Sequence(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">atleast_2d</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atleast_2d_Sequence</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atleast_3d(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">atleast_3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atleast_3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atleast_3d.Sequence(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">atleast_3d</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atleast_3d_Sequence</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">baddbmm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">baddbmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_baddbmm_mkl_(Tensor(a!) self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_baddbmm_mkl_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_baddbmm_mkl_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::baddbmm.out(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">baddbmm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">baddbmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::baddbmm.out(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">baddbmm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">baddbmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bartlett_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bartlett_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bartlett_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::bartlett_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bartlett_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bartlett_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bartlett_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bartlett_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bartlett_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::bartlett_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bartlett_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bartlett_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">batch_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="p">,</span> <span class="kt">double</span> <span class="n">momentum</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">cudnn_enabled</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantized_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor mean, Tensor var, float eps, float output_scale, int output_zero_point) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantized_batch_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">var</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="kt">double</span> <span class="n">output_scale</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">output_zero_point</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantized_batch_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">output_scale</span><span class="p">,</span> <span class="n">output_zero_point</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_batch_norm_impl_index(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -&gt; (Tensor, Tensor, Tensor, Tensor, int)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">_batch_norm_impl_index</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="p">,</span> <span class="kt">double</span> <span class="n">momentum</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">cudnn_enabled</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_batch_norm_impl_index</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_batch_norm_impl_index_backward(int impl_index, Tensor input, Tensor grad_output, Tensor? weight, Tensor? running_mean, Tensor? running_var, Tensor? save_mean, Tensor? save_var_transform, bool train, float eps, bool[3] output_mask, Tensor reservedSpace) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_batch_norm_impl_index_backward</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">impl_index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">save_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">save_var_transform</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reservedSpace</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_batch_norm_impl_index_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">impl_index</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">save_mean</span><span class="p">,</span> <span class="n">save_var_transform</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">,</span> <span class="n">reservedSpace</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bernoulli(Tensor self, *, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bernoulli</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bernoulli</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bernoulli.out(Tensor self, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bernoulli_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bernoulli_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bernoulli.out(Tensor self, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bernoulli_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bernoulli_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bernoulli.p(Tensor self, float p, *, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bernoulli</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bernoulli_p</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bilinear(Tensor input1, Tensor input2, Tensor weight, Tensor? bias) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bilinear</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bilinear</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::binary_cross_entropy(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">binary_cross_entropy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">binary_cross_entropy</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::binary_cross_entropy.out(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">binary_cross_entropy_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">binary_cross_entropy_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::binary_cross_entropy.out(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">binary_cross_entropy_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">binary_cross_entropy_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::binary_cross_entropy_backward(Tensor grad_output, Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">binary_cross_entropy_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">binary_cross_entropy_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::binary_cross_entropy_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">binary_cross_entropy_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">binary_cross_entropy_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::binary_cross_entropy_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">binary_cross_entropy_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">binary_cross_entropy_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::binary_cross_entropy_with_logits(Tensor self, Tensor target, Tensor? weight=None, Tensor? pos_weight=None, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">pos_weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">binary_cross_entropy_with_logits</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">pos_weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::binary_cross_entropy_with_logits_backward(Tensor grad_output, Tensor self, Tensor target, Tensor? weight=None, Tensor? pos_weight=None, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">binary_cross_entropy_with_logits_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">pos_weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">binary_cross_entropy_with_logits_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">pos_weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bincount(Tensor self, Tensor? weights=None, int minlength=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bincount</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weights</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">minlength</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bincount</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">minlength</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_not(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_not</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_not</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_not.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_not_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_not_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_not.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_not_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_not_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copysign.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">copysign_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copysign.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">copysign_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copysign.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">copysign</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copysign.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">copysign</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copysign.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">copysign_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copysign.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">copysign_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_not(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logical_not</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_not</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_not.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logical_not_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_not_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_not.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logical_not_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_not_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_xor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logical_xor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_xor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_xor.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logical_xor_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_xor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_xor.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logical_xor_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_xor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_and(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logical_and</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_and</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_and.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logical_and_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_and_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_and.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logical_and_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_and_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_or(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logical_or</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_or</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_or.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logical_or_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_or_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_or.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logical_or_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_or_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::blackman_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">blackman_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">blackman_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::blackman_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">blackman_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">blackman_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::blackman_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">blackman_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">blackman_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::blackman_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">blackman_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">blackman_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bmm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bmm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bmm.out(Tensor self, Tensor mat2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bmm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bmm.out(Tensor self, Tensor mat2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bmm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::broadcast_tensors(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">broadcast_tensors</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">broadcast_tensors</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::broadcast_to(Tensor(a) self, int[] size) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">broadcast_to</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cat(Tensor[] tensors, int dim=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cat</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cat</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cat.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cat_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cat_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cat.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cat_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cat_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cat.names(Tensor[] tensors, Dimname dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cat</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cat_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cat.names_out(Tensor[] tensors, Dimname dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cat_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cat_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cat.names_out(Tensor[] tensors, Dimname dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cat_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cat_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::block_diag(Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">block_diag</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">block_diag</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ceil(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ceil</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ceil</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ceil_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ceil_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ceil_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ceil.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ceil_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ceil_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ceil.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ceil_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ceil_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::chain_matmul(Tensor[] matrices) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">chain_matmul</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">matrices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">chain_matmul</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">matrices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::chain_matmul.out(Tensor[] matrices, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">chain_matmul_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">matrices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">chain_matmul_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">matrices</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::chain_matmul.out(Tensor[] matrices, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">chain_matmul_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">matrices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">chain_matmul_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">matrices</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsafe_chunk(Tensor self, int chunks, int dim=0) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">unsafe_chunk</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">chunks</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsafe_chunk</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunks</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::chunk(Tensor(a) self, int chunks, int dim=0) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">chunk</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">chunks</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">chunk</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunks</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensor_split.sections(Tensor(a) self, int sections, int dim=0) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">tensor_split</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">sections</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensor_split_sections</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sections</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensor_split.indices(Tensor(a) self, int[] indices, int dim=0) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">tensor_split</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensor_split_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensor_split.tensor_indices_or_sections(Tensor(a) self, Tensor tensor_indices_or_sections, int dim=0) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">tensor_split</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor_indices_or_sections</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensor_split_tensor_indices_or_sections</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor_indices_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp(Tensor self, Scalar? min=None, Scalar? max=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">clamp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">clamp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp.out(Tensor self, Scalar? min=None, Scalar? max=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp.out(Tensor self, Scalar? min=None, Scalar? max=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp.Tensor_out(Tensor self, Tensor? min=None, Tensor? max=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp.Tensor_out(Tensor self, Tensor? min=None, Tensor? max=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max(Tensor self, Scalar max) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">clamp_max</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max.Tensor(Tensor self, Tensor max) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">clamp_max</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max_(Tensor(a!) self, Scalar max) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_max_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max_.Tensor(Tensor(a!) self, Tensor max) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_max_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max.out(Tensor self, Scalar max, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_max_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max.out(Tensor self, Scalar max, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_max_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max.Tensor_out(Tensor self, Tensor max, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_max_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max.Tensor_out(Tensor self, Tensor max, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_max_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min(Tensor self, Scalar min) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">clamp_min</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min.Tensor(Tensor self, Tensor min) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">clamp_min</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min_(Tensor(a!) self, Scalar min) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_min_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min_.Tensor(Tensor(a!) self, Tensor min) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_min_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_min_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min.out(Tensor self, Scalar min, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_min_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min.Tensor_out(Tensor self, Tensor min, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_min_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min.Tensor_out(Tensor self, Tensor min, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clamp_min_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip(Tensor self, Scalar? min=None, Scalar? max=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">clip</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">clip</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clip_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clip_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip.out(Tensor self, Scalar? min=None, Scalar? max=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clip_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip.out(Tensor self, Scalar? min=None, Scalar? max=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clip_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip.Tensor_out(Tensor self, Tensor? min=None, Tensor? max=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clip_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip.Tensor_out(Tensor self, Tensor? min=None, Tensor? max=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">clip_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_is_acceptable(Tensor self) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">cudnn_is_acceptable</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_is_acceptable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::complex(Tensor real, Tensor imag) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">complex</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">real</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">imag</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">complex</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::complex.out(Tensor real, Tensor imag, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">complex_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">real</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">imag</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">complex_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::complex.out(Tensor real, Tensor imag, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">complex_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">real</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">imag</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">complex_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::polar(Tensor abs, Tensor angle) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">polar</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">abs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">angle</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">polar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">abs</span><span class="p">,</span> <span class="n">angle</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::polar.out(Tensor abs, Tensor angle, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">polar_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">abs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">angle</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">polar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">abs</span><span class="p">,</span> <span class="n">angle</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::polar.out(Tensor abs, Tensor angle, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">polar_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">abs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">angle</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">polar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">abs</span><span class="p">,</span> <span class="n">angle</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::constant_pad_nd(Tensor self, int[] pad, Scalar value=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">constant_pad_nd</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">pad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">constant_pad_nd</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">convolution</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::convolution_overrideable(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">convolution_overrideable</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">convolution_overrideable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::convolution_backward_overrideable(Tensor grad_output, Tensor input, Tensor weight, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool[3] output_mask) -&gt; (Tensor grad_input, Tensor grad_weight, Tensor grad_bias)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">convolution_backward_overrideable</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">convolution_backward_overrideable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_convolution(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">cudnn_enabled</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_convolution</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_convolution.deprecated(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">cudnn_enabled</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_convolution_deprecated</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_convolution_mode(Tensor input, Tensor weight, Tensor? bias, int[] stride, str padding, int[] dilation, int groups) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_convolution_mode</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_convolution_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_convolution_nogroup(Tensor input, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_convolution_nogroup</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_convolution_nogroup</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_convolution_double_backward(Tensor? ggI, Tensor? ggW, Tensor? ggb, Tensor gO, Tensor weight, Tensor self, int[] stride, int[] padding, int[] dilation, bool transposed, int[] output_padding, int groups, bool benchmark, bool deterministic, bool cudnn_enabled, bool allow_tf32, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_convolution_double_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">ggI</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">ggW</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">ggb</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gO</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">cudnn_enabled</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_convolution_double_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">ggI</span><span class="p">,</span> <span class="n">ggW</span><span class="p">,</span> <span class="n">ggb</span><span class="p">,</span> <span class="n">gO</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv1d(Tensor input, Tensor weight, Tensor? bias=None, int[1] stride=1, int[1] padding=0, int[1] dilation=1, int groups=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv2d(Tensor input, Tensor weight, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] dilation=1, int groups=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv3d(Tensor input, Tensor weight, Tensor? bias=None, int[3] stride=1, int[3] padding=0, int[3] dilation=1, int groups=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv1d.padding(Tensor input, Tensor weight, Tensor? bias=None, int[1] stride=1, str padding=&quot;valid&quot;, int[1] dilation=1, int groups=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv1d_padding</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv2d.padding(Tensor input, Tensor weight, Tensor? bias=None, int[2] stride=1, str padding=&quot;valid&quot;, int[2] dilation=1, int groups=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv2d_padding</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv3d.padding(Tensor input, Tensor weight, Tensor? bias=None, int[3] stride=1, str padding=&quot;valid&quot;, int[3] dilation=1, int groups=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv3d_padding</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv_tbc(Tensor self, Tensor weight, Tensor bias, int pad=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv_tbc</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv_tbc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">pad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv_tbc_backward(Tensor self, Tensor input, Tensor weight, Tensor bias, int pad) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">conv_tbc_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">pad</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv_tbc_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">pad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv_transpose1d(Tensor input, Tensor weight, Tensor? bias=None, int[1] stride=1, int[1] padding=0, int[1] output_padding=0, int groups=1, int[1] dilation=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv_transpose1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv_transpose1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv_transpose2d.input(Tensor input, Tensor weight, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] output_padding=0, int groups=1, int[2] dilation=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv_transpose2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv_transpose2d_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv_transpose3d.input(Tensor input, Tensor weight, Tensor? bias=None, int[3] stride=1, int[3] padding=0, int[3] output_padding=0, int groups=1, int[3] dilation=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv_transpose3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv_transpose3d_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_copy_from(Tensor self, Tensor dst, bool non_blocking=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_copy_from</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dst</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_copy_from</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_copy_from_and_resize(Tensor self, Tensor dst) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_copy_from_and_resize</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dst</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_copy_from_and_resize</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dst</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cos(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cos</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cos</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cos_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cos_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cos.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cos_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cos_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cos.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cos_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cos_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cosh(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cosh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cosh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cosh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cosh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cosh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cosh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cosh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cosh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cosh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cosh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cosine_embedding_loss(Tensor input1, Tensor input2, Tensor target, float margin=0.0, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cosine_embedding_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">double</span> <span class="n">margin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cosine_embedding_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::count_nonzero.dim_IntList(Tensor self, int[] dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">count_nonzero</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">count_nonzero_dim_IntList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::count_nonzero(Tensor self, int? dim=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">count_nonzero</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">count_nonzero</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cov(Tensor self, *, int correction=1, Tensor? fweights=None, Tensor? aweights=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cov</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">correction</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">fweights</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">aweights</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cov</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">fweights</span><span class="p">,</span> <span class="n">aweights</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::corrcoef(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">corrcoef</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">corrcoef</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_affine_grid_generator(Tensor theta, int N, int C, int H, int W) -&gt; Tensor grid</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_affine_grid_generator</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">theta</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">C</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">H</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">W</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_affine_grid_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_affine_grid_generator_backward(Tensor grad, int N, int C, int H, int W) -&gt; Tensor grad_theta</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_affine_grid_generator_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">C</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">H</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">W</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_affine_grid_generator_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_batch_norm(Tensor input, Tensor weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float exponential_average_factor, float epsilon) -&gt; (Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">cudnn_batch_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="p">,</span> <span class="kt">double</span> <span class="n">exponential_average_factor</span><span class="p">,</span> <span class="kt">double</span> <span class="n">epsilon</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_batch_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">exponential_average_factor</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_batch_norm_backward(Tensor input, Tensor grad_output, Tensor weight, Tensor? running_mean, Tensor? running_var, Tensor? save_mean, Tensor? save_var, float epsilon, Tensor reserveSpace) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">cudnn_batch_norm_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">save_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">save_var</span><span class="p">,</span> <span class="kt">double</span> <span class="n">epsilon</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reserveSpace</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_batch_norm_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">save_mean</span><span class="p">,</span> <span class="n">save_var</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">reserveSpace</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution.deprecated(Tensor self, Tensor weight, Tensor? bias, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_deprecated</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution.deprecated2(Tensor self, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_deprecated2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution(Tensor self, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool allow_tf32) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_backward_input(int[] self_size, Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool allow_tf32) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution_backward_input</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">self_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_backward_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_backward(Tensor self, Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool allow_tf32, bool[2] output_mask) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">cudnn_convolution_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">2</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_backward_weight(int[] weight_size, Tensor grad_output, Tensor self, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool allow_tf32) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution_backward_weight</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">weight_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_backward_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_transpose.deprecated(Tensor self, Tensor weight, Tensor? bias, int[] padding, int[] output_padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution_transpose</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_transpose_deprecated</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_transpose.deprecated2(Tensor self, Tensor weight, int[] padding, int[] output_padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution_transpose</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_transpose_deprecated2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_transpose(Tensor self, Tensor weight, int[] padding, int[] output_padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool allow_tf32) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution_transpose</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_transpose</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_transpose_backward(Tensor self, Tensor grad_output, Tensor weight, int[] padding, int[] output_padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool allow_tf32, bool[2] output_mask) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">cudnn_convolution_transpose_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">2</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_transpose_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_transpose_backward_input(Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool allow_tf32) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution_transpose_backward_input</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_transpose_backward_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_transpose_backward_weight(int[] weight_size, Tensor grad_output, Tensor self, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool allow_tf32) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution_transpose_backward_weight</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">weight_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">allow_tf32</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_transpose_backward_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">allow_tf32</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_relu(Tensor self, Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, int groups) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution_relu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_relu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_convolution_add_relu(Tensor self, Tensor weight, Tensor z, Scalar? alpha, Tensor? bias, int[] stride, int[] padding, int[] dilation, int groups) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_convolution_add_relu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">z</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_convolution_add_relu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_grid_sampler(Tensor self, Tensor grid) -&gt; Tensor output</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cudnn_grid_sampler</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grid</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_grid_sampler</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grid</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cudnn_grid_sampler_backward(Tensor self, Tensor grid, Tensor grad_output) -&gt; (Tensor grad_self, Tensor grad_grid)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">cudnn_grid_sampler_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grid</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cudnn_grid_sampler_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummax(Tensor self, int dim) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">cummax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummax.out(Tensor self, int dim, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">cummax_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummax_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummax.out(Tensor self, int dim, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">cummax_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummax_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummax.dimname(Tensor self, Dimname dim) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">cummax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummax_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummax.dimname_out(Tensor self, Dimname dim, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">cummax_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummax_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummax.dimname_out(Tensor self, Dimname dim, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">cummax_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummax_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cummax_helper(Tensor self, Tensor(a!) values, Tensor(b!) indices, int dim) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_cummax_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cummax_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummin(Tensor self, int dim) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">cummin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummin.out(Tensor self, int dim, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">cummin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummin.out(Tensor self, int dim, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">cummin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummin.dimname(Tensor self, Dimname dim) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">cummin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummin_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummin.dimname_out(Tensor self, Dimname dim, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">cummin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummin_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummin.dimname_out(Tensor self, Dimname dim, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">cummin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummin_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cummin_helper(Tensor self, Tensor(a!) values, Tensor(b!) indices, int dim) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_cummin_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cummin_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummaxmin_backward(Tensor grad, Tensor input, Tensor indices, int dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cummaxmin_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummaxmin_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod(Tensor self, int dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cumprod</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod.out(Tensor self, int dim, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cumprod_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod.out(Tensor self, int dim, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cumprod_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cumprod</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod.dimname_out(Tensor self, Dimname dim, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cumprod_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod.dimname_out(Tensor self, Dimname dim, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cumprod_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod_backward(Tensor grad, Tensor input, int dim, Tensor output) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cumprod_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">output</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum(Tensor self, int dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cumsum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum.out(Tensor self, int dim, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cumsum_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum.out(Tensor self, int dim, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cumsum_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cumsum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum.dimname_out(Tensor self, Dimname dim, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cumsum_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum.dimname_out(Tensor self, Dimname dim, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cumsum_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ctc_loss.IntList(Tensor log_probs, Tensor targets, int[] input_lengths, int[] target_lengths, int blank=0, int reduction=Mean, bool zero_infinity=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ctc_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_probs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">targets</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">zero_infinity</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ctc_loss_IntList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">zero_infinity</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ctc_loss.Tensor(Tensor log_probs, Tensor targets, Tensor input_lengths, Tensor target_lengths, int blank=0, int reduction=Mean, bool zero_infinity=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ctc_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_probs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">targets</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">zero_infinity</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ctc_loss_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">zero_infinity</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_ctc_loss(Tensor log_probs, Tensor targets, int[] input_lengths, int[] target_lengths, int blank=0, bool zero_infinity=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_ctc_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_probs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">targets</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">zero_infinity</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_ctc_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="p">,</span> <span class="n">zero_infinity</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_ctc_loss_backward(Tensor grad, Tensor log_probs, Tensor targets, int[] input_lengths, int[] target_lengths, Tensor neg_log_likelihood, Tensor log_alpha, int blank, bool zero_infinity=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_ctc_loss_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_probs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">targets</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">neg_log_likelihood</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_alpha</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">blank</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">zero_infinity</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_ctc_loss_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">neg_log_likelihood</span><span class="p">,</span> <span class="n">log_alpha</span><span class="p">,</span> <span class="n">blank</span><span class="p">,</span> <span class="n">zero_infinity</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diag_embed(Tensor self, int offset=0, int dim1=-2, int dim2=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">diag_embed</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">-2</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diag_embed</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diagflat(Tensor self, int offset=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">diagflat</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diagflat</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diagonal(Tensor(a) self, int offset=0, int dim1=0, int dim2=1) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">diagonal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diagonal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diagonal.Dimname(Tensor(a) self, *, Dimname outdim, Dimname dim1, Dimname dim2, int offset=0) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">diagonal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">outdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim2</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diagonal_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outdim</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="n">offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diagonal_backward(Tensor grad, int[] input_sizes, int offset, int dim1, int dim2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">diagonal_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">offset</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diagonal_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diff(Tensor self, int n=1, int dim=-1, Tensor? prepend=None, Tensor? append=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">diff</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">prepend</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">append</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diff</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">prepend</span><span class="p">,</span> <span class="n">append</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diff.out(Tensor self, int n=1, int dim=-1, Tensor? prepend=None, Tensor? append=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">diff_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">prepend</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">append</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diff_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">prepend</span><span class="p">,</span> <span class="n">append</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diff.out(Tensor self, int n=1, int dim=-1, Tensor? prepend=None, Tensor? append=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">diff_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">prepend</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">append</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diff_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">prepend</span><span class="p">,</span> <span class="n">append</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gradient.scalarint(Tensor self, *, Scalar? spacing=None, int? dim=None, int edge_order=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">gradient</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">spacing</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">edge_order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gradient_scalarint</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">edge_order</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gradient.scalararray(Tensor self, *, Scalar spacing, int[] dim, int edge_order=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">gradient</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">edge_order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gradient_scalararray</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">edge_order</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gradient.array(Tensor self, *, int[] dim, int edge_order=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">gradient</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">edge_order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gradient_array</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">edge_order</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gradient.scalarrayint(Tensor self, *, Scalar[] spacing, int? dim=None, int edge_order=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">gradient</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">edge_order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gradient_scalarrayint</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">edge_order</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gradient.scalarrayarray(Tensor self, *, Scalar[] spacing, int[] dim, int edge_order=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">gradient</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">edge_order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gradient_scalarrayarray</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">edge_order</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gradient.tensorarrayint(Tensor self, *, Tensor[] spacing, int? dim=None, int edge_order=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">gradient</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">edge_order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gradient_tensorarrayint</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">edge_order</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gradient.tensorarray(Tensor self, *, Tensor[] spacing, int[] dim, int edge_order=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">gradient</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">edge_order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gradient_tensorarray</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">edge_order</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">div</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">div_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">div_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">div</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">rounding_mode</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_Tensor_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.out_mode(Tensor self, Tensor other, *, str? rounding_mode, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">div_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">rounding_mode</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_out_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.out_mode(Tensor self, Tensor other, *, str? rounding_mode, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">div_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">rounding_mode</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_out_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">div</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">div</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">rounding_mode</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_Scalar_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">divide</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">divide_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">divide_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">divide</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">divide</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">rounding_mode</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_Tensor_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.out_mode(Tensor self, Tensor other, *, str? rounding_mode, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">divide_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">rounding_mode</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_out_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.out_mode(Tensor self, Tensor other, *, str? rounding_mode, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">divide_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">rounding_mode</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_out_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">divide</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">rounding_mode</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_Scalar_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::true_divide.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">true_divide</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">true_divide_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::true_divide.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">true_divide_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">true_divide_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::true_divide.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">true_divide_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">true_divide_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::true_divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">true_divide</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">true_divide_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dot(Tensor self, Tensor tensor) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">dot</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dot</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dot.out(Tensor self, Tensor tensor, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dot_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dot.out(Tensor self, Tensor tensor, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dot_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vdot(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">vdot</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vdot</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vdot.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vdot_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vdot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vdot.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vdot_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vdot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::einsum(str equation, Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">einsum</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">equation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">einsum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">equation</span><span class="p">,</span> <span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::embedding(Tensor weight, Tensor indices, int padding_idx=-1, bool scale_grad_by_freq=False, bool sparse=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">embedding</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">embedding</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">sparse</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::embedding_backward(Tensor grad, Tensor indices, int num_weights, int padding_idx, bool scale_grad_by_freq, bool sparse) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">embedding_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_weights</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">embedding_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_weights</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">sparse</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::embedding_dense_backward(Tensor grad_output, Tensor indices, int num_weights, int padding_idx, bool scale_grad_by_freq) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">embedding_dense_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_weights</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">embedding_dense_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_weights</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::embedding_renorm_(Tensor(a!) self, Tensor indices, float max_norm, float norm_type) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">embedding_renorm_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="kt">double</span> <span class="n">max_norm</span><span class="p">,</span> <span class="kt">double</span> <span class="n">norm_type</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">embedding_renorm_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">max_norm</span><span class="p">,</span> <span class="n">norm_type</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::embedding_sparse_backward(Tensor grad, Tensor indices, int num_weights, int padding_idx, bool scale_grad_by_freq) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">embedding_sparse_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_weights</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">embedding_sparse_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_weights</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_embedding_bag_forward_only(Tensor weight, Tensor indices, Tensor offsets, bool scale_grad_by_freq=False, int mode=0, bool sparse=False, Tensor? per_sample_weights=None, bool include_last_offset=False, int padding_idx=-1) -&gt; (Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_embedding_bag_forward_only</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offsets</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">per_sample_weights</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">include_last_offset</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_embedding_bag_forward_only</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">sparse</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="n">include_last_offset</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_rowwise_prune(Tensor weight, Tensor mask, ScalarType compressed_indices_dtype) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_rowwise_prune</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">compressed_indices_dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_rowwise_prune</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">compressed_indices_dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::row_stack(Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">row_stack</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">row_stack</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::row_stack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">row_stack_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">row_stack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::row_stack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">row_stack_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">row_stack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::embedding_bag(Tensor weight, Tensor indices, Tensor offsets, bool scale_grad_by_freq=False, int mode=0, bool sparse=False, Tensor? per_sample_weights=None, bool include_last_offset=False) -&gt; (Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">embedding_bag</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offsets</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">per_sample_weights</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">include_last_offset</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">embedding_bag</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">sparse</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="n">include_last_offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::embedding_bag.padding_idx(Tensor weight, Tensor indices, Tensor offsets, bool scale_grad_by_freq, int mode, bool sparse, Tensor? per_sample_weights, bool include_last_offset, int? padding_idx) -&gt; (Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">embedding_bag</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offsets</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">include_last_offset</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">padding_idx</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">embedding_bag_padding_idx</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">sparse</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="n">include_last_offset</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_embedding_bag(Tensor weight, Tensor indices, Tensor offsets, bool scale_grad_by_freq=False, int mode=0, bool sparse=False, Tensor? per_sample_weights=None, bool include_last_offset=False, int padding_idx=-1) -&gt; (Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_embedding_bag</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offsets</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">per_sample_weights</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">include_last_offset</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_embedding_bag</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">sparse</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="n">include_last_offset</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_embedding_bag_backward(Tensor grad, Tensor indices, Tensor offsets, Tensor offset2bag, Tensor bag_size, Tensor maximum_indices, int num_weights, bool scale_grad_by_freq, int mode, bool sparse, Tensor? per_sample_weights, int padding_idx=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_embedding_bag_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offsets</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offset2bag</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bag_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">maximum_indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_weights</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_embedding_bag_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">offset2bag</span><span class="p">,</span> <span class="n">bag_size</span><span class="p">,</span> <span class="n">maximum_indices</span><span class="p">,</span> <span class="n">num_weights</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">sparse</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_embedding_bag_sparse_backward(Tensor grad, Tensor indices, Tensor offsets, Tensor offset2bag, Tensor bag_size, int num_weights, bool scale_grad_by_freq, int mode, Tensor? per_sample_weights, int padding_idx=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_embedding_bag_sparse_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offsets</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offset2bag</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bag_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_weights</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_embedding_bag_sparse_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">offset2bag</span><span class="p">,</span> <span class="n">bag_size</span><span class="p">,</span> <span class="n">num_weights</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_embedding_bag_dense_backward(Tensor grad, Tensor indices, Tensor offset2bag, Tensor bag_size, Tensor maximum_indices, int num_weights, bool scale_grad_by_freq, int mode, Tensor? per_sample_weights, int padding_idx=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_embedding_bag_dense_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offset2bag</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bag_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">maximum_indices</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_weights</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_embedding_bag_dense_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offset2bag</span><span class="p">,</span> <span class="n">bag_size</span><span class="p">,</span> <span class="n">maximum_indices</span><span class="p">,</span> <span class="n">num_weights</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_embedding_bag_per_sample_weights_backward(Tensor grad, Tensor weight, Tensor indices, Tensor offsets, Tensor offset2bag, int mode, int padding_idx=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_embedding_bag_per_sample_weights_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offsets</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">offset2bag</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_embedding_bag_per_sample_weights_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">offset2bag</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::empty.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::empty.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::empty.memory_format(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_memory_format</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::empty.memory_format(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_memory_format</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_empty_affine_quantized(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, float scale=1, int zero_point=0, MemoryFormat? memory_format=contiguous_format) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_empty_affine_quantized</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="kt">double</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">zero_point</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">MemoryFormat</span><span class="o">::</span><span class="n">Contiguous</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_empty_affine_quantized</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_empty_affine_quantized(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, float scale=1, int zero_point=0, MemoryFormat? memory_format=contiguous_format) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_empty_affine_quantized</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="kt">double</span> <span class="n">scale</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_empty_affine_quantized</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_empty_per_channel_affine_quantized(int[] size, *, Tensor scales, Tensor zero_points, int axis, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=contiguous_format) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_empty_per_channel_affine_quantized</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scales</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_points</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">MemoryFormat</span><span class="o">::</span><span class="n">Contiguous</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_empty_per_channel_affine_quantized</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">zero_points</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_empty_per_channel_affine_quantized(int[] size, *, Tensor scales, Tensor zero_points, int axis, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=contiguous_format) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_empty_per_channel_affine_quantized</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scales</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_points</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_empty_per_channel_affine_quantized</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">zero_points</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::empty_quantized(int[] size, Tensor qtensor, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty_quantized</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">qtensor</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_quantized</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">qtensor</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::empty_quantized(int[] size, Tensor qtensor, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty_quantized</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">qtensor</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_quantized</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">qtensor</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::empty.out(int[] size, *, MemoryFormat? memory_format=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">empty_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::empty.out(int[] size, *, MemoryFormat? memory_format=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">empty_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::empty_strided(int[] size, int[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty_strided</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_strided</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::empty_strided(int[] size, int[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">empty_strided</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">empty_strided</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erf(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">erf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erf_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">erf_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erf_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erf.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">erf_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erf_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erf.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">erf_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erf_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erfc(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">erfc</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erfc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">erfc_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfc_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erfc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">erfc_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erfc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">erfc_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::exp(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">exp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::exp_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exp_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::exp.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::exp.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::exp2(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">exp2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::exp2_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exp2_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp2_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::exp2.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exp2_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::exp2.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exp2_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::expm1(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">expm1</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">expm1</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::expm1_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">expm1_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">expm1_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::expm1.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">expm1_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">expm1_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::expm1.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">expm1_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">expm1_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eye(int n, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">eye</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eye</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::eye(int n, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">eye</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eye</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eye.m(int n, int m, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">eye</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">m</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eye_m</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::eye.m(int n, int m, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">eye</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">m</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eye_m</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eye.out(int n, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eye_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eye_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eye.out(int n, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eye_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eye_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eye.m_out(int n, int m, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eye_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">m</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eye_m_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eye.m_out(int n, int m, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eye_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">m</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eye_m_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flatten.using_ints(Tensor(a) self, int start_dim=0, int end_dim=-1) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">flatten</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">end_dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flatten_using_ints</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">start_dim</span><span class="p">,</span> <span class="n">end_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flatten.named_out_dim(Tensor(a) self, int start_dim, int end_dim, Dimname out_dim) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">flatten</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">start_dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">end_dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">out_dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flatten_named_out_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">start_dim</span><span class="p">,</span> <span class="n">end_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flatten.using_names(Tensor(a) self, Dimname start_dim, Dimname end_dim, Dimname out_dim) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">flatten</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">start_dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">end_dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">out_dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flatten_using_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">start_dim</span><span class="p">,</span> <span class="n">end_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flatten.DimnameList(Tensor(a) self, Dimname[] dims, Dimname out_dim) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">flatten</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dims</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">out_dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flatten_DimnameList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fill_.Scalar(Tensor(a!) self, Scalar value) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fill_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fill__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fill_.Tensor(Tensor(a!) self, Tensor value) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fill_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fill__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">floor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">floor_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">floor_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">floor_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor_divide(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">floor_divide</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_divide</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor_divide.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">floor_divide_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_divide_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor_divide.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">floor_divide_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_divide_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor_divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">floor_divide</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_divide_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frac(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">frac</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frac</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frac_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">frac_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frac_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frac.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">frac_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frac_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frac.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">frac_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frac_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::full.names(int[] size, Scalar fill_value, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">full</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">full_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::full.names(int[] size, Scalar fill_value, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">full</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">full_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::full(int[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">full</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">full</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::full(int[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">full</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">full</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::full.out(int[] size, Scalar fill_value, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">full_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">fill_value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">full_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::full.out(int[] size, Scalar fill_value, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">full_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">full_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::full_like(Tensor self, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">full_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">full_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::full_like(Tensor self, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">full_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">full_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::from_file(str filename, bool? shared=None, int? size=0, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">from_file</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">filename</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">shared</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">from_file</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">shared</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::from_file(str filename, bool? shared=None, int? size=0, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">from_file</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">filename</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">shared</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">from_file</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">shared</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gcd.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gcd_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gcd_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gcd.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gcd_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gcd_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gcd(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">gcd</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gcd</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gcd_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gcd_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gcd_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lcm.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lcm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lcm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lcm.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lcm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lcm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lcm(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">lcm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lcm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lcm_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lcm_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lcm_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::grid_sampler(Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">grid_sampler</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grid</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">grid_sampler</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::grid_sampler_2d(Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">grid_sampler_2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grid</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">grid_sampler_2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::grid_sampler_2d_backward(Tensor grad_output, Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">grid_sampler_2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grid</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">grid_sampler_2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_grid_sampler_2d_cpu_fallback(Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_grid_sampler_2d_cpu_fallback</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grid</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_grid_sampler_2d_cpu_fallback</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_grid_sampler_2d_cpu_fallback_backward(Tensor grad_output, Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_grid_sampler_2d_cpu_fallback_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grid</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_grid_sampler_2d_cpu_fallback_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::grid_sampler_3d(Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">grid_sampler_3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grid</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">grid_sampler_3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::grid_sampler_3d_backward(Tensor grad_output, Tensor input, Tensor grid, int interpolation_mode, int padding_mode, bool align_corners) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">grid_sampler_3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grid</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">grid_sampler_3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hann_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hann_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hann_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::hann_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hann_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hann_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hann_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hann_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hann_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::hann_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hann_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hann_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hamming_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hamming_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hamming_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::hamming_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hamming_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hamming_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hamming_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hamming_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hamming_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::hamming_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hamming_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hamming_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hamming_window.periodic_alpha(int window_length, bool periodic, float alpha, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hamming_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="kt">double</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hamming_window_periodic_alpha</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::hamming_window.periodic_alpha(int window_length, bool periodic, float alpha, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hamming_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="kt">double</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hamming_window_periodic_alpha</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hamming_window.periodic_alpha_beta(int window_length, bool periodic, float alpha, float beta, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hamming_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="kt">double</span> <span class="n">alpha</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hamming_window_periodic_alpha_beta</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::hamming_window.periodic_alpha_beta(int window_length, bool periodic, float alpha, float beta, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hamming_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="kt">double</span> <span class="n">alpha</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hamming_window_periodic_alpha_beta</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kaiser_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">kaiser_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kaiser_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::kaiser_window(int window_length, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">kaiser_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kaiser_window</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kaiser_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">kaiser_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kaiser_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::kaiser_window.periodic(int window_length, bool periodic, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">kaiser_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kaiser_window_periodic</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kaiser_window.beta(int window_length, bool periodic, float beta, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">kaiser_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kaiser_window_beta</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::kaiser_window.beta(int window_length, bool periodic, float beta, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">kaiser_window</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">window_length</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">periodic</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kaiser_window_beta</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">periodic</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hinge_embedding_loss(Tensor self, Tensor target, float margin=1.0, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hinge_embedding_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">double</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hinge_embedding_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::group_norm(Tensor input, int num_groups, Tensor? weight=None, Tensor? bias=None, float eps=1e-05, bool cudnn_enabled=True) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">group_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_groups</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="kt">double</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">cudnn_enabled</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">group_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">num_groups</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_group_norm(Tensor input, Tensor? weight, Tensor? bias, int N, int C, int HxW, int group, float eps) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">native_group_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">C</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">HxW</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">group</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_group_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">HxW</span><span class="p">,</span> <span class="n">group</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_group_norm_backward(Tensor grad_out, Tensor input, Tensor mean, Tensor rstd, Tensor? weight, int N, int C, int HxW, int group, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">native_group_norm_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rstd</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">C</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">HxW</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">group</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_group_norm_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_out</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">rstd</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">HxW</span><span class="p">,</span> <span class="n">group</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fft_r2c(Tensor self, int[] dim, int normalization, bool onesided) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_fft_r2c</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">normalization</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">onesided</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fft_r2c</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="n">onesided</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fft_r2c.out(Tensor self, int[] dim, int normalization, bool onesided, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_fft_r2c_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">normalization</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">onesided</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fft_r2c_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="n">onesided</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fft_r2c.out(Tensor self, int[] dim, int normalization, bool onesided, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_fft_r2c_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">normalization</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">onesided</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fft_r2c_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="n">onesided</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fft_c2r(Tensor self, int[] dim, int normalization, int last_dim_size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_fft_c2r</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">normalization</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">last_dim_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fft_c2r</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="n">last_dim_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fft_c2r.out(Tensor self, int[] dim, int normalization, int last_dim_size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_fft_c2r_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">normalization</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">last_dim_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fft_c2r_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="n">last_dim_size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fft_c2r.out(Tensor self, int[] dim, int normalization, int last_dim_size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_fft_c2r_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">normalization</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">last_dim_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fft_c2r_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="n">last_dim_size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fft_c2c(Tensor self, int[] dim, int normalization, bool forward) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_fft_c2c</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">normalization</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">forward</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fft_c2c</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="n">forward</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fft_c2c.out(Tensor self, int[] dim, int normalization, bool forward, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_fft_c2c_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">normalization</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">forward</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fft_c2c_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="n">forward</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fft_c2c.out(Tensor self, int[] dim, int normalization, bool forward, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_fft_c2c_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">normalization</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">forward</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fft_c2c_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">normalization</span><span class="p">,</span> <span class="n">forward</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cufft_get_plan_cache_size(int device_index) -&gt; int</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">_cufft_get_plan_cache_size</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">device_index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cufft_get_plan_cache_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">device_index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cufft_get_plan_cache_max_size(int device_index) -&gt; int</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">_cufft_get_plan_cache_max_size</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">device_index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cufft_get_plan_cache_max_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">device_index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cufft_set_plan_cache_max_size(int device_index, int max_size) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_cufft_set_plan_cache_max_size</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">device_index</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">max_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cufft_set_plan_cache_max_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">device_index</span><span class="p">,</span> <span class="n">max_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cufft_clear_plan_cache(int device_index) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_cufft_clear_plan_cache</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">device_index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cufft_clear_plan_cache</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">device_index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index.Tensor(Tensor self, Tensor?[] indices) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_copy(Tensor self, int dim, Tensor index, Tensor source) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_copy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">source</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_copy</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_copy.dimname(Tensor self, Dimname dim, Tensor index, Tensor source) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_copy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">source</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_copy_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index_put_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">accumulate</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_put_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">accumulate</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_put(Tensor self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_put</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">accumulate</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_put</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">accumulate</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_index_put_impl_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">accumulate</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unsafe</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_index_put_impl_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">accumulate</span><span class="p">,</span> <span class="n">unsafe</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::instance_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool use_input_stats, float momentum, float eps, bool cudnn_enabled) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">instance_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">use_input_stats</span><span class="p">,</span> <span class="kt">double</span> <span class="n">momentum</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">cudnn_enabled</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">instance_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">use_input_stats</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::inverse(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">inverse</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">inverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::inverse.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">inverse_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">inverse_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::inverse.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">inverse_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">inverse_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_inverse_helper(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_inverse_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_inverse_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isclose</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="kt">double</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="kt">double</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">equal_nan</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isclose</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="p">,</span> <span class="n">equal_nan</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isin.Tensor_Tensor_out(Tensor elements, Tensor test_elements, *, bool assume_unique=False, bool invert=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elements</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">test_elements</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">assume_unique</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">invert</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isin_Tensor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">test_elements</span><span class="p">,</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="n">invert</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isin.Tensor_Tensor_out(Tensor elements, Tensor test_elements, *, bool assume_unique=False, bool invert=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elements</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">test_elements</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">invert</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isin_Tensor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">test_elements</span><span class="p">,</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="n">invert</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isin.Tensor_Tensor(Tensor elements, Tensor test_elements, *, bool assume_unique=False, bool invert=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elements</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">test_elements</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">assume_unique</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">invert</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isin_Tensor_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">test_elements</span><span class="p">,</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="n">invert</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isin.Tensor_Scalar_out(Tensor elements, Scalar test_element, *, bool assume_unique=False, bool invert=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elements</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">test_element</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">assume_unique</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">invert</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isin_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">test_element</span><span class="p">,</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="n">invert</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isin.Tensor_Scalar_out(Tensor elements, Scalar test_element, *, bool assume_unique=False, bool invert=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elements</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">test_element</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">invert</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isin_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">test_element</span><span class="p">,</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="n">invert</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isin.Tensor_Scalar(Tensor elements, Scalar test_element, *, bool assume_unique=False, bool invert=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elements</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">test_element</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">assume_unique</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">invert</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isin_Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">test_element</span><span class="p">,</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="n">invert</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isin.Scalar_Tensor_out(Scalar element, Tensor test_elements, *, bool assume_unique=False, bool invert=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">element</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">test_elements</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">assume_unique</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">invert</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isin_Scalar_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="n">test_elements</span><span class="p">,</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="n">invert</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isin.Scalar_Tensor_out(Scalar element, Tensor test_elements, *, bool assume_unique=False, bool invert=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">element</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">test_elements</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">invert</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isin_Scalar_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="n">test_elements</span><span class="p">,</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="n">invert</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isin.Scalar_Tensor(Scalar element, Tensor test_elements, *, bool assume_unique=False, bool invert=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">element</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">test_elements</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">assume_unique</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">invert</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isin_Scalar_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="n">test_elements</span><span class="p">,</span> <span class="n">assume_unique</span><span class="p">,</span> <span class="n">invert</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isnan(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isnan</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isnan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_distributed(Tensor self) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_distributed</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_distributed</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_floating_point(Tensor self) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">__dispatch_is_floating_point</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_floating_point</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_complex(Tensor self) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">__dispatch_is_complex</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_complex</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_conj(Tensor self) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">__dispatch_is_conj</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_conj</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_neg(Tensor self) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">__dispatch_is_neg</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_neg</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isreal(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isreal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isreal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_nonzero(Tensor self) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_nonzero</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_nonzero</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_same_size(Tensor self, Tensor other) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_same_size</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_same_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_signed(Tensor self) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">__dispatch_is_signed</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_signed</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_inference(Tensor self) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">__dispatch_is_inference</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_inference</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kl_div(Tensor self, Tensor target, int reduction=Mean, *, bool log_target=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">kl_div</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">log_target</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kl_div</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">log_target</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kl_div_backward(Tensor grad_output, Tensor self, Tensor target, int reduction=Mean, *, bool log_target=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">kl_div_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">log_target</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kl_div_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">log_target</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kron(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">kron</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kron</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kron.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">kron_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kron_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kron.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">kron_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kron_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue(Tensor self, int k, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">kthvalue</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue.values(Tensor self, int k, int dim=-1, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">kthvalue_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue.values(Tensor self, int k, int dim=-1, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">kthvalue_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue.dimname(Tensor self, int k, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">kthvalue</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue.dimname_out(Tensor self, int k, Dimname dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">kthvalue_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue.dimname_out(Tensor self, int k, Dimname dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">kthvalue_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::layer_norm(Tensor input, int[] normalized_shape, Tensor? weight=None, Tensor? bias=None, float eps=1e-05, bool cudnn_enable=True) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">layer_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="kt">double</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">cudnn_enable</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">layer_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">cudnn_enable</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_layer_norm(Tensor input, int[] normalized_shape, Tensor? weight, Tensor? bias, float eps) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">native_layer_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_layer_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_layer_norm_backward(Tensor grad_out, Tensor input, int[] normalized_shape, Tensor mean, Tensor rstd, Tensor? weight, Tensor? bias, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">native_layer_norm_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rstd</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_layer_norm_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_out</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">rstd</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nan_to_num(Tensor self, float? nan=None, float? posinf=None, float? neginf=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nan_to_num</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">nan</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">posinf</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">neginf</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nan_to_num</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">nan</span><span class="p">,</span> <span class="n">posinf</span><span class="p">,</span> <span class="n">neginf</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nan_to_num_(Tensor(a!) self, float? nan=None, float? posinf=None, float? neginf=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nan_to_num_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">nan</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">posinf</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">neginf</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nan_to_num_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">nan</span><span class="p">,</span> <span class="n">posinf</span><span class="p">,</span> <span class="n">neginf</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nan_to_num.out(Tensor self, float? nan=None, float? posinf=None, float? neginf=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nan_to_num_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">nan</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">posinf</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">neginf</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nan_to_num_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">nan</span><span class="p">,</span> <span class="n">posinf</span><span class="p">,</span> <span class="n">neginf</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nan_to_num.out(Tensor self, float? nan=None, float? posinf=None, float? neginf=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nan_to_num_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">nan</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">posinf</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">neginf</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nan_to_num_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">nan</span><span class="p">,</span> <span class="n">posinf</span><span class="p">,</span> <span class="n">neginf</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linear(Tensor input, Tensor weight, Tensor? bias=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linear</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linear</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_linear(Tensor self, Tensor weight, Tensor? bias=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_linear</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_linear</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_linear_backward_input(int[] input_size, Tensor grad_output, Tensor weight) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_linear_backward_input</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_linear_backward_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_linear_backward_weights(Tensor grad_output, Tensor input, Tensor weight, bool bias_defined) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">mkldnn_linear_backward_weights</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bias_defined</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_linear_backward_weights</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias_defined</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_linear_backward(Tensor self, Tensor grad_output, Tensor weight, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">mkldnn_linear_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_linear_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fbgemm_linear_int8_weight_fp32_activation(Tensor input, Tensor weight, Tensor packed, Tensor col_offsets, Scalar weight_scale, Scalar weight_zero_point, Tensor bias) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fbgemm_linear_int8_weight_fp32_activation</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">weight_scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">weight_zero_point</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fbgemm_linear_int8_weight_fp32_activation</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">packed</span><span class="p">,</span> <span class="n">col_offsets</span><span class="p">,</span> <span class="n">weight_scale</span><span class="p">,</span> <span class="n">weight_zero_point</span><span class="p">,</span> <span class="n">bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fbgemm_linear_int8_weight(Tensor input, Tensor weight, Tensor packed, Tensor col_offsets, Scalar weight_scale, Scalar weight_zero_point, Tensor bias) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fbgemm_linear_int8_weight</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">weight_scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">weight_zero_point</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fbgemm_linear_int8_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">packed</span><span class="p">,</span> <span class="n">col_offsets</span><span class="p">,</span> <span class="n">weight_scale</span><span class="p">,</span> <span class="n">weight_zero_point</span><span class="p">,</span> <span class="n">bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fbgemm_linear_quantize_weight(Tensor input) -&gt; (Tensor, Tensor, float, int)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="kt">double</span><span class="p">,</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">fbgemm_linear_quantize_weight</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fbgemm_linear_quantize_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fbgemm_pack_gemm_matrix_fp16(Tensor input) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fbgemm_pack_gemm_matrix_fp16</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fbgemm_pack_gemm_matrix_fp16</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fbgemm_linear_fp16_weight_fp32_activation(Tensor input, Tensor packed_weight, Tensor bias) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fbgemm_linear_fp16_weight_fp32_activation</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fbgemm_linear_fp16_weight_fp32_activation</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">packed_weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fbgemm_linear_fp16_weight(Tensor input, Tensor packed_weight, Tensor bias) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fbgemm_linear_fp16_weight</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fbgemm_linear_fp16_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">packed_weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fbgemm_pack_quantized_matrix(Tensor input) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fbgemm_pack_quantized_matrix</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fbgemm_pack_quantized_matrix</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fbgemm_pack_quantized_matrix.KN(Tensor input, int K, int N) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fbgemm_pack_quantized_matrix</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">K</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fbgemm_pack_quantized_matrix_KN</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ldexp.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ldexp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ldexp_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ldexp_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ldexp_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ldexp_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ldexp.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ldexp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ldexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ldexp.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ldexp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ldexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linspace(Scalar start, Scalar end, int? steps=None, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linspace</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">steps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linspace</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::linspace(Scalar start, Scalar end, int? steps=None, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linspace</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">steps</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linspace</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linspace.out(Scalar start, Scalar end, int? steps=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linspace_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">steps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linspace_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linspace.out(Scalar start, Scalar end, int? steps=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linspace_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">steps</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linspace_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">log</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log10(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">log10</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log10</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log10_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log10_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log10_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log10.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log10_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log10_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log10.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log10_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log10_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log1p(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">log1p</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log1p</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log1p_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log1p_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log1p_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log1p.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log1p_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log1p_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log1p.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log1p_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log1p_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log2(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">log2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log2_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log2_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log2_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log2.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log2_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log2.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log2_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logaddexp.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logaddexp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logaddexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logaddexp.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logaddexp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logaddexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logaddexp(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logaddexp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logaddexp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logaddexp2.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logaddexp2_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logaddexp2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logaddexp2.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logaddexp2_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logaddexp2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logaddexp2(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logaddexp2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logaddexp2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">xlogy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.Scalar_Self(Scalar self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">xlogy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_Scalar_Self</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.Scalar_Other(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">xlogy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_Scalar_Other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">xlogy_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy_.Scalar_Other(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">xlogy_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy__Scalar_Other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.OutTensor(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">xlogy_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_OutTensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.OutTensor(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">xlogy_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_OutTensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.OutScalar_Self(Scalar self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">xlogy_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_OutScalar_Self</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.OutScalar_Self(Scalar self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">xlogy_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_OutScalar_Self</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.OutScalar_Other(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">xlogy_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_OutScalar_Other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.OutScalar_Other(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">xlogy_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_OutScalar_Other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logdet(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logdet</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logdet</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logspace(Scalar start, Scalar end, int? steps=None, float base=10.0, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logspace</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">steps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">double</span> <span class="n">base</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logspace</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::logspace(Scalar start, Scalar end, int? steps=None, float base=10.0, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logspace</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">steps</span><span class="p">,</span> <span class="kt">double</span> <span class="n">base</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logspace</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logspace.out(Scalar start, Scalar end, int? steps=None, float base=10.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logspace_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">steps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">double</span> <span class="n">base</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logspace_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logspace.out(Scalar start, Scalar end, int? steps=None, float base=10.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logspace_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">steps</span><span class="p">,</span> <span class="kt">double</span> <span class="n">base</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logspace_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">log_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_softmax_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">log_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_softmax_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_log_softmax(Tensor self, int dim, bool half_to_float) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_log_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">half_to_float</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_log_softmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">half_to_float</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_log_softmax_backward_data(Tensor grad_output, Tensor output, int dim, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_log_softmax_backward_data</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_log_softmax_backward_data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_logcumsumexp(Tensor self, int dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_logcumsumexp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_logcumsumexp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_logcumsumexp.out(Tensor self, int dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_logcumsumexp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_logcumsumexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_logcumsumexp.out(Tensor self, int dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_logcumsumexp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_logcumsumexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logcumsumexp(Tensor self, int dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logcumsumexp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logcumsumexp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logcumsumexp.out(Tensor self, int dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logcumsumexp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logcumsumexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logcumsumexp.out(Tensor self, int dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logcumsumexp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logcumsumexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logcumsumexp.dimname(Tensor self, Dimname dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logcumsumexp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logcumsumexp_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logcumsumexp.dimname_out(Tensor self, Dimname dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logcumsumexp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logcumsumexp_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logcumsumexp.dimname_out(Tensor self, Dimname dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logcumsumexp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logcumsumexp_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logsumexp(Tensor self, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logsumexp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logsumexp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logsumexp.out(Tensor self, int[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logsumexp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logsumexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logsumexp.out(Tensor self, int[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logsumexp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logsumexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logsumexp.names(Tensor self, Dimname[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logsumexp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logsumexp_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logsumexp.names_out(Tensor self, Dimname[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logsumexp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logsumexp_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logsumexp.names_out(Tensor self, Dimname[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logsumexp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logsumexp_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::margin_ranking_loss(Tensor input1, Tensor input2, Tensor target, float margin=0.0, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">margin_ranking_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">double</span> <span class="n">margin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">margin_ranking_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matmul(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">matmul</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matmul</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matmul.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">matmul_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matmul_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matmul.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">matmul_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matmul_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_rank.tol(Tensor self, float tol, bool symmetric=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">matrix_rank</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">tol</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">symmetric</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_rank_tol</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">symmetric</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_rank(Tensor self, bool symmetric=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">matrix_rank</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">symmetric</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_rank</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">symmetric</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_power(Tensor self, int n) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">matrix_power</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_power</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_power.out(Tensor self, int n, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">matrix_power_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_power_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_power.out(Tensor self, int n, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">matrix_power_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_power_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_exp(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">matrix_exp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_exp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_exp_backward(Tensor self, Tensor grad) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">matrix_exp_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_exp_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_aminmax(Tensor self) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_aminmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_aminmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_aminmax.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_aminmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_aminmax_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_compute_linear_combination(Tensor input, Tensor coefficients) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_compute_linear_combination</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">coefficients</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_compute_linear_combination</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_compute_linear_combination.out(Tensor input, Tensor coefficients, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_compute_linear_combination_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">coefficients</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_compute_linear_combination_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_compute_linear_combination.out(Tensor input, Tensor coefficients, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_compute_linear_combination_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_compute_linear_combination_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">max</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.dim_max(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) max, Tensor(b!) max_values) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">max_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_values</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_dim_max</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">max_values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.dim_max(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) max, Tensor(b!) max_values) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">max_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_values</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_dim_max</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">max_values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">max</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.names_dim_max(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) max, Tensor(b!) max_values) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">max_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_values</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_names_dim_max</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">max_values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.names_dim_max(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) max, Tensor(b!) max_values) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">max_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_values</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_names_dim_max</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">max_values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::value_selecting_reduction_backward(Tensor grad, int dim, Tensor indices, int[] sizes, bool keepdim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">value_selecting_reduction_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">sizes</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">value_selecting_reduction_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">sizes</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::amax(Tensor self, int[1] dim=[], bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">amax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">amax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::amax.out(Tensor self, int[1] dim=[], bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">amax_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">amax_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::amax.out(Tensor self, int[1] dim=[], bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">amax_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">amax_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool1d_with_indices(Tensor self, int[1] kernel_size, int[1] stride=[], int[1] padding=0, int[1] dilation=1, bool ceil_mode=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">max_pool1d_with_indices</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool1d_with_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool1d(Tensor self, int[1] kernel_size, int[1] stride=[], int[1] padding=0, int[1] dilation=1, bool ceil_mode=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max_pool1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool2d(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max_pool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_max_pool2d(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_max_pool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_max_pool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_max_pool2d_backward(Tensor grad_output, Tensor output, Tensor input, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_max_pool2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_max_pool2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_max_pool3d(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, int[3] dilation=1, bool ceil_mode=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_max_pool3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_max_pool3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_max_pool3d_backward(Tensor grad_output, Tensor output, Tensor input, int[3] kernel_size, int[3] stride=[], int[3] padding=0, int[3] dilation=1, bool ceil_mode=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_max_pool3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_max_pool3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantized_max_pool1d(Tensor self, int[1] kernel_size, int[1] stride=[], int[1] padding=0, int[1] dilation=1, bool ceil_mode=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantized_max_pool1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantized_max_pool1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantized_max_pool2d(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantized_max_pool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantized_max_pool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool3d(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, int[3] dilation=1, bool ceil_mode=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max_pool3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean.dim(Tensor self, int[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean.out(Tensor self, int[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean.out(Tensor self, int[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean.names_dim(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean.names_out(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean.names_out(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::median(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">median</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::median.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">median</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::median.dim_values(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">median_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median_dim_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::median.dim_values(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">median_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median_dim_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::median.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">median</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::median.names_dim_values(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">median_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median_names_dim_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::median.names_dim_values(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">median_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median_names_dim_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nanmedian</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">nanmedian</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian.dim_values(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">nanmedian_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian_dim_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian.dim_values(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">nanmedian_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian_dim_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">nanmedian</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian.names_dim_values(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">nanmedian_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian_names_dim_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian.names_dim_values(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">nanmedian_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian_names_dim_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">min</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.dim_min(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) min, Tensor(b!) min_indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">min_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_dim_min</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">min_indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.dim_min(Tensor self, int dim, bool keepdim=False, *, Tensor(a!) min, Tensor(b!) min_indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">min_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min_indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_dim_min</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">min_indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">min</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.names_dim_min(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) min, Tensor(b!) min_indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">min_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_names_dim_min</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">min_indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.names_dim_min(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) min, Tensor(b!) min_indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">min_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min_indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_names_dim_min</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">min_indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::amin(Tensor self, int[1] dim=[], bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">amin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">amin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::amin.out(Tensor self, int[1] dim=[], bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">amin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">amin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::amin.out(Tensor self, int[1] dim=[], bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">amin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">amin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_convolution(Tensor self, Tensor weight, Tensor? bias, int[] padding, int[] stride, int[] dilation, int groups) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_convolution</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_convolution_backward_input(int[] self_size, Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool bias_defined) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_convolution_backward_input</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">self_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bias_defined</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_convolution_backward_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">bias_defined</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_convolution_backward_weights(int[] weight_size, Tensor grad_output, Tensor self, int[] padding, int[] stride, int[] dilation, int groups, bool bias_defined) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">mkldnn_convolution_backward_weights</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">weight_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bias_defined</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_convolution_backward_weights</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">bias_defined</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_convolution_backward(Tensor self, Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">mkldnn_convolution_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_convolution_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_batch_norm(Tensor input, Tensor weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float exponential_average_factor, float epsilon) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">miopen_batch_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="p">,</span> <span class="kt">double</span> <span class="n">exponential_average_factor</span><span class="p">,</span> <span class="kt">double</span> <span class="n">epsilon</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_batch_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">exponential_average_factor</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_batch_norm_backward(Tensor input, Tensor grad_output, Tensor weight, Tensor? running_mean, Tensor? running_var, Tensor? save_mean, Tensor? save_var, float epsilon) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">miopen_batch_norm_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">save_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">save_var</span><span class="p">,</span> <span class="kt">double</span> <span class="n">epsilon</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_batch_norm_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">save_mean</span><span class="p">,</span> <span class="n">save_var</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_convolution(Tensor self, Tensor weight, Tensor? bias, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_convolution</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_convolution_backward_input(int[] self_size, Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_convolution_backward_input</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">self_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_convolution_backward_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_convolution_backward(Tensor self, Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">miopen_convolution_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_convolution_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_convolution_backward_bias(Tensor grad_output) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_convolution_backward_bias</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_convolution_backward_bias</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_convolution_backward_weight(int[] weight_size, Tensor grad_output, Tensor self, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_convolution_backward_weight</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">weight_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_convolution_backward_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_convolution_transpose(Tensor self, Tensor weight, Tensor? bias, int[] padding, int[] output_padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_convolution_transpose</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_convolution_transpose</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_convolution_transpose_backward(Tensor self, Tensor grad_output, Tensor weight, int[] padding, int[] output_padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">miopen_convolution_transpose_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_convolution_transpose_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_convolution_transpose_backward_input(Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_convolution_transpose_backward_input</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_convolution_transpose_backward_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_convolution_transpose_backward_weight(int[] weight_size, Tensor grad_output, Tensor self, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_convolution_transpose_backward_weight</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">weight_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_convolution_transpose_backward_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_depthwise_convolution(Tensor self, Tensor weight, Tensor? bias, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_depthwise_convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_depthwise_convolution</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_depthwise_convolution_backward_input(int[] self_size, Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_depthwise_convolution_backward_input</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">self_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_depthwise_convolution_backward_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_depthwise_convolution_backward(Tensor self, Tensor grad_output, Tensor weight, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">miopen_depthwise_convolution_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_depthwise_convolution_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_depthwise_convolution_backward_weight(int[] weight_size, Tensor grad_output, Tensor self, int[] padding, int[] stride, int[] dilation, int groups, bool benchmark, bool deterministic) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">miopen_depthwise_convolution_backward_weight</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">weight_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">benchmark</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">deterministic</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_depthwise_convolution_backward_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight_size</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_rnn(Tensor input, Tensor[] weight, int weight_stride0, Tensor hx, Tensor? cx, int mode, int hidden_size, int num_layers, bool batch_first, float dropout, bool train, bool bidirectional, int[] batch_sizes, Tensor? dropout_state) -&gt; (Tensor, Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">miopen_rnn</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">cx</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">dropout_state</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_rnn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">dropout_state</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::miopen_rnn_backward(Tensor input, Tensor[] weight, int weight_stride0, Tensor weight_buf, Tensor hx, Tensor? cx, Tensor output, Tensor? grad_output, Tensor? grad_hy, Tensor? grad_cy, int mode, int hidden_size, int num_layers, bool batch_first, float dropout, bool train, bool bidirectional, int[] batch_sizes, Tensor? dropout_state, Tensor reserve, bool[4] output_mask) -&gt; (Tensor, Tensor, Tensor, Tensor[])</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span> <span class="n">miopen_rnn_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight_buf</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">cx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_hy</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_cy</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">mode</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">dropout_state</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reserve</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">4</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">miopen_rnn_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="n">weight_buf</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">grad_hy</span><span class="p">,</span> <span class="n">grad_cy</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">dropout_state</span><span class="p">,</span> <span class="n">reserve</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mm.out(Tensor self, Tensor mat2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mm.out(Tensor self, Tensor mat2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_mm(Tensor sparse, Tensor dense) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_mm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sparse</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dense</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_mm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sparse</span><span class="p">,</span> <span class="n">dense</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_sparse_matmul(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_sparse_matmul</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_sparse_matmul</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_mask_helper(Tensor t, Tensor mask_indices) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_mask_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">t</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask_indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_mask_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">mask_indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mode(Tensor self, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">mode</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mode.values(Tensor self, int dim=-1, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">mode_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mode_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mode.values(Tensor self, int dim=-1, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">mode_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mode_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mode.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">mode</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mode_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mode.dimname_out(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">mode_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mode_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mode.dimname_out(Tensor self, Dimname dim, bool keepdim=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">mode_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mode_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mul.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mul</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mul_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mul.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mul_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mul_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mul.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mul_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mul_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mul.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mul</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mul_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multiply.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">multiply</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multiply_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multiply.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multiply_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multiply_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multiply.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multiply_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multiply_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multiply.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">multiply</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multiply_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mv(Tensor self, Tensor vec) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mv</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mv.out(Tensor self, Tensor vec, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mv_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mv.out(Tensor self, Tensor vec, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mv_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mvlgamma.out(Tensor self, int p, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mvlgamma_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mvlgamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mvlgamma.out(Tensor self, int p, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mvlgamma_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mvlgamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mvlgamma(Tensor self, int p) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mvlgamma</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mvlgamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow_copy(Tensor self, int dim, int start, int length) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">narrow_copy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">start</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">length</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow_copy</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow_copy.out(Tensor self, int dim, int start, int length, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">narrow_copy_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">start</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">length</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow_copy_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow_copy.out(Tensor self, int dim, int start, int length, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">narrow_copy_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">start</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">length</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow_copy_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow(Tensor(a) self, int dim, int start, int length) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">narrow</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">start</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">length</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow.Tensor(Tensor(a) self, int dim, Tensor start, int length) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">narrow</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">length</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">native_batch_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="p">,</span> <span class="kt">double</span> <span class="n">momentum</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_batch_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_batch_norm.out(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, *, Tensor(a!) out, Tensor(b!) save_mean, Tensor(c!) save_invstd) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">native_batch_norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">save_mean</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">save_invstd</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="p">,</span> <span class="kt">double</span> <span class="n">momentum</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_batch_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">save_mean</span><span class="p">,</span> <span class="n">save_invstd</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_batch_norm.out(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, *, Tensor(a!) out, Tensor(b!) save_mean, Tensor(c!) save_invstd) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">native_batch_norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="p">,</span> <span class="kt">double</span> <span class="n">momentum</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">save_mean</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">save_invstd</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_batch_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">save_mean</span><span class="p">,</span> <span class="n">save_invstd</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm_stats(Tensor input, float eps) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">batch_norm_stats</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm_stats</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm_elemt(Tensor input, Tensor? weight, Tensor? bias, Tensor mean, Tensor invstd, float eps) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">batch_norm_elemt</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">invstd</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm_elemt</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm_elemt.out(Tensor input, Tensor? weight, Tensor? bias, Tensor mean, Tensor invstd, float eps, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch_norm_elemt_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">invstd</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm_elemt_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm_elemt.out(Tensor input, Tensor? weight, Tensor? bias, Tensor mean, Tensor invstd, float eps, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch_norm_elemt_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">invstd</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm_elemt_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm_gather_stats(Tensor input, Tensor mean, Tensor invstd, Tensor? running_mean, Tensor? running_var, float momentum, float eps, int count) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">batch_norm_gather_stats</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">invstd</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">double</span> <span class="n">momentum</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">count</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm_gather_stats</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm_gather_stats_with_counts(Tensor input, Tensor mean, Tensor invstd, Tensor? running_mean, Tensor? running_var, float momentum, float eps, Tensor counts) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">batch_norm_gather_stats_with_counts</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">invstd</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">double</span> <span class="n">momentum</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">counts</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm_gather_stats_with_counts</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">counts</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_batch_norm_backward(Tensor grad_out, Tensor input, Tensor? weight, Tensor? running_mean, Tensor? running_var, Tensor? save_mean, Tensor? save_invstd, bool train, float eps, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">native_batch_norm_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">save_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">save_invstd</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_batch_norm_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_out</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">save_mean</span><span class="p">,</span> <span class="n">save_invstd</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm_backward_reduce(Tensor grad_out, Tensor input, Tensor mean, Tensor invstd, Tensor? weight, bool input_g, bool weight_g, bool bias_g) -&gt; (Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">batch_norm_backward_reduce</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">invstd</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">input_g</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">weight_g</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bias_g</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm_backward_reduce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_out</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">input_g</span><span class="p">,</span> <span class="n">weight_g</span><span class="p">,</span> <span class="n">bias_g</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm_backward_elemt(Tensor grad_out, Tensor input, Tensor mean, Tensor invstd, Tensor? weight, Tensor mean_dy, Tensor mean_dy_xmu, Tensor count) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">batch_norm_backward_elemt</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">invstd</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean_dy</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean_dy_xmu</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">count</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm_backward_elemt</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_out</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">mean_dy</span><span class="p">,</span> <span class="n">mean_dy_xmu</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::batch_norm_update_stats(Tensor input, Tensor? running_mean, Tensor? running_var, float momentum) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">batch_norm_update_stats</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">running_var</span><span class="p">,</span> <span class="kt">double</span> <span class="n">momentum</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">batch_norm_update_stats</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">momentum</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_vulkan_available() -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_vulkan_available</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_vulkan_available</span><span class="o">::</span><span class="n">call</span><span class="p">();</span>
<span class="p">}</span>

<span class="c1">// aten::_nnpack_available() -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">_nnpack_available</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_nnpack_available</span><span class="o">::</span><span class="n">call</span><span class="p">();</span>
<span class="p">}</span>

<span class="c1">// aten::_nnpack_spatial_convolution(Tensor input, Tensor weight, Tensor? bias, int[2] padding, int[2] stride=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_nnpack_spatial_convolution</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_nnpack_spatial_convolution</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_nnpack_spatial_convolution_backward(Tensor input, Tensor grad_output, Tensor weight, int[2] padding, bool[3] output_mask) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_nnpack_spatial_convolution_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_nnpack_spatial_convolution_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_nnpack_spatial_convolution_backward_input(Tensor input, Tensor grad_output, Tensor weight, int[2] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_nnpack_spatial_convolution_backward_input</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_nnpack_spatial_convolution_backward_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_nnpack_spatial_convolution_backward_weight(Tensor input, int[] weightsize, Tensor grad_output, int[2] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_nnpack_spatial_convolution_backward_weight</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">weightsize</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_nnpack_spatial_convolution_backward_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">weightsize</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ones.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ones</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ones_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::ones.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ones</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ones_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ones(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ones</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ones</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::ones(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ones</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ones</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ones.out(int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ones_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ones_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ones.out(int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ones_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ones_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ones_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ones_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ones_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::ones_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ones_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ones_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pairwise_distance(Tensor x1, Tensor x2, float p=2, float eps=1e-06, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">pairwise_distance</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x2</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pairwise_distance</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cdist(Tensor x1, Tensor x2, float p=2, int? compute_mode=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cdist</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x2</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">compute_mode</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cdist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">compute_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_euclidean_dist(Tensor x1, Tensor x2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_euclidean_dist</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_euclidean_dist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cdist_forward(Tensor x1, Tensor x2, float p, int? compute_mode) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cdist_forward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x2</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">compute_mode</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cdist_forward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">compute_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cdist_backward(Tensor grad, Tensor x1, Tensor x2, float p, Tensor cdist) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cdist_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x2</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cdist</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cdist_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">cdist</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pdist(Tensor self, float p=2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">pdist</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pdist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_pdist_forward(Tensor self, float p=2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_pdist_forward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_pdist_forward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_pdist_backward(Tensor grad, Tensor self, float p, Tensor pdist) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_pdist_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">pdist</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_pdist_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">pdist</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cosine_similarity(Tensor x1, Tensor x2, int dim=1, float eps=1e-08) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x2</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cosine_similarity</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::permute(Tensor(a) self, int[] dims) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">permute</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">permute</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::movedim.intlist(Tensor(a) self, int[] source, int[] destination) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">movedim</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">source</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">destination</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">movedim_intlist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">destination</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::movedim.int(Tensor(a) self, int source, int destination) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">movedim</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">source</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">destination</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">movedim_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">destination</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::moveaxis.intlist(Tensor(a) self, int[] source, int[] destination) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">moveaxis</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">source</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">destination</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">moveaxis_intlist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">destination</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::moveaxis.int(Tensor(a) self, int source, int destination) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">moveaxis</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">source</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">destination</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">moveaxis_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">destination</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pixel_shuffle(Tensor self, int upscale_factor) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">pixel_shuffle</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">upscale_factor</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pixel_shuffle</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">upscale_factor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pixel_unshuffle(Tensor self, int downscale_factor) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">pixel_unshuffle</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">downscale_factor</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pixel_unshuffle</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">downscale_factor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::channel_shuffle(Tensor self, int groups) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">channel_shuffle</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">channel_shuffle</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_pin_memory(Tensor self, Device? device=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_pin_memory</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_pin_memory</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">device</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pinverse(Tensor self, float rcond=1e-15) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">pinverse</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">rcond</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pinverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">rcond</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::poisson_nll_loss(Tensor input, Tensor target, bool log_input, bool full, float eps, int reduction) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">poisson_nll_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">log_input</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">full</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">poisson_nll_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">log_input</span><span class="p">,</span> <span class="n">full</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rad2deg(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rad2deg</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rad2deg</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rad2deg_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rad2deg_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rad2deg_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rad2deg.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rad2deg_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rad2deg_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rad2deg.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rad2deg_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rad2deg_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::deg2rad(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">deg2rad</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">deg2rad</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::deg2rad_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">deg2rad_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">deg2rad_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::deg2rad.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">deg2rad_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">deg2rad_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::deg2rad.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">deg2rad_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">deg2rad_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scalar_tensor(Scalar s, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scalar_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">s</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scalar_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::scalar_tensor(Scalar s, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scalar_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">s</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scalar_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rand.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::rand.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rand.generator_with_names(int[] size, *, Generator? generator, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_generator_with_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::rand.generator_with_names(int[] size, *, Generator? generator, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_generator_with_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rand(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::rand(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rand.generator(int[] size, *, Generator? generator, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::rand.generator(int[] size, *, Generator? generator, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rand.out(int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rand_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rand.out(int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rand_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rand.generator_out(int[] size, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rand_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rand.generator_out(int[] size, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rand_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rand_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::rand_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rand_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rand_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint(int high, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randint(int high, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.generator(int high, int[] size, *, Generator? generator, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randint.generator(int high, int[] size, *, Generator? generator, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.low(int low, int high, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_low</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randint.low(int low, int high, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_low</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.low_generator(int low, int high, int[] size, *, Generator? generator, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_low_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randint.low_generator(int low, int high, int[] size, *, Generator? generator, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_low_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.out(int high, int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randint_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.out(int high, int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randint_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.generator_out(int high, int[] size, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randint_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.generator_out(int high, int[] size, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randint_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.low_out(int low, int high, int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randint_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_low_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.low_out(int low, int high, int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randint_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_low_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.low_generator_out(int low, int high, int[] size, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randint_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_low_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint.low_generator_out(int low, int high, int[] size, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randint_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_low_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint_like(Tensor self, int high, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::randint_like(Tensor self, int high, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randint_like.low_dtype(Tensor self, int low, int high, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_like_low_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::randint_like.low_dtype(Tensor self, int low, int high, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randint_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">low</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">high</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randint_like_low_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randn(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randn(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randn.generator(int[] size, *, Generator? generator, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randn.generator(int[] size, *, Generator? generator, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randn.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randn.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randn.generator_with_names(int[] size, *, Generator? generator, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_generator_with_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randn.generator_with_names(int[] size, *, Generator? generator, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_generator_with_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randn.out(int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randn_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randn.out(int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randn_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randn.generator_out(int[] size, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randn_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randn.generator_out(int[] size, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randn_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randn_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::randn_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randn_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randn_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randperm(int n, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randperm</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">kLong</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randperm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randperm(int n, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randperm</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randperm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randperm.generator(int n, *, Generator? generator, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randperm</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">kLong</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randperm_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::randperm.generator(int n, *, Generator? generator, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randperm</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randperm_generator</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randperm.out(int n, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randperm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randperm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randperm.out(int n, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randperm_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randperm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randperm.generator_out(int n, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randperm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randperm_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::randperm.generator_out(int n, *, Generator? generator, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">randperm_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">randperm_generator_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::range.step(Scalar start, Scalar end, Scalar step=1, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">range</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">range_step</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::range.step(Scalar start, Scalar end, Scalar step=1, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">range</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">step</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">range_step</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::range(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">range</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">range</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::range(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">range</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">range</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::range.out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">range_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">range_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::range.out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">range_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">start</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">step</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">range_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ravel(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ravel</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ravel</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reciprocal(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">reciprocal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reciprocal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reciprocal_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reciprocal_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reciprocal_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reciprocal.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reciprocal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reciprocal_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reciprocal.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reciprocal_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reciprocal_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::neg(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">neg</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">neg</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::neg_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">neg_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">neg_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::neg.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">neg_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">neg_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::neg.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">neg_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">neg_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::negative(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">negative</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">negative</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::negative_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">negative_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">negative_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::negative.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">negative_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">negative_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::negative.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">negative_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">negative_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::repeat_interleave.Tensor(Tensor repeats, *, int? output_size=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">repeat_interleave</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">repeats</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">repeat_interleave_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">repeats</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::repeat_interleave.self_Tensor(Tensor self, Tensor repeats, int? dim=None, *, int? output_size=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">repeat_interleave</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">repeats</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">repeat_interleave_self_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">repeats</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::repeat_interleave.self_int(Tensor self, int repeats, int? dim=None, *, int? output_size=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">repeat_interleave</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">repeats</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">repeat_interleave_self_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">repeats</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reshape(Tensor(a) self, int[] shape) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">reshape</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">shape</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reshape</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_reshape_alias(Tensor(a) self, int[] size, int[] stride) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_reshape_alias</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_reshape_alias</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_mkldnn_reshape(Tensor self, int[] shape) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_mkldnn_reshape</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">shape</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_mkldnn_reshape</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::round(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">round</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">round</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::round_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">round_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">round_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::round.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">round_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">round_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::round.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">round_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">round_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rrelu(Tensor self, Scalar lower=0.125, Scalar upper=0.3333333333333333, bool training=False, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rrelu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.125</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.3333333333333333</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rrelu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rrelu_(Tensor(a!) self, Scalar lower=0.125, Scalar upper=0.3333333333333333, bool training=False, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rrelu_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.125</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.3333333333333333</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rrelu_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::relu(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">relu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">relu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::relu_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">relu_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">relu_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::relu6(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">relu6</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">relu6</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::relu6_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">relu6_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">relu6_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prelu(Tensor self, Tensor weight) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">prelu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prelu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prelu_backward(Tensor grad_output, Tensor self, Tensor weight) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">prelu_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prelu_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gelu.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gelu_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gelu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gelu.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gelu_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gelu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gelu(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">gelu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gelu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gelu_backward.grad_input(Tensor grad, Tensor self, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gelu_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gelu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gelu_backward.grad_input(Tensor grad, Tensor self, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gelu_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gelu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gelu_backward(Tensor grad, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">gelu_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gelu_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::infinitely_differentiable_gelu_backward(Tensor grad, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">infinitely_differentiable_gelu_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">infinitely_differentiable_gelu_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardshrink.out(Tensor self, Scalar lambd=0.5, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardshrink_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardshrink_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardshrink.out(Tensor self, Scalar lambd=0.5, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardshrink_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardshrink_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardshrink(Tensor self, Scalar lambd=0.5) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hardshrink</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardshrink</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardshrink_backward.grad_input(Tensor grad_out, Tensor self, Scalar lambd, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardshrink_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardshrink_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_out</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardshrink_backward.grad_input(Tensor grad_out, Tensor self, Scalar lambd, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardshrink_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardshrink_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_out</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardshrink_backward(Tensor grad_out, Tensor self, Scalar lambd) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hardshrink_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardshrink_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_out</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rsqrt(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rsqrt</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rsqrt</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rsqrt_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rsqrt_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rsqrt_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rsqrt.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rsqrt_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rsqrt_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rsqrt.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rsqrt_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rsqrt_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::select.Dimname(Tensor(a) self, Dimname dim, int index) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">select</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">select_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::select.int(Tensor(a) self, int dim, int index) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">select</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">select_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::select_backward(Tensor grad, int[] input_sizes, int dim, int index) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">select_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">select_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::selu(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">selu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">selu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::selu_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">selu_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">selu_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::celu(Tensor self, Scalar alpha=1.0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">celu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">celu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::celu_(Tensor(a!) self, Scalar alpha=1.0) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">celu_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">celu_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::silu(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">silu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">silu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::silu_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">silu_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">silu_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::silu.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">silu_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">silu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::silu.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">silu_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">silu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::silu_backward.grad_input(Tensor grad_output, Tensor self, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">silu_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">silu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::silu_backward.grad_input(Tensor grad_output, Tensor self, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">silu_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">silu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::silu_backward(Tensor grad_output, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">silu_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">silu_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mish(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mish</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mish</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mish_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mish_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mish_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mish.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mish_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mish_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mish.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mish_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mish_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mish_backward(Tensor grad_output, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mish_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mish_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sigmoid(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sigmoid</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sigmoid</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sigmoid_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sigmoid_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sigmoid_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sigmoid.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sigmoid_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sigmoid_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sigmoid.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sigmoid_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sigmoid_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logit(Tensor self, float? eps=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logit</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logit_(Tensor(a!) self, float? eps=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logit_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logit_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logit.out(Tensor self, float? eps=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logit_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logit_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logit.out(Tensor self, float? eps=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logit_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logit_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sin(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sin_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sin_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sin.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sin.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sinc(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sinc</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sinc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sinc_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinc_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sinc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sinc_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sinc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sinc_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sinh(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sinh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sinh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sinh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sinh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sinh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sinh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::detach(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">detach</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">detach</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::detach_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">detach_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">detach_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::size.int(Tensor self, int dim) -&gt; int</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">__dispatch_size</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">size_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::size.Dimname(Tensor self, Dimname dim) -&gt; int</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">size</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">size_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slice.Tensor(Tensor(a) self, int dim=0, int? start=None, int? end=None, int step=1) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">slice</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">start</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">end</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slice_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slice_backward(Tensor grad, int[] input_sizes, int dim, int start, int end, int step) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">slice_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">start</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">end</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">step</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slice_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slogdet(Tensor self) -&gt; (Tensor sign, Tensor logabsdet)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">slogdet</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slogdet</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::smm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">smm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">smm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softmax_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softmax_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_softmax(Tensor self, int dim, bool half_to_float) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">half_to_float</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_softmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">half_to_float</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_softmax_backward_data(Tensor grad_output, Tensor output, int dim, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_softmax_backward_data</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_softmax_backward_data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsafe_split.Tensor(Tensor self, int split_size, int dim=0) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">unsafe_split</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">split_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsafe_split_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">split_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::split.Tensor(Tensor(a) self, int split_size, int dim=0) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">split</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">split_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">split_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">split_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsafe_split_with_sizes(Tensor self, int[] split_sizes, int dim=0) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">unsafe_split_with_sizes</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">split_sizes</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsafe_split_with_sizes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">split_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::split_with_sizes(Tensor(a) self, int[] split_sizes, int dim=0) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">split_with_sizes</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">split_sizes</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">split_with_sizes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">split_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hsplit.int(Tensor(a) self, int sections) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">hsplit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">sections</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hsplit_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sections</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hsplit.array(Tensor(a) self, int[] indices) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">hsplit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hsplit_array</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vsplit.int(Tensor(a) self, int sections) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">vsplit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">sections</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vsplit_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sections</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vsplit.array(Tensor(a) self, int[] indices) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">vsplit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vsplit_array</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dsplit.int(Tensor(a) self, int sections) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">dsplit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">sections</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dsplit_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sections</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dsplit.array(Tensor(a) self, int[] indices) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">dsplit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dsplit_array</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">squeeze</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze.dim(Tensor(a) self, int dim) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">squeeze</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze.dimname(Tensor(a) self, Dimname dim) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">squeeze</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sspaddmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sspaddmm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sspaddmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sspaddmm.out(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sspaddmm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sspaddmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sspaddmm.out(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sspaddmm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sspaddmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::stack(Tensor[] tensors, int dim=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">stack</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">stack</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::stack.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">stack_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">stack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::stack.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">stack_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">stack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_stack(Tensor[] tensors, int dim=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_stack</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_stack</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_stack.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_stack_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_stack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_stack.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_stack_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_stack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hstack(Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hstack</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hstack</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hstack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hstack_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hstack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hstack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hstack_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hstack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vstack(Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">vstack</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vstack</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vstack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vstack_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vstack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vstack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vstack_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vstack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dstack(Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">dstack</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dstack</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dstack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dstack_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dstack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dstack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dstack_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dstack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::stft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool normalized=False, bool? onesided=None, bool? return_complex=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">stft</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n_fft</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">hop_length</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">win_length</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">window</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">normalized</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">onesided</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">return_complex</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">stft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_fft</span><span class="p">,</span> <span class="n">hop_length</span><span class="p">,</span> <span class="n">win_length</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">normalized</span><span class="p">,</span> <span class="n">onesided</span><span class="p">,</span> <span class="n">return_complex</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::istft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool center=True, bool normalized=False, bool? onesided=None, int? length=None, bool return_complex=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">istft</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n_fft</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">hop_length</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">win_length</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">window</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">center</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">normalized</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">onesided</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">length</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_complex</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">istft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_fft</span><span class="p">,</span> <span class="n">hop_length</span><span class="p">,</span> <span class="n">win_length</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">center</span><span class="p">,</span> <span class="n">normalized</span><span class="p">,</span> <span class="n">onesided</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">return_complex</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::stride.int(Tensor self, int dim) -&gt; int</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">__dispatch_stride</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">stride_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::stride.Dimname(Tensor self, Dimname dim) -&gt; int</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">stride</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">stride_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum.dim_IntList(Tensor self, int[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_dim_IntList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum.dim_DimnameList(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_dim_DimnameList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum.IntList_out(Tensor self, int[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sum_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_IntList_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum.IntList_out(Tensor self, int[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sum_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_IntList_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum.DimnameList_out(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sum_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_DimnameList_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum.DimnameList_out(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sum_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_DimnameList_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nansum(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nansum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nansum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nansum.dim_IntList(Tensor self, int[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nansum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nansum_dim_IntList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nansum.IntList_out(Tensor self, int[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nansum_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nansum_IntList_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nansum.IntList_out(Tensor self, int[1] dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nansum_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nansum_IntList_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sqrt(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sqrt</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sqrt</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sqrt_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sqrt_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sqrt_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sqrt.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sqrt_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sqrt_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sqrt.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sqrt_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sqrt_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::square(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">square</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">square</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::square_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">square_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">square_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::square.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">square_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">square_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::square.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">square_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">square_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std(Tensor self, bool unbiased=True) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">std</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.dim(Tensor self, int[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">std</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.correction(Tensor self, int[1]? dim, *, int? correction, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">std</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_correction</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std_mean(Tensor self, bool unbiased=True) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">std_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_mean</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std_mean.dim(Tensor self, int[1] dim, bool unbiased=True, bool keepdim=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">std_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_mean_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std_mean.correction(Tensor self, int[1]? dim, *, int? correction, bool keepdim=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">std_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_mean_correction</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std_mean.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">std_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_mean_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std_mean.correction_names(Tensor self, Dimname[1] dim, *, int? correction, bool keepdim=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">std_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_mean_correction_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.out(Tensor self, int[1] dim, bool unbiased=True, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.out(Tensor self, int[1] dim, bool unbiased=True, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.correction_out(Tensor self, int[1]? dim, *, int? correction, bool keepdim=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_correction_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.correction_out(Tensor self, int[1]? dim, *, int? correction, bool keepdim=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_correction_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">std</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.names_out(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.names_out(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.correction_names(Tensor self, Dimname[1] dim, *, int? correction, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">std</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_correction_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.correction_names_out(Tensor self, Dimname[1] dim, *, int? correction, bool keepdim=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_correction_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.correction_names_out(Tensor self, Dimname[1] dim, *, int? correction, bool keepdim=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_correction_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">prod</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod.dim_int(Tensor self, int dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">prod</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod_dim_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod.int_out(Tensor self, int dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">prod_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod_int_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod.int_out(Tensor self, int dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">prod_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod_int_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod.dim_Dimname(Tensor self, Dimname dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">prod</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod_dim_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod.Dimname_out(Tensor self, Dimname dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">prod_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod_Dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod.Dimname_out(Tensor self, Dimname dim, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">prod_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod_Dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::t(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">t</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">t</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tan(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">tan</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tan_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tan_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tan.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tan_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tan_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tan.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tan_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tan_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tanh(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">tanh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tanh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tanh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tanh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tanh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tanh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tanh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tanh.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tanh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tanh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensordot(Tensor self, Tensor other, int[] dims_self, int[] dims_other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">tensordot</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims_self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims_other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensordot</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dims_self</span><span class="p">,</span> <span class="n">dims_other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensordot.out(Tensor self, Tensor other, int[] dims_self, int[] dims_other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensordot_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims_self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims_other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensordot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dims_self</span><span class="p">,</span> <span class="n">dims_other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensordot.out(Tensor self, Tensor other, int[] dims_self, int[] dims_other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensordot_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims_self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims_other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensordot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dims_self</span><span class="p">,</span> <span class="n">dims_other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::threshold(Tensor self, Scalar threshold, Scalar value) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">threshold</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">threshold</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::threshold_(Tensor(a!) self, Scalar threshold, Scalar value) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">threshold_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">threshold_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::threshold.out(Tensor self, Scalar threshold, Scalar value, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">threshold_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">threshold_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::threshold.out(Tensor self, Scalar threshold, Scalar value, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">threshold_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">threshold_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::threshold_backward.grad_input(Tensor grad_output, Tensor self, Scalar threshold, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">threshold_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">threshold_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::threshold_backward.grad_input(Tensor grad_output, Tensor self, Scalar threshold, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">threshold_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">threshold_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::threshold_backward(Tensor grad_output, Tensor self, Scalar threshold) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">threshold_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">threshold_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tile(Tensor self, int[] dims) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">tile</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tile</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::transpose.int(Tensor(a) self, int dim0, int dim1) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">transpose</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">transpose_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::transpose.Dimname(Tensor(a) self, Dimname dim0, Dimname dim1) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">transpose</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">transpose_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_mkldnn_transpose(Tensor self, int dim0, int dim1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_mkldnn_transpose</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_mkldnn_transpose</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_mkldnn_transpose_(Tensor(a!) self, int dim0, int dim1) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_mkldnn_transpose_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_mkldnn_transpose_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::one_hot(Tensor self, int num_classes=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">one_hot</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">one_hot</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flip(Tensor self, int[] dims) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">flip</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flip</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fliplr(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fliplr</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fliplr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flipud(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">flipud</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flipud</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::roll(Tensor self, int[1] shifts, int[1] dims=[]) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">roll</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">shifts</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">roll</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">shifts</span><span class="p">,</span> <span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rot90(Tensor self, int k=1, int[] dims=[0,1]) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rot90</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dims</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rot90</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trapezoid.x(Tensor y, Tensor x, *, int dim=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">trapezoid</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">y</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trapezoid_x</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trapezoid.dx(Tensor y, *, Scalar dx=1, int dim=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">trapezoid</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">y</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">dx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trapezoid_dx</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trapz.x(Tensor y, Tensor x, *, int dim=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">trapz</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">y</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trapz_x</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trapz.dx(Tensor y, *, float dx=1, int dim=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">trapz</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">y</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trapz_dx</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_trilinear(Tensor i1, Tensor i2, Tensor i3, int[] expand1, int[] expand2, int[] expand3, int[] sumdim, int unroll_dim=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_trilinear</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">i1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">i2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">i3</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">expand1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">expand2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">expand3</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">sumdim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">unroll_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_trilinear</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="n">i3</span><span class="p">,</span> <span class="n">expand1</span><span class="p">,</span> <span class="n">expand2</span><span class="p">,</span> <span class="n">expand3</span><span class="p">,</span> <span class="n">sumdim</span><span class="p">,</span> <span class="n">unroll_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triplet_margin_loss(Tensor anchor, Tensor positive, Tensor negative, float margin=1.0, float p=2, float eps=1e-06, bool swap=False, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">triplet_margin_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">anchor</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">positive</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">negative</span><span class="p">,</span> <span class="kt">double</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="kt">double</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="kt">double</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">swap</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triplet_margin_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">swap</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trunc(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">trunc</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trunc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trunc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">trunc_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trunc_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trunc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">trunc_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trunc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trunc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">trunc_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trunc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fix(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fix</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fix</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fix_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fix_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fix_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fix.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fix_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fix_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fix.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fix_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fix_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_has_compatible_shallow_copy_type(Tensor self, Tensor from) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">_has_compatible_shallow_copy_type</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">from</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_has_compatible_shallow_copy_type</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">from</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_unique(Tensor self, bool sorted=True, bool return_inverse=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_unique</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sorted</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_inverse</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_unique</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sorted</span><span class="p">,</span> <span class="n">return_inverse</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unique_dim(Tensor self, int dim, bool sorted=True, bool return_inverse=False, bool return_counts=False) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">unique_dim</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sorted</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_inverse</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_counts</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unique_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">sorted</span><span class="p">,</span> <span class="n">return_inverse</span><span class="p">,</span> <span class="n">return_counts</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unique_consecutive(Tensor self, bool return_inverse=False, bool return_counts=False, int? dim=None) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">unique_consecutive</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_inverse</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_counts</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unique_consecutive</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">return_inverse</span><span class="p">,</span> <span class="n">return_counts</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unique_dim_consecutive(Tensor self, int dim, bool return_inverse=False, bool return_counts=False) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">unique_dim_consecutive</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_inverse</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_counts</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unique_dim_consecutive</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">return_inverse</span><span class="p">,</span> <span class="n">return_counts</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_unique2(Tensor self, bool sorted=True, bool return_inverse=False, bool return_counts=False) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_unique2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sorted</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_inverse</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">return_counts</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_unique2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sorted</span><span class="p">,</span> <span class="n">return_inverse</span><span class="p">,</span> <span class="n">return_counts</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_unsafe_view(Tensor self, int[] size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_unsafe_view</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_unsafe_view</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsqueeze(Tensor(a) self, int dim) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">unsqueeze</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsqueeze</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vander(Tensor x, int? N=None, bool increasing=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">vander</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">N</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">increasing</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vander</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">increasing</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var(Tensor self, bool unbiased=True) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">var</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.dim(Tensor self, int[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">var</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.correction(Tensor self, int[1]? dim, *, int? correction, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">var</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_correction</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.out(Tensor self, int[1] dim, bool unbiased=True, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">var_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.out(Tensor self, int[1] dim, bool unbiased=True, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">var_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.correction_out(Tensor self, int[1]? dim, *, int? correction, bool keepdim=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">var_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_correction_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.correction_out(Tensor self, int[1]? dim, *, int? correction, bool keepdim=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">var_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_correction_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">var</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.names_out(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">var_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.names_out(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">var_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.correction_names(Tensor self, Dimname[1] dim, *, int? correction, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">var</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_correction_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.correction_names_out(Tensor self, Dimname[1] dim, *, int? correction, bool keepdim=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">var_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_correction_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.correction_names_out(Tensor self, Dimname[1] dim, *, int? correction, bool keepdim=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">var_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_correction_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var_mean(Tensor self, bool unbiased=True) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">var_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_mean</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var_mean.dim(Tensor self, int[1] dim, bool unbiased=True, bool keepdim=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">var_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_mean_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var_mean.correction(Tensor self, int[1]? dim, *, int? correction, bool keepdim=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">var_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_mean_correction</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var_mean.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">var_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unbiased</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_mean_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">unbiased</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var_mean.correction_names(Tensor self, Dimname[1] dim, *, int? correction, bool keepdim=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">var_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">correction</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_mean_correction_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">correction</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::where.self(Tensor condition, Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">where</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">condition</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">where_self</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::where.ScalarSelf(Tensor condition, Scalar self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">where</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">condition</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">where_ScalarSelf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::where.ScalarOther(Tensor condition, Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">where</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">condition</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">where_ScalarOther</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::where.Scalar(Tensor condition, Scalar self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">where</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">condition</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">where_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::where(Tensor condition) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">where</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">condition</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">where</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">condition</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_s_where(Tensor condition, Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_s_where</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">condition</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_s_where</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm_except_dim(Tensor v, int pow=2, int dim=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">norm_except_dim</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">v</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">pow</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_except_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">pow</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_weight_norm(Tensor v, Tensor g, int dim=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_weight_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">v</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">g</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_weight_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_weight_norm_cuda_interface(Tensor v, Tensor g, int dim=0) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_weight_norm_cuda_interface</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">v</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">g</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_weight_norm_cuda_interface</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_weight_norm_cuda_interface_backward(Tensor grad_w, Tensor saved_v, Tensor saved_g, Tensor saved_norms, int dim) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_weight_norm_cuda_interface_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_w</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">saved_v</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">saved_g</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">saved_norms</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_weight_norm_cuda_interface_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_w</span><span class="p">,</span> <span class="n">saved_v</span><span class="p">,</span> <span class="n">saved_g</span><span class="p">,</span> <span class="n">saved_norms</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_weight_norm_differentiable_backward(Tensor grad_w, Tensor saved_v, Tensor saved_g, Tensor saved_norms, int dim) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_weight_norm_differentiable_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_w</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">saved_v</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">saved_g</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">saved_norms</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_weight_norm_differentiable_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_w</span><span class="p">,</span> <span class="n">saved_v</span><span class="p">,</span> <span class="n">saved_g</span><span class="p">,</span> <span class="n">saved_norms</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::zeros.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">zeros</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zeros_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::zeros.names(int[] size, *, Dimname[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">zeros</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span> <span class="n">names</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zeros_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::zeros(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">zeros</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zeros</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::zeros(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">zeros</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zeros</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::zeros.out(int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zeros_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zeros_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::zeros.out(int[] size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zeros_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zeros_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::zeros_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">zeros_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zeros_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span> <span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::zeros_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">zeros_like</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zeros_like</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_standard_gamma_grad(Tensor self, Tensor output) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_standard_gamma_grad</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_standard_gamma_grad</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_standard_gamma(Tensor self, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_standard_gamma</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_standard_gamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_dirichlet_grad(Tensor x, Tensor alpha, Tensor total) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_dirichlet_grad</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">x</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_dirichlet_grad</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">total</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sample_dirichlet(Tensor self, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sample_dirichlet</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sample_dirichlet</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::poisson(Tensor self, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">poisson</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">poisson</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::binomial(Tensor count, Tensor prob, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">binomial</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">count</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">prob</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">binomial</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_norm(Tensor self, Scalar p=2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">native_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::native_norm.ScalarOpt_dim_dtype(Tensor self, Scalar? p, int[1] dim, bool keepdim, ScalarType? dtype) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">native_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">native_norm_ScalarOpt_dim_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_sum(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_sum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_sum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_sum.dtype(Tensor self, *, ScalarType dtype) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_sum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_sum_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_sum.dim(Tensor self, int[1] dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_sum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_sum_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_sum.dim_dtype(Tensor self, int[1] dim, *, ScalarType dtype) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_sum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_sum_dim_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_sum_backward(Tensor grad, Tensor self, int[] dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_sum_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_sum_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_softmax_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_softmax_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_softmax(Tensor self, int dim, bool half_to_float) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">half_to_float</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_softmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">half_to_float</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_softmax_backward_data(Tensor grad_output, Tensor output, int dim, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_softmax_backward_data</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_softmax_backward_data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_log_softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_log_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_log_softmax_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_log_softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_log_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_log_softmax_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_log_softmax(Tensor self, int dim, bool half_to_float) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_log_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">half_to_float</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_log_softmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">half_to_float</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_log_softmax_backward_data(Tensor grad_output, Tensor output, int dim, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_log_softmax_backward_data</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_log_softmax_backward_data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.ScalarOpt_dtype(Tensor self, Scalar? p, *, ScalarType dtype) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_ScalarOpt_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.Scalar(Tensor self, Scalar p=2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.ScalarOpt_dim_dtype(Tensor self, Scalar? p, int[1] dim, bool keepdim, *, ScalarType dtype) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_ScalarOpt_dim_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.ScalarOpt_dim(Tensor self, Scalar? p, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_ScalarOpt_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.dtype_out(Tensor self, Scalar? p, int[1] dim, bool keepdim, *, ScalarType dtype, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_dtype_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.dtype_out(Tensor self, Scalar? p, int[1] dim, bool keepdim, *, ScalarType dtype, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_dtype_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.out(Tensor self, Scalar? p, int[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.out(Tensor self, Scalar? p, int[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.names_ScalarOpt_dim_dtype(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim, *, ScalarType dtype) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_names_ScalarOpt_dim_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.names_ScalarOpt_dim(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_names_ScalarOpt_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.names_dtype_out(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim, *, ScalarType dtype, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_names_dtype_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.names_dtype_out(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim, *, ScalarType dtype, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_names_dtype_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.names_out(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.names_out(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_names_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frexp.Tensor(Tensor self) -&gt; (Tensor mantissa, Tensor exponent)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">frexp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frexp_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frexp.Tensor_out(Tensor self, *, Tensor(a!) mantissa, Tensor(b!) exponent) -&gt; (Tensor(a!) mantissa, Tensor(b!) exponent)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">frexp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mantissa</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frexp_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mantissa</span><span class="p">,</span> <span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frexp.Tensor_out(Tensor self, *, Tensor(a!) mantissa, Tensor(b!) exponent) -&gt; (Tensor(a!) mantissa, Tensor(b!) exponent)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">frexp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mantissa</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frexp_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mantissa</span><span class="p">,</span> <span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frobenius_norm(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">frobenius_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frobenius_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frobenius_norm.dim(Tensor self, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">frobenius_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frobenius_norm_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frobenius_norm.out(Tensor self, int[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">frobenius_norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frobenius_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frobenius_norm.out(Tensor self, int[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">frobenius_norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frobenius_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nuclear_norm(Tensor self, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nuclear_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nuclear_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nuclear_norm.out(Tensor self, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nuclear_norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nuclear_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nuclear_norm.out(Tensor self, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nuclear_norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nuclear_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nuclear_norm.dim(Tensor self, int[2] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nuclear_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nuclear_norm_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nuclear_norm.dim_out(Tensor self, int[2] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nuclear_norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nuclear_norm_dim_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nuclear_norm.dim_out(Tensor self, int[2] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nuclear_norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nuclear_norm_dim_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">clone</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clone</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::positive(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">positive</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">positive</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::resize_as_(Tensor(a!) self, Tensor the_template, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">resize_as_</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">the_template</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resize_as_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">the_template</span><span class="p">,</span> <span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::resize_as_sparse_(Tensor(a!) self, Tensor the_template) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">resize_as_sparse_</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">the_template</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resize_as_sparse_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">the_template</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::zero_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zero_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sub.out(Tensor self, Tensor other, *, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sub_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sub_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sub.out(Tensor self, Tensor other, *, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sub_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sub_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sub</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sub_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sub</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sub_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::subtract.out(Tensor self, Tensor other, *, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">subtract_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">subtract_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::subtract.out(Tensor self, Tensor other, *, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">subtract_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">subtract_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::subtract.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">subtract</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">subtract_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::subtract.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">subtract</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">subtract_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rsub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rsub</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rsub_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::heaviside.out(Tensor self, Tensor values, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">heaviside_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">heaviside_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::heaviside.out(Tensor self, Tensor values, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">heaviside_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">heaviside_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::heaviside(Tensor self, Tensor values) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">heaviside</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">heaviside</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rsub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rsub</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rsub_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_addmm(Tensor self, Tensor sparse, Tensor dense, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_addmm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sparse</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dense</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_addmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sparse</span><span class="p">,</span> <span class="n">dense</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmm.out(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addmm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmm.out(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addmm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">addmm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_csr_tensor.crow_col_value_size(Tensor crow_indices, Tensor col_indices, Tensor values, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_csr_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">crow_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_csr_tensor_crow_col_value_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_csr_tensor.crow_col_value_size(Tensor crow_indices, Tensor col_indices, Tensor values, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_csr_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">crow_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_csr_tensor_crow_col_value_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_csr_tensor.crow_col_value(Tensor crow_indices, Tensor col_indices, Tensor values, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_csr_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">crow_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_csr_tensor_crow_col_value</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_csr_tensor.crow_col_value(Tensor crow_indices, Tensor col_indices, Tensor values, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_csr_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">crow_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_csr_tensor_crow_col_value</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_csr_tensor_unsafe(Tensor crow_indices, Tensor col_indices, Tensor values, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_csr_tensor_unsafe</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">crow_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_csr_tensor_unsafe</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_csr_tensor_unsafe(Tensor crow_indices, Tensor col_indices, Tensor values, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_csr_tensor_unsafe</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">crow_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_csr_tensor_unsafe</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_coo_tensor.size(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_coo_tensor_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_coo_tensor.size(int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_coo_tensor_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_coo_tensor.indices(Tensor indices, Tensor values, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_coo_tensor_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_coo_tensor.indices(Tensor indices, Tensor values, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_coo_tensor_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_coo_tensor.indices_size(Tensor indices, Tensor values, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_coo_tensor_indices_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_coo_tensor.indices_size(Tensor indices, Tensor values, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_coo_tensor_indices_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_coo_tensor_unsafe(Tensor indices, Tensor values, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_coo_tensor_unsafe</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_coo_tensor_unsafe</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_coo_tensor_unsafe(Tensor indices, Tensor values, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_coo_tensor_unsafe</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_coo_tensor_unsafe</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_validate_sparse_coo_tensor_args(Tensor indices, Tensor values, int[] size) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_validate_sparse_coo_tensor_args</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_validate_sparse_coo_tensor_args</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_validate_sparse_csr_tensor_args(Tensor crow_indices, Tensor col_indices, Tensor values, int[] size) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_validate_sparse_csr_tensor_args</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">crow_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_validate_sparse_csr_tensor_args</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_coo_tensor_with_dims(int sparse_dim, int dense_dim, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_coo_tensor_with_dims</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">sparse_dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dense_dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_coo_tensor_with_dims</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sparse_dim</span><span class="p">,</span> <span class="n">dense_dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_coo_tensor_with_dims(int sparse_dim, int dense_dim, int[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_coo_tensor_with_dims</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">sparse_dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dense_dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_coo_tensor_with_dims</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sparse_dim</span><span class="p">,</span> <span class="n">dense_dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_coo_tensor_with_dims_and_tensors(int sparse_dim, int dense_dim, int[] size, Tensor indices, Tensor values, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_coo_tensor_with_dims_and_tensors</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">sparse_dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dense_dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_coo_tensor_with_dims_and_tensors</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sparse_dim</span><span class="p">,</span> <span class="n">dense_dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_coo_tensor_with_dims_and_tensors(int sparse_dim, int dense_dim, int[] size, Tensor indices, Tensor values, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_sparse_coo_tensor_with_dims_and_tensors</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">sparse_dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dense_dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_coo_tensor_with_dims_and_tensors</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sparse_dim</span><span class="p">,</span> <span class="n">dense_dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_to_cpu(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_to_cpu</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_to_cpu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_dense_backward(Tensor grad, Tensor input) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">to_dense_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_dense_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_coalesce(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_coalesce</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_coalesce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hspmm.out(Tensor mat1, Tensor mat2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hspmm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hspmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hspmm.out(Tensor mat1, Tensor mat2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hspmm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hspmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hspmm(Tensor mat1, Tensor mat2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hspmm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mat2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hspmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copy_sparse_to_sparse_(Tensor(a!) self, Tensor src, bool non_blocking=False) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">copy_sparse_to_sparse_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copy_sparse_to_sparse_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unbind.int(Tensor(a) self, int dim=0) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">unbind</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unbind_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unbind.Dimname(Tensor(a) self, Dimname dim) -&gt; Tensor(a)[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">unbind</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unbind_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_reorder_conv2d_weight(Tensor self, int[2] padding=0, int[2] stride=1, int[2] dilation=1, int groups=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_reorder_conv2d_weight</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_reorder_conv2d_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_reorder_conv3d_weight(Tensor self, int[3] padding=0, int[3] stride=1, int[3] dilation=1, int groups=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_reorder_conv3d_weight</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_reorder_conv3d_weight</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_mkldnn_backward(Tensor grad, Tensor input) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">to_mkldnn_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_mkldnn_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantize_per_tensor(Tensor self, float scale, int zero_point, ScalarType dtype) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantize_per_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">scale</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantize_per_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantize_per_tensor.tensor_qparams(Tensor self, Tensor scale, Tensor zero_point, ScalarType dtype) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantize_per_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantize_per_tensor_tensor_qparams</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantize_per_tensor.tensors(Tensor[] tensors, Tensor scales, Tensor zero_points, ScalarType dtype) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">quantize_per_tensor</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scales</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_points</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantize_per_tensor_tensors</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">zero_points</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantize_per_channel(Tensor self, Tensor scales, Tensor zero_points, int axis, ScalarType dtype) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantize_per_channel</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scales</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_points</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">dtype</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantize_per_channel</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">zero_points</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dequantize.self(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">dequantize</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dequantize_self</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dequantize.tensors(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">dequantize</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dequantize_tensors</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::q_scale(Tensor self) -&gt; float</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">double</span> <span class="n">q_scale</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_scale</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::q_zero_point(Tensor self) -&gt; int</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">q_zero_point</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_zero_point</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::q_per_channel_scales(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">q_per_channel_scales</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_per_channel_scales</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::q_per_channel_zero_points(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">q_per_channel_zero_points</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_per_channel_zero_points</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::q_per_channel_axis(Tensor self) -&gt; int</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">q_per_channel_axis</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_per_channel_axis</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::int_repr(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">int_repr</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">int_repr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_make_per_tensor_quantized_tensor(Tensor self, float scale, int zero_point) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_make_per_tensor_quantized_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">scale</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">zero_point</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_make_per_tensor_quantized_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_make_per_channel_quantized_tensor(Tensor self, Tensor scale, Tensor zero_point, int axis) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_make_per_channel_quantized_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_make_per_channel_quantized_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">axis</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fake_quantize_per_tensor_affine(Tensor self, float scale, int zero_point, int quant_min, int quant_max) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fake_quantize_per_tensor_affine</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">scale</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fake_quantize_per_tensor_affine</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fake_quantize_per_tensor_affine.tensor_qparams(Tensor self, Tensor scale, Tensor zero_point, int quant_min, int quant_max) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fake_quantize_per_tensor_affine</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fake_quantize_per_tensor_affine_tensor_qparams</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fake_quantize_per_tensor_affine_cachemask(Tensor self, float scale, int zero_point, int quant_min, int quant_max) -&gt; (Tensor output, Tensor mask)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">fake_quantize_per_tensor_affine_cachemask</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">scale</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fake_quantize_per_tensor_affine_cachemask</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fake_quantize_per_tensor_affine_cachemask_tensor_qparams(Tensor self, Tensor scale, Tensor zero_point, Tensor fake_quant_enabled, int quant_min, int quant_max) -&gt; (Tensor output, Tensor mask)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_fake_quantize_per_tensor_affine_cachemask_tensor_qparams</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fake_quant_enabled</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fake_quantize_per_tensor_affine_cachemask_tensor_qparams</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">fake_quant_enabled</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fake_quantize_per_tensor_affine_cachemask_backward(Tensor grad, Tensor mask) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fake_quantize_per_tensor_affine_cachemask_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fake_quantize_per_tensor_affine_cachemask_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fake_quantize_learnable_per_tensor_affine(Tensor self, Tensor scale, Tensor zero_point, int quant_min, int quant_max, float grad_factor=1.0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_fake_quantize_learnable_per_tensor_affine</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">,</span> <span class="kt">double</span> <span class="n">grad_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fake_quantize_learnable_per_tensor_affine</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">,</span> <span class="n">grad_factor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fake_quantize_learnable_per_tensor_affine_backward(Tensor grad, Tensor self, Tensor scale, Tensor zero_point, int quant_min, int quant_max, float grad_factor=1.0) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_fake_quantize_learnable_per_tensor_affine_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">,</span> <span class="kt">double</span> <span class="n">grad_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fake_quantize_learnable_per_tensor_affine_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">,</span> <span class="n">grad_factor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fake_quantize_per_channel_affine(Tensor self, Tensor scale, Tensor zero_point, int axis, int quant_min, int quant_max) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fake_quantize_per_channel_affine</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fake_quantize_per_channel_affine</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fake_quantize_per_channel_affine_cachemask(Tensor self, Tensor scale, Tensor zero_point, int axis, int quant_min, int quant_max) -&gt; (Tensor output, Tensor mask)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">fake_quantize_per_channel_affine_cachemask</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fake_quantize_per_channel_affine_cachemask</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fake_quantize_per_channel_affine_cachemask_backward(Tensor grad, Tensor mask) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fake_quantize_per_channel_affine_cachemask_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fake_quantize_per_channel_affine_cachemask_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fake_quantize_learnable_per_channel_affine(Tensor self, Tensor scale, Tensor zero_point, int axis, int quant_min, int quant_max, float grad_factor=1.0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_fake_quantize_learnable_per_channel_affine</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">,</span> <span class="kt">double</span> <span class="n">grad_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fake_quantize_learnable_per_channel_affine</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">,</span> <span class="n">grad_factor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fake_quantize_learnable_per_channel_affine_backward(Tensor grad, Tensor self, Tensor scale, Tensor zero_point, int axis, int quant_min, int quant_max, float grad_factor=1.0) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_fake_quantize_learnable_per_channel_affine_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">,</span> <span class="kt">double</span> <span class="n">grad_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fake_quantize_learnable_per_channel_affine_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">,</span> <span class="n">grad_factor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fused_moving_avg_obs_fake_quant(Tensor self, Tensor observer_on, Tensor fake_quant_on, Tensor(a!) running_min, Tensor(b!) running_max, Tensor(c!) scale, Tensor(d!) zero_point, float averaging_const, int quant_min, int quant_max, int ch_axis, bool per_row_fake_quant=False, bool symmetric_quant=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fused_moving_avg_obs_fake_quant</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">observer_on</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fake_quant_on</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">running_min</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">running_max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">double</span> <span class="n">averaging_const</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ch_axis</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">per_row_fake_quant</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">symmetric_quant</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fused_moving_avg_obs_fake_quant</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">observer_on</span><span class="p">,</span> <span class="n">fake_quant_on</span><span class="p">,</span> <span class="n">running_min</span><span class="p">,</span> <span class="n">running_max</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">averaging_const</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">,</span> <span class="n">ch_axis</span><span class="p">,</span> <span class="n">per_row_fake_quant</span><span class="p">,</span> <span class="n">symmetric_quant</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_fused_moving_avg_obs_fq_helper(Tensor self, Tensor observer_on, Tensor fake_quant_on, Tensor(a!) running_min, Tensor(b!) running_max, Tensor(c!) scale, Tensor(d!) zero_point, float averaging_const, int quant_min, int quant_max, int ch_axis, bool per_row_fake_quant=False, bool symmetric_quant=False) -&gt; (Tensor output, Tensor mask)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_fused_moving_avg_obs_fq_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">observer_on</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fake_quant_on</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">running_min</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">running_max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">zero_point</span><span class="p">,</span> <span class="kt">double</span> <span class="n">averaging_const</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_min</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">quant_max</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ch_axis</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">per_row_fake_quant</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">symmetric_quant</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fused_moving_avg_obs_fq_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">observer_on</span><span class="p">,</span> <span class="n">fake_quant_on</span><span class="p">,</span> <span class="n">running_min</span><span class="p">,</span> <span class="n">running_max</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">averaging_const</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">,</span> <span class="n">ch_axis</span><span class="p">,</span> <span class="n">per_row_fake_quant</span><span class="p">,</span> <span class="n">symmetric_quant</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_choose_qparams_per_tensor(Tensor self, bool reduce_range=False) -&gt; (float, int)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">_choose_qparams_per_tensor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">reduce_range</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_choose_qparams_per_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">reduce_range</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_saturate_weight_to_fp16(Tensor weight) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_saturate_weight_to_fp16</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_saturate_weight_to_fp16</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::choose_qparams_optimized(Tensor input, int numel, int n_bins, float ratio, int bit_width) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">choose_qparams_optimized</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">numel</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n_bins</span><span class="p">,</span> <span class="kt">double</span> <span class="n">ratio</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">bit_width</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">choose_qparams_optimized</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">numel</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">bit_width</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::meshgrid(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">meshgrid</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">meshgrid</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cartesian_prod(Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cartesian_prod</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cartesian_prod</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::combinations(Tensor self, int r=2, bool with_replacement=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">combinations</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">with_replacement</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">combinations</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">with_replacement</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::result_type.Tensor(Tensor tensor, Tensor other) -&gt; ScalarType</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">result_type</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">result_type_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::result_type.Scalar(Tensor tensor, Scalar other) -&gt; ScalarType</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">result_type</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">result_type_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::result_type.Scalar_Tensor(Scalar scalar, Tensor tensor) -&gt; ScalarType</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">result_type</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">result_type_Scalar_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">scalar</span><span class="p">,</span> <span class="n">tensor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::result_type.Scalar_Scalar(Scalar scalar1, Scalar scalar2) -&gt; ScalarType</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">result_type</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">result_type_Scalar_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">scalar1</span><span class="p">,</span> <span class="n">scalar2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::can_cast(ScalarType from, ScalarType to) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">can_cast</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">from</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">to</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">can_cast</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">from</span><span class="p">,</span> <span class="n">to</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::promote_types(ScalarType type1, ScalarType type2) -&gt; ScalarType</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">promote_types</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">type1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span> <span class="n">type2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">promote_types</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">type1</span><span class="p">,</span> <span class="n">type2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_local_scalar_dense(Tensor self) -&gt; Scalar</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="n">_local_scalar_dense</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_local_scalar_dense</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_thnn_fused_lstm_cell(Tensor input_gates, Tensor hidden_gates, Tensor cx, Tensor? input_bias=None, Tensor? hidden_bias=None) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_thnn_fused_lstm_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input_gates</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hidden_gates</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cx</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">input_bias</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">hidden_bias</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_thnn_fused_lstm_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input_gates</span><span class="p">,</span> <span class="n">hidden_gates</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">,</span> <span class="n">hidden_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_thnn_fused_lstm_cell_backward(Tensor? grad_hy, Tensor? grad_cy, Tensor cx, Tensor cy, Tensor workspace, bool has_bias) -&gt; (Tensor, Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_thnn_fused_lstm_cell_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_hy</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_cy</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cy</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">workspace</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_thnn_fused_lstm_cell_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_hy</span><span class="p">,</span> <span class="n">grad_cy</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">cy</span><span class="p">,</span> <span class="n">workspace</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_thnn_differentiable_lstm_cell_backward(Tensor? grad_hy, Tensor? grad_cy, Tensor input_gates, Tensor hidden_gates, Tensor? input_bias, Tensor? hidden_bias, Tensor cx, Tensor cy) -&gt; (Tensor, Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_thnn_differentiable_lstm_cell_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_hy</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">grad_cy</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input_gates</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hidden_gates</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">input_bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">hidden_bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cy</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_thnn_differentiable_lstm_cell_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_hy</span><span class="p">,</span> <span class="n">grad_cy</span><span class="p">,</span> <span class="n">input_gates</span><span class="p">,</span> <span class="n">hidden_gates</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">,</span> <span class="n">hidden_bias</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">cy</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_thnn_fused_gru_cell(Tensor input_gates, Tensor hidden_gates, Tensor hx, Tensor? input_bias=None, Tensor? hidden_bias=None) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_thnn_fused_gru_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input_gates</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hidden_gates</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">input_bias</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">hidden_bias</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_thnn_fused_gru_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input_gates</span><span class="p">,</span> <span class="n">hidden_gates</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">,</span> <span class="n">hidden_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_thnn_fused_gru_cell_backward(Tensor grad_hy, Tensor workspace, bool has_bias) -&gt; (Tensor, Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_thnn_fused_gru_cell_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_hy</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">workspace</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_thnn_fused_gru_cell_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_hy</span><span class="p">,</span> <span class="n">workspace</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_thnn_differentiable_gru_cell_backward(Tensor grad_hy, Tensor input_gates, Tensor hidden_gates, Tensor hx, Tensor? input_bias, Tensor? hidden_bias) -&gt; (Tensor, Tensor, Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_thnn_differentiable_gru_cell_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_hy</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input_gates</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hidden_gates</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">input_bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">hidden_bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_thnn_differentiable_gru_cell_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_hy</span><span class="p">,</span> <span class="n">input_gates</span><span class="p">,</span> <span class="n">hidden_gates</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">,</span> <span class="n">hidden_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lstm.input(Tensor input, Tensor[] hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional, bool batch_first) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">lstm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">hx</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">params</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_biases</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lstm_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lstm.data(Tensor data, Tensor batch_sizes, Tensor[] hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">lstm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">hx</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">params</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_biases</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lstm_data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gru.input(Tensor input, Tensor hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional, bool batch_first) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">gru</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">params</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_biases</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gru_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gru.data(Tensor data, Tensor batch_sizes, Tensor hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">gru</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">params</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_biases</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gru_data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rnn_tanh.input(Tensor input, Tensor hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional, bool batch_first) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">rnn_tanh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">params</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_biases</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rnn_tanh_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rnn_tanh.data(Tensor data, Tensor batch_sizes, Tensor hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">rnn_tanh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">params</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_biases</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rnn_tanh_data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rnn_relu.input(Tensor input, Tensor hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional, bool batch_first) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">rnn_relu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">params</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_biases</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rnn_relu_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rnn_relu.data(Tensor data, Tensor batch_sizes, Tensor hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">rnn_relu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">params</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">has_biases</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_layers</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dropout</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">train</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">bidirectional</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rnn_relu_data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lstm_cell(Tensor input, Tensor[] hx, Tensor w_ih, Tensor w_hh, Tensor? b_ih=None, Tensor? b_hh=None) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">lstm_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">b_ih</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">b_hh</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lstm_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gru_cell(Tensor input, Tensor hx, Tensor w_ih, Tensor w_hh, Tensor? b_ih=None, Tensor? b_hh=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">gru_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">b_ih</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">b_hh</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gru_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rnn_tanh_cell(Tensor input, Tensor hx, Tensor w_ih, Tensor w_hh, Tensor? b_ih=None, Tensor? b_hh=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rnn_tanh_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">b_ih</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">b_hh</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rnn_tanh_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rnn_relu_cell(Tensor input, Tensor hx, Tensor w_ih, Tensor w_hh, Tensor? b_ih=None, Tensor? b_hh=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rnn_relu_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">b_ih</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">b_hh</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rnn_relu_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantized_lstm_cell(Tensor input, Tensor[] hx, Tensor w_ih, Tensor w_hh, Tensor b_ih, Tensor b_hh, Tensor packed_ih, Tensor packed_hh, Tensor col_offsets_ih, Tensor col_offsets_hh, Scalar scale_ih, Scalar scale_hh, Scalar zero_point_ih, Scalar zero_point_hh) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">quantized_lstm_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">zero_point_hh</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantized_lstm_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span> <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantized_gru_cell(Tensor input, Tensor hx, Tensor w_ih, Tensor w_hh, Tensor b_ih, Tensor b_hh, Tensor packed_ih, Tensor packed_hh, Tensor col_offsets_ih, Tensor col_offsets_hh, Scalar scale_ih, Scalar scale_hh, Scalar zero_point_ih, Scalar zero_point_hh) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantized_gru_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">zero_point_hh</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantized_gru_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span> <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantized_rnn_relu_cell(Tensor input, Tensor hx, Tensor w_ih, Tensor w_hh, Tensor b_ih, Tensor b_hh, Tensor packed_ih, Tensor packed_hh, Tensor col_offsets_ih, Tensor col_offsets_hh, Scalar scale_ih, Scalar scale_hh, Scalar zero_point_ih, Scalar zero_point_hh) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantized_rnn_relu_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">zero_point_hh</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantized_rnn_relu_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span> <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantized_rnn_tanh_cell(Tensor input, Tensor hx, Tensor w_ih, Tensor w_hh, Tensor b_ih, Tensor b_hh, Tensor packed_ih, Tensor packed_hh, Tensor col_offsets_ih, Tensor col_offsets_hh, Scalar scale_ih, Scalar scale_hh, Scalar zero_point_ih, Scalar zero_point_hh) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantized_rnn_tanh_cell</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hx</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">w_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">zero_point_hh</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantized_rnn_tanh_cell</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span> <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_pack_padded_sequence(Tensor input, Tensor lengths, bool batch_first) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_pack_padded_sequence</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lengths</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_pack_padded_sequence</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_pack_padded_sequence_backward(Tensor grad, int[] input_size, Tensor batch_sizes, bool batch_first) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_pack_padded_sequence_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_pack_padded_sequence_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_pad_packed_sequence(Tensor data, Tensor batch_sizes, bool batch_first, Scalar padding_value, int total_length) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_pad_packed_sequence</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">padding_value</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">total_length</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_pad_packed_sequence</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">total_length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_fill.Scalar(Tensor self, Tensor mask, Scalar value) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">masked_fill</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_fill_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_fill.Tensor(Tensor self, Tensor mask, Tensor value) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">masked_fill</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_fill_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_scatter(Tensor self, Tensor mask, Tensor source) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">masked_scatter</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">source</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_scatter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::put(Tensor self, Tensor index, Tensor source, bool accumulate=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">put</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">source</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">accumulate</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">put</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">accumulate</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_add(Tensor self, int dim, Tensor index, Tensor source) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_add</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">source</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_add</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_add.alpha(Tensor self, int dim, Tensor index, Tensor source, *, Scalar alpha) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_add</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">source</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_add_alpha</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_add</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">source</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_add_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill.int_Scalar(Tensor self, int dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_fill</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill_int_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill.int_Tensor(Tensor self, int dim, Tensor index, Tensor value) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_fill</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill_int_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill.Dimname_Scalar(Tensor self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_fill</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill_Dimname_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill.Dimname_Tensor(Tensor self, Dimname dim, Tensor index, Tensor value) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_fill</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill_Dimname_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.src(Tensor self, int dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scatter</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_src</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.src_out(Tensor self, int dim, Tensor index, Tensor src, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_src_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.src_out(Tensor self, int dim, Tensor index, Tensor src, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_src_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.value(Tensor self, int dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scatter</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_value</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.value_out(Tensor self, int dim, Tensor index, Scalar value, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_value_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.value_out(Tensor self, int dim, Tensor index, Scalar value, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_value_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.reduce(Tensor self, int dim, Tensor index, Tensor src, *, str reduce) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scatter</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">reduce</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_reduce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">reduce</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.reduce_out(Tensor self, int dim, Tensor index, Tensor src, *, str reduce, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">reduce</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_reduce_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.reduce_out(Tensor self, int dim, Tensor index, Tensor src, *, str reduce, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_reduce_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.value_reduce(Tensor self, int dim, Tensor index, Scalar value, *, str reduce) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scatter</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">reduce</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_value_reduce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">reduce</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.value_reduce_out(Tensor self, int dim, Tensor index, Scalar value, *, str reduce, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">reduce</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_value_reduce_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.value_reduce_out(Tensor self, int dim, Tensor index, Scalar value, *, str reduce, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_value_reduce_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.dimname_src(Tensor self, Dimname dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scatter</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_dimname_src</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.dimname_value(Tensor self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scatter</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_dimname_value</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_add(Tensor self, int dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scatter_add</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_add</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_add.out(Tensor self, int dim, Tensor index, Tensor src, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_add_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_add_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_add.out(Tensor self, int dim, Tensor index, Tensor src, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">scatter_add_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_add_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">scatter_add</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">src</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_add_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_and_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_and_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_and_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_and_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_and</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_and</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__and__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__and__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__and___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__and__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__and__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__and___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_or_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_or_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_or_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_or_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_or</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_or</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__or__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__or__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__or___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__or__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__or__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__or___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_xor_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_xor_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_xor_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_xor_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_xor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_xor</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__xor__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__xor__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__xor___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__xor__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__xor__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__xor___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__lshift__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__lshift__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__lshift___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__lshift__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__lshift__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__lshift___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_left_shift</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_left_shift_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_left_shift_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift.Tensor_Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_left_shift</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift_Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift.Tensor_Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_left_shift_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift.Tensor_Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_left_shift_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift.Scalar_Tensor(Scalar self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_left_shift</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift_Scalar_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__rshift__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__rshift__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__rshift___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__rshift__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">__rshift__</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__rshift___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_right_shift</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_right_shift_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_right_shift_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift.Tensor_Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_right_shift</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift_Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift.Tensor_Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_right_shift_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift.Tensor_Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bitwise_right_shift_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift.Scalar_Tensor(Scalar self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bitwise_right_shift</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift_Scalar_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addbmm.out(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addbmm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addbmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addbmm.out(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addbmm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addbmm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">addbmm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">batch2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addbmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diag.out(Tensor self, int diagonal=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">diag_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diag_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diag.out(Tensor self, int diagonal=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">diag_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diag_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diag(Tensor self, int diagonal=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">diag</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diag</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diag_backward(Tensor grad, int[] input_sizes, int diagonal) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">diag_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diag_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cross.out(Tensor self, Tensor other, int? dim=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cross_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cross_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cross.out(Tensor self, Tensor other, int? dim=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cross_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cross_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cross(Tensor self, Tensor other, int? dim=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cross</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cross</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triu.out(Tensor self, int diagonal=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">triu_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triu.out(Tensor self, int diagonal=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">triu_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triu(Tensor self, int diagonal=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">triu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tril.out(Tensor self, int diagonal=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tril_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tril_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tril.out(Tensor self, int diagonal=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tril_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tril_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tril(Tensor self, int diagonal=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">tril</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tril</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tril_indices(int row, int col, int offset=0, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">tril_indices</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">row</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">col</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">kLong</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tril_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::tril_indices(int row, int col, int offset=0, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">tril_indices</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">row</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">col</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">offset</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tril_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triu_indices(int row, int col, int offset=0, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">triu_indices</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">row</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">col</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">kLong</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triu_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::triu_indices(int row, int col, int offset=0, *, ScalarType? dtype=long, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">triu_indices</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">row</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">col</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">offset</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triu_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trace(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">trace</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trace</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trace_backward(Tensor grad, int[] sizes) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">trace_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">sizes</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trace_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">sizes</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ne.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ne_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ne.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ne_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ne.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ne</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ne.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ne_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ne.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ne_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ne.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ne</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">not_equal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">not_equal_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">not_equal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">not_equal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">not_equal_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">not_equal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eq_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eq_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">eq</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eq_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eq_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">eq</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ge_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ge_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ge</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ge_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ge_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ge</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">greater_equal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">greater_equal_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">greater_equal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">greater_equal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">greater_equal_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">greater_equal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">le_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">le_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">le</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">le_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">le_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">le</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">less_equal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">less_equal_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">less_equal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">less_equal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">less_equal_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">less_equal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gt_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gt_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">gt</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gt_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gt_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">gt</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">greater_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">greater_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">greater</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">greater_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">greater_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">greater</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lt_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lt_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">lt</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lt_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lt_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">lt</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">less_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">less_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">less</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">less_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">less_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">less</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::take.out(Tensor self, Tensor index, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">take_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">take_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::take.out(Tensor self, Tensor index, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">take_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">take_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::take(Tensor self, Tensor index) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">take</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">take</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::take_along_dim.out(Tensor self, Tensor indices, int? dim=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">take_along_dim_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">take_along_dim_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::take_along_dim.out(Tensor self, Tensor indices, int? dim=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">take_along_dim_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">take_along_dim_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::take_along_dim(Tensor self, Tensor indices, int? dim=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">take_along_dim</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">take_along_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_select.out(Tensor self, int dim, Tensor index, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index_select_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_select_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_select.out(Tensor self, int dim, Tensor index, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index_select_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_select_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_select(Tensor self, int dim, Tensor index) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_select</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_select</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_select.dimname_out(Tensor self, Dimname dim, Tensor index, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index_select_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_select_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_select.dimname_out(Tensor self, Dimname dim, Tensor index, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index_select_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_select_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_select.dimname(Tensor self, Dimname dim, Tensor index) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_select</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_select_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_select_backward(Tensor grad, int[] self_sizes, int dim, Tensor index) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">index_select_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">self_sizes</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_select_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_select.out(Tensor self, Tensor mask, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">masked_select_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_select_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_select.out(Tensor self, Tensor mask, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">masked_select_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_select_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_select(Tensor self, Tensor mask) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">masked_select</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_select</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_select_backward(Tensor grad, Tensor input, Tensor mask) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">masked_select_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_select_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nonzero.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nonzero_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nonzero_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nonzero.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nonzero_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nonzero_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nonzero(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nonzero</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nonzero</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nonzero_numpy(Tensor self) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">nonzero_numpy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nonzero_numpy</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gather.out(Tensor self, int dim, Tensor index, *, bool sparse_grad=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gather_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse_grad</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gather_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gather.out(Tensor self, int dim, Tensor index, *, bool sparse_grad=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gather_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse_grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gather_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gather(Tensor self, int dim, Tensor index, *, bool sparse_grad=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">gather</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse_grad</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gather</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gather_backward(Tensor grad, Tensor self, int dim, Tensor index, bool sparse_grad) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">gather_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse_grad</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gather_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gather.dimname_out(Tensor self, Dimname dim, Tensor index, *, bool sparse_grad=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gather_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse_grad</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gather_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gather.dimname_out(Tensor self, Dimname dim, Tensor index, *, bool sparse_grad=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">gather_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse_grad</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gather_dimname_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gather.dimname(Tensor self, Dimname dim, Tensor index, *, bool sparse_grad=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">gather</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sparse_grad</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gather_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_gather_sparse_backward(Tensor self, int dim, Tensor index, Tensor grad) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_gather_sparse_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_gather_sparse_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcmul.out(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addcmul_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcmul_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcmul.out(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addcmul_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcmul_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcmul(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">addcmul</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcmul</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcdiv.out(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addcdiv_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcdiv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcdiv.out(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">addcdiv_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcdiv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcdiv(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">addcdiv</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcdiv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cross_entropy_loss(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, int ignore_index=-100) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cross_entropy_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="o">=</span><span class="mi">-100</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cross_entropy_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lstsq.X(Tensor self, Tensor A, *, Tensor(a!) X, Tensor(b!) qr) -&gt; (Tensor(a!) solution, Tensor(b!) QR)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">lstsq_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">X</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">qr</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lstsq_X</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">qr</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lstsq.X(Tensor self, Tensor A, *, Tensor(a!) X, Tensor(b!) qr) -&gt; (Tensor(a!) solution, Tensor(b!) QR)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">lstsq_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">X</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">qr</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lstsq_X</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">qr</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lstsq(Tensor self, Tensor A) -&gt; (Tensor solution, Tensor QR)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">lstsq</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lstsq</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triangular_solve.X(Tensor self, Tensor A, bool upper=True, bool transpose=False, bool unitriangular=False, *, Tensor(a!) X, Tensor(b!) M) -&gt; (Tensor(a!) solution, Tensor(b!) cloned_coefficient)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">triangular_solve_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">X</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">M</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transpose</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unitriangular</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triangular_solve_X</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">unitriangular</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triangular_solve.X(Tensor self, Tensor A, bool upper=True, bool transpose=False, bool unitriangular=False, *, Tensor(a!) X, Tensor(b!) M) -&gt; (Tensor(a!) solution, Tensor(b!) cloned_coefficient)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">triangular_solve_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transpose</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unitriangular</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">X</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">M</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triangular_solve_X</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">unitriangular</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triangular_solve(Tensor self, Tensor A, bool upper=True, bool transpose=False, bool unitriangular=False) -&gt; (Tensor solution, Tensor cloned_coefficient)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">triangular_solve</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transpose</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unitriangular</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triangular_solve</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">unitriangular</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::symeig.e(Tensor self, bool eigenvectors=False, bool upper=True, *, Tensor(a!) e, Tensor(b!) V) -&gt; (Tensor(a!) eigenvalues, Tensor(b!) eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">symeig_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">e</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">V</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">eigenvectors</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">symeig_e</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">V</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::symeig.e(Tensor self, bool eigenvectors=False, bool upper=True, *, Tensor(a!) e, Tensor(b!) V) -&gt; (Tensor(a!) eigenvalues, Tensor(b!) eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">symeig_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">e</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">V</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">symeig_e</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">V</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::symeig(Tensor self, bool eigenvectors=False, bool upper=True) -&gt; (Tensor eigenvalues, Tensor eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">symeig</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">eigenvectors</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">symeig</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="n">upper</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_symeig_helper(Tensor self, bool eigenvectors, bool upper) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_symeig_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_symeig_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="n">upper</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eig.e(Tensor self, bool eigenvectors=False, *, Tensor(a!) e, Tensor(b!) v) -&gt; (Tensor(a!) eigenvalues, Tensor(b!) eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">eig_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">e</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">v</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">eigenvectors</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eig_e</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">v</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eig.e(Tensor self, bool eigenvectors=False, *, Tensor(a!) e, Tensor(b!) v) -&gt; (Tensor(a!) eigenvalues, Tensor(b!) eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">eig_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">e</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">v</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eig_e</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">v</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eig(Tensor self, bool eigenvectors=False) -&gt; (Tensor eigenvalues, Tensor eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">eig</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">eigenvectors</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eig</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::svd.U(Tensor self, bool some=True, bool compute_uv=True, *, Tensor(a!) U, Tensor(b!) S, Tensor(c!) V) -&gt; (Tensor(a!) U, Tensor(b!) S, Tensor(c!) V)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">svd_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">U</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">S</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">V</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">some</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">compute_uv</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">svd_U</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">some</span><span class="p">,</span> <span class="n">compute_uv</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::svd.U(Tensor self, bool some=True, bool compute_uv=True, *, Tensor(a!) U, Tensor(b!) S, Tensor(c!) V) -&gt; (Tensor(a!) U, Tensor(b!) S, Tensor(c!) V)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">svd_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">some</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">compute_uv</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">U</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">S</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">V</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">svd_U</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">some</span><span class="p">,</span> <span class="n">compute_uv</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::svd(Tensor self, bool some=True, bool compute_uv=True) -&gt; (Tensor U, Tensor S, Tensor V)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">svd</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">some</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">compute_uv</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">svd</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">some</span><span class="p">,</span> <span class="n">compute_uv</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_svd_helper(Tensor self, bool some, bool compute_uv) -&gt; (Tensor U, Tensor S, Tensor V)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_svd_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">some</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">compute_uv</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_svd_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">some</span><span class="p">,</span> <span class="n">compute_uv</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::swapaxes(Tensor(a) self, int axis0, int axis1) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">swapaxes</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">axis1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">swapaxes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">axis0</span><span class="p">,</span> <span class="n">axis1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::swapdims(Tensor(a) self, int dim0, int dim1) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">swapdims</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim0</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">swapdims</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky.out(Tensor self, bool upper=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cholesky_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky.out(Tensor self, bool upper=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cholesky_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky(Tensor self, bool upper=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cholesky</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">upper</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky_solve.out(Tensor self, Tensor input2, bool upper=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cholesky_solve_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_solve_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky_solve.out(Tensor self, Tensor input2, bool upper=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cholesky_solve_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_solve_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky_solve(Tensor self, Tensor input2, bool upper=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cholesky_solve</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_solve</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">upper</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cholesky_solve_helper(Tensor self, Tensor A, bool upper) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cholesky_solve_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cholesky_solve_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">upper</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::solve(Tensor self, Tensor A) -&gt; (Tensor solution, Tensor LU)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">solve</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">solve</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::solve.solution(Tensor self, Tensor A, *, Tensor(a!) solution, Tensor(b!) lu) -&gt; (Tensor(a!) solution, Tensor(b!) LU)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">solve_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">solution</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lu</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">solve_solution</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">solution</span><span class="p">,</span> <span class="n">lu</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::solve.solution(Tensor self, Tensor A, *, Tensor(a!) solution, Tensor(b!) lu) -&gt; (Tensor(a!) solution, Tensor(b!) LU)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">solve_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">solution</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lu</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">solve_solution</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">solution</span><span class="p">,</span> <span class="n">lu</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_solve_helper(Tensor self, Tensor A) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_solve_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">A</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_solve_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky_inverse(Tensor self, bool upper=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">cholesky_inverse</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_inverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">upper</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky_inverse.out(Tensor self, bool upper=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cholesky_inverse_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_inverse_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky_inverse.out(Tensor self, bool upper=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">cholesky_inverse_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">upper</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_inverse_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::qr.Q(Tensor self, bool some=True, *, Tensor(a!) Q, Tensor(b!) R) -&gt; (Tensor(a!) Q, Tensor(b!) R)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">qr_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">Q</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">R</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">some</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">qr_Q</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">some</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">R</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::qr.Q(Tensor self, bool some=True, *, Tensor(a!) Q, Tensor(b!) R) -&gt; (Tensor(a!) Q, Tensor(b!) R)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">qr_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">some</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">Q</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">R</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">qr_Q</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">some</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">R</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::qr(Tensor self, bool some=True) -&gt; (Tensor Q, Tensor R)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">qr</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">some</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">qr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">some</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::geqrf.a(Tensor self, *, Tensor(a!) a, Tensor(b!) tau) -&gt; (Tensor(a!) a, Tensor(b!) tau)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">geqrf_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">a</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tau</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">geqrf_a</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">tau</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::geqrf.a(Tensor self, *, Tensor(a!) a, Tensor(b!) tau) -&gt; (Tensor(a!) a, Tensor(b!) tau)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">geqrf_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">a</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tau</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">geqrf_a</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">tau</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::geqrf(Tensor self) -&gt; (Tensor a, Tensor tau)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">geqrf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">geqrf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::orgqr(Tensor self, Tensor input2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">orgqr</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">orgqr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::orgqr.out(Tensor self, Tensor input2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">orgqr_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">orgqr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::orgqr.out(Tensor self, Tensor input2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">orgqr_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">orgqr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ormqr.out(Tensor self, Tensor input2, Tensor input3, bool left=True, bool transpose=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ormqr_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input3</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">left</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transpose</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ormqr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">input3</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ormqr.out(Tensor self, Tensor input2, Tensor input3, bool left=True, bool transpose=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ormqr_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input3</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">left</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ormqr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">input3</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ormqr(Tensor self, Tensor input2, Tensor input3, bool left=True, bool transpose=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ormqr</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input3</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">left</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">transpose</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ormqr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">input3</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">transpose</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_lu_with_info(Tensor self, bool pivot=True, bool check_errors=True) -&gt; (Tensor, Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_lu_with_info</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">pivot</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">check_errors</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_lu_with_info</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">check_errors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lu_solve.out(Tensor self, Tensor LU_data, Tensor LU_pivots, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lu_solve_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_pivots</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lu_solve_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lu_solve.out(Tensor self, Tensor LU_data, Tensor LU_pivots, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lu_solve_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lu_solve_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lu_solve(Tensor self, Tensor LU_data, Tensor LU_pivots) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">lu_solve</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_pivots</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lu_solve</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lu_unpack(Tensor LU_data, Tensor LU_pivots, bool unpack_data=True, bool unpack_pivots=True) -&gt; (Tensor P, Tensor L, Tensor U)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">lu_unpack</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unpack_data</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unpack_pivots</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lu_unpack</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">unpack_data</span><span class="p">,</span> <span class="n">unpack_pivots</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lu_unpack.out(Tensor LU_data, Tensor LU_pivots, bool unpack_data=True, bool unpack_pivots=True, *, Tensor(a!) P, Tensor(b!) L, Tensor(c!) U) -&gt; (Tensor(a!) P, Tensor(b!) L, Tensor(c!) U)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">lu_unpack_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">P</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">L</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">U</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unpack_data</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unpack_pivots</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lu_unpack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">unpack_data</span><span class="p">,</span> <span class="n">unpack_pivots</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">U</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lu_unpack.out(Tensor LU_data, Tensor LU_pivots, bool unpack_data=True, bool unpack_pivots=True, *, Tensor(a!) P, Tensor(b!) L, Tensor(c!) U) -&gt; (Tensor(a!) P, Tensor(b!) L, Tensor(c!) U)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">lu_unpack_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_data</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unpack_data</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unpack_pivots</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">P</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">L</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">U</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lu_unpack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">unpack_data</span><span class="p">,</span> <span class="n">unpack_pivots</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">U</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multinomial.out(Tensor self, int num_samples, bool replacement=False, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multinomial_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_samples</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">replacement</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multinomial_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">replacement</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multinomial.out(Tensor self, int num_samples, bool replacement=False, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multinomial_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_samples</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">replacement</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multinomial_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">replacement</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multinomial(Tensor self, int num_samples, bool replacement=False, *, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">multinomial</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">num_samples</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">replacement</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multinomial</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">replacement</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lgamma.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lgamma_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lgamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lgamma.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lgamma_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lgamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lgamma(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">lgamma</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lgamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::digamma.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">digamma_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">digamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::digamma.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">digamma_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">digamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::digamma(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">digamma</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">digamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::polygamma.out(int n, Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">polygamma_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">polygamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::polygamma.out(int n, Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">polygamma_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">polygamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::polygamma(int n, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">polygamma</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">polygamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erfinv(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">erfinv</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfinv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erfinv.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">erfinv_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfinv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erfinv.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">erfinv_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfinv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::i0(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">i0</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">i0</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::i0_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">i0_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">i0_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::i0.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">i0_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">i0_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::i0.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">i0_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">i0_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sign(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sign</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sign</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sign.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sign_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sign_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sign.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sign_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sign_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::signbit(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">signbit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">signbit</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::signbit.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">signbit_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">signbit_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::signbit.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">signbit_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">signbit_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dist(Tensor self, Tensor other, Scalar p=2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">dist</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atan2.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">atan2_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atan2.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">atan2_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atan2(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">atan2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lerp.Scalar_out(Tensor self, Tensor end, Scalar weight, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lerp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lerp.Scalar_out(Tensor self, Tensor end, Scalar weight, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lerp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lerp.Tensor_out(Tensor self, Tensor end, Tensor weight, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lerp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lerp.Tensor_out(Tensor self, Tensor end, Tensor weight, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lerp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lerp.Scalar(Tensor self, Tensor end, Scalar weight) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">lerp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lerp.Tensor(Tensor self, Tensor end, Tensor weight) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">lerp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">end</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histc.out(Tensor self, int bins=100, Scalar min=0, Scalar max=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">histc_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histc.out(Tensor self, int bins=100, Scalar min=0, Scalar max=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">histc_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">bins</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histc(Tensor self, int bins=100, Scalar min=0, Scalar max=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">histc</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">min</span><span class="p">,</span> <span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histogram.bins_tensor_out(Tensor self, Tensor bins, *, Tensor? weight=None, bool density=False, Tensor(a!) hist, Tensor(b!) bin_edges) -&gt; (Tensor(a!) hist, Tensor(b!) bin_edges)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">histogram_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hist</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bin_edges</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bins</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">density</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histogram_bins_tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="n">hist</span><span class="p">,</span> <span class="n">bin_edges</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histogram.bins_tensor_out(Tensor self, Tensor bins, *, Tensor? weight=None, bool density=False, Tensor(a!) hist, Tensor(b!) bin_edges) -&gt; (Tensor(a!) hist, Tensor(b!) bin_edges)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">histogram_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bins</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">density</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hist</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bin_edges</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histogram_bins_tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="n">hist</span><span class="p">,</span> <span class="n">bin_edges</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histogram.bins_tensor(Tensor self, Tensor bins, *, Tensor? weight=None, bool density=False) -&gt; (Tensor hist, Tensor bin_edges)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">histogram</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bins</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">density</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histogram_bins_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">density</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histogram.bin_ct_out(Tensor self, int bins=100, *, float[]? range=None, Tensor? weight=None, bool density=False, Tensor(a!) hist, Tensor(b!) bin_edges) -&gt; (Tensor(a!) hist, Tensor(b!) bin_edges)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">histogram_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hist</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bin_edges</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">range</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">density</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histogram_bin_ct_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">range</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="n">hist</span><span class="p">,</span> <span class="n">bin_edges</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histogram.bin_ct_out(Tensor self, int bins=100, *, float[]? range=None, Tensor? weight=None, bool density=False, Tensor(a!) hist, Tensor(b!) bin_edges) -&gt; (Tensor(a!) hist, Tensor(b!) bin_edges)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">histogram_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">bins</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">range</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">density</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hist</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bin_edges</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histogram_bin_ct_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">range</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="n">hist</span><span class="p">,</span> <span class="n">bin_edges</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histogram.bin_ct(Tensor self, int bins=100, *, float[]? range=None, Tensor? weight=None, bool density=False) -&gt; (Tensor hist, Tensor bin_edges)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">histogram</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">range</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">bool</span> <span class="n">density</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histogram_bin_ct</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">range</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">density</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fmod_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fmod_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fmod</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fmod_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fmod_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fmod</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hypot.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hypot_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hypot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hypot.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hypot_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hypot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hypot(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hypot</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hypot</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igamma.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">igamma_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igamma.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">igamma_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igamma(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">igamma</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igammac.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">igammac_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igammac_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igammac.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">igammac_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igammac_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igammac(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">igammac</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igammac</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nextafter.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nextafter_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nextafter_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nextafter.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nextafter_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nextafter_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nextafter(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nextafter</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nextafter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">remainder_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">remainder_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">remainder</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">remainder_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">remainder_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">remainder</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder.Scalar_Tensor(Scalar self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">remainder</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder_Scalar_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">min</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmin(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fmin</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmin.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fmin_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmin.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fmin_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmin_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmax(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmax.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fmax_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmax_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmax.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fmax_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmax_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::maximum(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">maximum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">maximum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::maximum.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">maximum_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">maximum_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::maximum.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">maximum_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">maximum_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.other(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::minimum(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">minimum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">minimum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::minimum.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">minimum_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">minimum_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::minimum.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">minimum_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">minimum_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">min_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.other(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">min</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.scalar_out(Tensor self, float q, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">quantile_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.scalar_out(Tensor self, float q, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">quantile_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantile</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.out(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">quantile_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.out(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">quantile_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantile</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.scalar_out(Tensor self, float q, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nanquantile_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.scalar_out(Tensor self, float q, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nanquantile_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nanquantile</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.out(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nanquantile_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.out(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nanquantile_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nanquantile</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.new_scalar_out(Tensor self, float q, int? dim, bool keepdim, *, str interpolation, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">quantile_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_new_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.new_scalar_out(Tensor self, float q, int? dim, bool keepdim, *, str interpolation, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">quantile_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_new_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.new_scalar(Tensor self, float q, int? dim, bool keepdim, *, str interpolation) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantile</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_new_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.new_out(Tensor self, Tensor q, int? dim, bool keepdim, *, str interpolation, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">quantile_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_new_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.new_out(Tensor self, Tensor q, int? dim, bool keepdim, *, str interpolation, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">quantile_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_new_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.new(Tensor self, Tensor q, int? dim, bool keepdim, *, str interpolation) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">quantile</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_new</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.new_scalar_out(Tensor self, float q, int? dim, bool keepdim, *, str interpolation, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nanquantile_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_new_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.new_scalar_out(Tensor self, float q, int? dim, bool keepdim, *, str interpolation, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nanquantile_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_new_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.new_scalar(Tensor self, float q, int? dim, bool keepdim, *, str interpolation) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nanquantile</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_new_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.new_out(Tensor self, Tensor q, int? dim, bool keepdim, *, str interpolation, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nanquantile_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_new_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.new_out(Tensor self, Tensor q, int? dim, bool keepdim, *, str interpolation, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nanquantile_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_new_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.new(Tensor self, Tensor q, int? dim, bool keepdim, *, str interpolation) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nanquantile</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">q</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">interpolation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_new</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">interpolation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.values(Tensor self, int dim=-1, bool descending=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">sort_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.values(Tensor self, int dim=-1, bool descending=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">sort_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.values_stable(Tensor self, *, bool? stable, int dim=-1, bool descending=False, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">sort_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">stable</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_values_stable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">stable</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.values_stable(Tensor self, *, bool? stable, int dim=-1, bool descending=False, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">sort_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">stable</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_values_stable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">stable</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort(Tensor self, int dim=-1, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">sort</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.stable(Tensor self, *, bool? stable, int dim=-1, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">sort</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">stable</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_stable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">stable</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.dimname_values(Tensor self, Dimname dim, bool descending=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">sort_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_dimname_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.dimname_values(Tensor self, Dimname dim, bool descending=False, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">sort_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_dimname_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.dimname_values_stable(Tensor self, *, bool? stable, Dimname dim, bool descending=False, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">sort_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">stable</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_dimname_values_stable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">stable</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.dimname_values_stable(Tensor self, *, bool? stable, Dimname dim, bool descending=False, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">sort_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">stable</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_dimname_values_stable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">stable</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.dimname(Tensor self, Dimname dim, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">sort</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.dimname_stable(Tensor self, *, bool? stable, Dimname dim, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">sort</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">stable</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_dimname_stable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">stable</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::msort.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">msort_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">msort_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::msort.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">msort_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">msort_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::msort(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">msort</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">msort</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argsort(Tensor self, int dim=-1, bool descending=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">argsort</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argsort</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argsort.dimname(Tensor self, Dimname dim, bool descending=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">argsort</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Dimname</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argsort_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::topk.values(Tensor self, int k, int dim=-1, bool largest=True, bool sorted=True, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">topk_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">largest</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sorted</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">topk_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">largest</span><span class="p">,</span> <span class="n">sorted</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::topk.values(Tensor self, int k, int dim=-1, bool largest=True, bool sorted=True, *, Tensor(a!) values, Tensor(b!) indices) -&gt; (Tensor(a!) values, Tensor(b!) indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">topk_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">largest</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sorted</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">topk_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">largest</span><span class="p">,</span> <span class="n">sorted</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::topk(Tensor self, int k, int dim=-1, bool largest=True, bool sorted=True) -&gt; (Tensor values, Tensor indices)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">topk</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">k</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">largest</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">sorted</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">topk</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">largest</span><span class="p">,</span> <span class="n">sorted</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">all</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">any</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::renorm.out(Tensor self, Scalar p, int dim, Scalar maxnorm, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">renorm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">maxnorm</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">renorm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">maxnorm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::renorm.out(Tensor self, Scalar p, int dim, Scalar maxnorm, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">renorm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">maxnorm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">renorm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">maxnorm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::renorm(Tensor self, Scalar p, int dim, Scalar maxnorm) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">renorm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">maxnorm</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">renorm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">maxnorm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unfold_backward(Tensor grad_in, int[] input_sizes, int dim, int size, int step) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">unfold_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_in</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">step</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unfold_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_in</span><span class="p">,</span> <span class="n">input_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::equal(Tensor self, Tensor other) -&gt; bool</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">bool</span> <span class="n">equal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">equal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Tensor_Tensor_out(Tensor self, Tensor exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">pow_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Tensor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Tensor_Tensor_out(Tensor self, Tensor exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">pow_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Tensor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Tensor_Tensor(Tensor self, Tensor exponent) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">pow</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Tensor_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Scalar_out(Scalar self, Tensor exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">pow_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Scalar_out(Scalar self, Tensor exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">pow_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Scalar(Scalar self, Tensor exponent) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">pow</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Tensor_Scalar_out(Tensor self, Scalar exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">pow_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Tensor_Scalar_out(Tensor self, Scalar exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">pow_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">pow</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Tensor_Tensor_out(Tensor self, Tensor exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">float_power_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Tensor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Tensor_Tensor_out(Tensor self, Tensor exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">float_power_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Tensor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Tensor_Tensor(Tensor self, Tensor exponent) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">float_power</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Tensor_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Scalar_out(Scalar self, Tensor exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">float_power_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Scalar_out(Scalar self, Tensor exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">float_power_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Scalar(Scalar self, Tensor exponent) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">float_power</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Tensor_Scalar_out(Tensor self, Scalar exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">float_power_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Tensor_Scalar_out(Tensor self, Scalar exponent, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">float_power_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Tensor_Scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Tensor_Scalar(Tensor self, Scalar exponent) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">float_power</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">exponent</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.Tensor_float_out(Tensor mean, float std=1, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">normal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_Tensor_float_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.Tensor_float_out(Tensor mean, float std=1, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">normal_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">std</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_Tensor_float_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.Tensor_float(Tensor mean, float std=1, *, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">normal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_Tensor_float</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.float_Tensor_out(float mean, Tensor std, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">normal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">double</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_float_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.float_Tensor_out(float mean, Tensor std, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">normal_outf</span><span class="p">(</span><span class="kt">double</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_float_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.float_Tensor(float mean, Tensor std, *, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">normal</span><span class="p">(</span><span class="kt">double</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_float_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.Tensor_Tensor_out(Tensor mean, Tensor std, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">normal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_Tensor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.Tensor_Tensor_out(Tensor mean, Tensor std, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">normal_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_Tensor_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.Tensor_Tensor(Tensor mean, Tensor std, *, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">normal</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mean</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">std</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_Tensor_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.float_float(float mean, float std, int[] size, *, Generator? generator=None, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">normal</span><span class="p">(</span><span class="kt">double</span> <span class="n">mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">std</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_float_float</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::normal.float_float(float mean, float std, int[] size, *, Generator? generator=None, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">normal</span><span class="p">(</span><span class="kt">double</span> <span class="n">mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">std</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_float_float</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.float_float_out(float mean, float std, int[] size, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">normal_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">double</span> <span class="n">mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">std</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_float_float_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal.float_float_out(float mean, float std, int[] size, *, Generator? generator=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">normal_outf</span><span class="p">(</span><span class="kt">double</span> <span class="n">mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">std</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_float_float_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::alias(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">alias</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">alias</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_index_copy_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">source</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_index_copy_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cumsum(Tensor self, int dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cumsum</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cumsum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cumsum.out(Tensor self, int dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_cumsum_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cumsum_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cumsum.out(Tensor self, int dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_cumsum_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cumsum_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cumprod(Tensor self, int dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cumprod</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cumprod</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cumprod.out(Tensor self, int dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_cumprod_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cumprod_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cumprod.out(Tensor self, int dim, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_cumprod_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cumprod_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_amp_foreach_non_finite_check_and_unscale_(Tensor(a!)[] self, Tensor(b!) found_inf, Tensor inv_scale) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_amp_foreach_non_finite_check_and_unscale_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">found_inf</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">inv_scale</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_amp_foreach_non_finite_check_and_unscale_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">found_inf</span><span class="p">,</span> <span class="n">inv_scale</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_amp_update_scale_(Tensor(a!) self, Tensor(b!) growth_tracker, Tensor found_inf, float scale_growth_factor, float scale_backoff_factor, int growth_interval) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_amp_update_scale_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">growth_tracker</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">found_inf</span><span class="p">,</span> <span class="kt">double</span> <span class="n">scale_growth_factor</span><span class="p">,</span> <span class="kt">double</span> <span class="n">scale_backoff_factor</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">growth_interval</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_amp_update_scale_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">growth_tracker</span><span class="p">,</span> <span class="n">found_inf</span><span class="p">,</span> <span class="n">scale_growth_factor</span><span class="p">,</span> <span class="n">scale_backoff_factor</span><span class="p">,</span> <span class="n">growth_interval</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cat(Tensor[] tensors, int dim=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_cat</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cat</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cat.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_cat_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cat_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_cat.out(Tensor[] tensors, int dim=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_cat_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_cat_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_add.Scalar(Tensor[] tensors, Scalar scalar) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_add</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_add_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">scalar</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_add_.Scalar(Tensor(a!)[] self, Scalar scalar) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_add_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_add__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scalar</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sub.Scalar(Tensor[] tensors, Scalar scalar) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_sub</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sub_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">scalar</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sub_.Scalar(Tensor(a!)[] self, Scalar scalar) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_sub_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sub__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scalar</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_mul.Scalar(Tensor[] tensors, Scalar scalar) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_mul</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_mul_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">scalar</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_mul_.Scalar(Tensor(a!)[] self, Scalar scalar) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_mul_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_mul__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scalar</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_div.Scalar(Tensor[] tensors, Scalar scalar) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_div</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_div_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">scalar</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_div_.Scalar(Tensor(a!)[] self, Scalar scalar) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_div_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scalar</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_div__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scalar</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_add.List(Tensor[] tensors1, Tensor[] tensors2, *, Scalar alpha=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_add</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_add_List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors1</span><span class="p">,</span> <span class="n">tensors2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_add_.List(Tensor(a!)[] self, Tensor[] other, *, Scalar alpha=1) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_add_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_add__List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sub.List(Tensor[] tensors1, Tensor[] tensors2, *, Scalar alpha=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_sub</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sub_List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors1</span><span class="p">,</span> <span class="n">tensors2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sub_.List(Tensor(a!)[] self, Tensor[] other, *, Scalar alpha=1) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_sub_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sub__List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_mul.List(Tensor[] tensors1, Tensor[] tensors2) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_mul</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_mul_List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors1</span><span class="p">,</span> <span class="n">tensors2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_mul_.List(Tensor(a!)[] self, Tensor[] other) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_mul_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_mul__List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_div.List(Tensor[] tensors1, Tensor[] tensors2) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_div</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_div_List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors1</span><span class="p">,</span> <span class="n">tensors2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_div_.List(Tensor(a!)[] self, Tensor[] other) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_div_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_div__List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_add.ScalarList(Tensor[] tensors, Scalar[] scalars) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_add</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_add_ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_add_.ScalarList(Tensor(a!)[] self, Scalar[] scalars) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_add_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_add__ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sub.ScalarList(Tensor[] tensors, Scalar[] scalars) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_sub</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sub_ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sub_.ScalarList(Tensor(a!)[] self, Scalar[] scalars) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_sub_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sub__ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_div.ScalarList(Tensor[] tensors, Scalar[] scalars) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_div</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_div_ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_div_.ScalarList(Tensor(a!)[] self, Scalar[] scalars) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_div_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_div__ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_mul.ScalarList(Tensor[] tensors, Scalar[] scalars) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_mul</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_mul_ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_mul_.ScalarList(Tensor(a!)[] self, Scalar[] scalars) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_mul_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_mul__ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_exp(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_exp</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_exp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_zero_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_zero_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_zero_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_exp_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_exp_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_exp_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sqrt(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_sqrt</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sqrt</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sqrt_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_sqrt_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sqrt_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_abs(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_abs</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_abs</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_abs_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_abs_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_abs_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_acos(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_acos</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_acos</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_acos_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_acos_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_acos_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_asin(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_asin</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_asin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_asin_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_asin_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_asin_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_atan(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_atan</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_atan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_atan_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_atan_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_atan_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_ceil(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_ceil</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_ceil</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_ceil_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_ceil_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_ceil_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_cos(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_cos</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_cos</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_cos_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_cos_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_cos_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_cosh(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_cosh</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_cosh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_cosh_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_cosh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_cosh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_erf(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_erf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_erf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_erf_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_erf_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_erf_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_erfc(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_erfc</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_erfc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_erfc_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_erfc_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_erfc_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_expm1(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_expm1</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_expm1</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_expm1_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_expm1_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_expm1_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_floor(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_floor</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_floor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_floor_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_floor_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_floor_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_log(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_log</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_log</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_log_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_log_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_log_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_log10(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_log10</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_log10</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_log10_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_log10_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_log10_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_log1p(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_log1p</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_log1p</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_log1p_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_log1p_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_log1p_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_log2(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_log2</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_log2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_log2_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_log2_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_log2_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_neg(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_neg</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_neg</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_neg_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_neg_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_neg_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_tan(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_tan</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_tan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_tan_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_tan_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_tan_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_tanh(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_tanh</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_tanh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_tanh_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_tanh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_tanh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sin(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_sin</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sin_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_sin_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sin_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sinh(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_sinh</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sinh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sinh_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_sinh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sinh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_round(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_round</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_round</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_round_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_round_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_round_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_lgamma(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_lgamma</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_lgamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_lgamma_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_lgamma_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_lgamma_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_frac(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_frac</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_frac</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_frac_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_frac_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_frac_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_reciprocal(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_reciprocal</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_reciprocal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_reciprocal_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_reciprocal_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_reciprocal_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sigmoid(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_sigmoid</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sigmoid</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_sigmoid_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_sigmoid_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_sigmoid_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_trunc(Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_trunc</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_trunc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_trunc_(Tensor(a!)[] self) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_trunc_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_trunc_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_addcdiv_.Scalar(Tensor(a!)[] self, Tensor[] tensor1, Tensor[] tensor2, Scalar value=1) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_addcdiv_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_addcdiv__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_addcmul_.Scalar(Tensor(a!)[] self, Tensor[] tensor1, Tensor[] tensor2, Scalar value=1) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_addcmul_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_addcmul__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_addcdiv_.ScalarList(Tensor(a!)[] self, Tensor[] tensor1, Tensor[] tensor2, Scalar[] scalars) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_addcdiv_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_addcdiv__ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_addcmul_.ScalarList(Tensor(a!)[] self, Tensor[] tensor1, Tensor[] tensor2, Scalar[] scalars) -&gt; ()</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">_foreach_addcmul_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_addcmul__ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_addcdiv.Scalar(Tensor[] input, Tensor[] tensor1, Tensor[] tensor2, Scalar value=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_addcdiv</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_addcdiv_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_addcmul.Scalar(Tensor[] input, Tensor[] tensor1, Tensor[] tensor2, Scalar value=1) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_addcmul</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor2</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_addcmul_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_addcdiv.ScalarList(Tensor[] input, Tensor[] tensor1, Tensor[] tensor2, Scalar[] scalars) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_addcdiv</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_addcdiv_ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_addcmul.ScalarList(Tensor[] input, Tensor[] tensor1, Tensor[] tensor2, Scalar[] scalars) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_addcmul</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="n">scalars</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_addcmul_ScalarList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">scalars</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_maximum.List(Tensor[] tensors1, Tensor[] tensors2) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_maximum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_maximum_List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors1</span><span class="p">,</span> <span class="n">tensors2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_foreach_minimum.List(Tensor[] tensors1, Tensor[] tensors2) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_foreach_minimum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_foreach_minimum_List</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors1</span><span class="p">,</span> <span class="n">tensors2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bucketize.Tensor(Tensor self, Tensor boundaries, *, bool out_int32=False, bool right=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bucketize</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">boundaries</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">out_int32</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">right</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bucketize_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">out_int32</span><span class="p">,</span> <span class="n">right</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bucketize.Tensor_out(Tensor self, Tensor boundaries, *, bool out_int32=False, bool right=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bucketize_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">boundaries</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">out_int32</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">right</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bucketize_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">out_int32</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bucketize.Tensor_out(Tensor self, Tensor boundaries, *, bool out_int32=False, bool right=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">bucketize_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">boundaries</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">out_int32</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">right</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bucketize_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">out_int32</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bucketize.Scalar(Scalar self, Tensor boundaries, *, bool out_int32=False, bool right=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">bucketize</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">boundaries</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">out_int32</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">right</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bucketize_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">out_int32</span><span class="p">,</span> <span class="n">right</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::searchsorted.Tensor(Tensor sorted_sequence, Tensor self, *, bool out_int32=False, bool right=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">searchsorted</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sorted_sequence</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">out_int32</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">right</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">searchsorted_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sorted_sequence</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">out_int32</span><span class="p">,</span> <span class="n">right</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::searchsorted.Tensor_out(Tensor sorted_sequence, Tensor self, *, bool out_int32=False, bool right=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">searchsorted_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sorted_sequence</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">out_int32</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">right</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">searchsorted_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sorted_sequence</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">out_int32</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::searchsorted.Tensor_out(Tensor sorted_sequence, Tensor self, *, bool out_int32=False, bool right=False, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">searchsorted_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sorted_sequence</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">out_int32</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">right</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">searchsorted_Tensor_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sorted_sequence</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">out_int32</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::searchsorted.Scalar(Tensor sorted_sequence, Scalar self, *, bool out_int32=False, bool right=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">searchsorted</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sorted_sequence</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">out_int32</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">right</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">searchsorted_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sorted_sequence</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">out_int32</span><span class="p">,</span> <span class="n">right</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mse_loss.out(Tensor self, Tensor target, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mse_loss_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mse_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mse_loss.out(Tensor self, Tensor target, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mse_loss_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mse_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mse_loss(Tensor self, Tensor target, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mse_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mse_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mse_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mse_loss_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mse_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mse_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">mse_loss_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mse_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mse_loss_backward(Tensor grad_output, Tensor self, Tensor target, int reduction) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mse_loss_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mse_loss_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::l1_loss.out(Tensor self, Tensor target, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">l1_loss_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">l1_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::l1_loss.out(Tensor self, Tensor target, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">l1_loss_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">l1_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::l1_loss(Tensor self, Tensor target, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">l1_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">l1_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::l1_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">l1_loss_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">l1_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::l1_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">l1_loss_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">l1_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::l1_loss_backward(Tensor grad_output, Tensor self, Tensor target, int reduction) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">l1_loss_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">l1_loss_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multi_margin_loss.out(Tensor self, Tensor target, Scalar p=1, Scalar margin=1, Tensor? weight=None, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multi_margin_loss_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">margin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multi_margin_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multi_margin_loss.out(Tensor self, Tensor target, Scalar p=1, Scalar margin=1, Tensor? weight=None, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multi_margin_loss_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">margin</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multi_margin_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multi_margin_loss(Tensor self, Tensor target, Scalar p=1, Scalar margin=1, Tensor? weight=None, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">multi_margin_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">margin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multi_margin_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multi_margin_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, Scalar p, Scalar margin, Tensor? weight=None, int reduction=Mean, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multi_margin_loss_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">margin</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multi_margin_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multi_margin_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, Scalar p, Scalar margin, Tensor? weight=None, int reduction=Mean, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multi_margin_loss_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">margin</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multi_margin_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multi_margin_loss_backward(Tensor grad_output, Tensor self, Tensor target, Scalar p, Scalar margin, Tensor? weight=None, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">multi_margin_loss_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">margin</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multi_margin_loss_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multilabel_margin_loss.out(Tensor self, Tensor target, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multilabel_margin_loss_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multilabel_margin_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multilabel_margin_loss.out(Tensor self, Tensor target, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multilabel_margin_loss_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multilabel_margin_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multilabel_margin_loss(Tensor self, Tensor target, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">multilabel_margin_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multilabel_margin_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multilabel_margin_loss_forward.output(Tensor self, Tensor target, int reduction, *, Tensor(a!) output, Tensor(b!) is_target) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">multilabel_margin_loss_forward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">is_target</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multilabel_margin_loss_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">is_target</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multilabel_margin_loss_forward.output(Tensor self, Tensor target, int reduction, *, Tensor(a!) output, Tensor(b!) is_target) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">multilabel_margin_loss_forward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">is_target</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multilabel_margin_loss_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">is_target</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multilabel_margin_loss_forward(Tensor self, Tensor target, int reduction) -&gt; (Tensor output, Tensor is_target)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">multilabel_margin_loss_forward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multilabel_margin_loss_forward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multilabel_margin_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, Tensor is_target, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multilabel_margin_loss_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">is_target</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multilabel_margin_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">is_target</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multilabel_margin_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, Tensor is_target, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">multilabel_margin_loss_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">is_target</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multilabel_margin_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">is_target</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multilabel_margin_loss_backward(Tensor grad_output, Tensor self, Tensor target, int reduction, Tensor is_target) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">multilabel_margin_loss_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">is_target</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multilabel_margin_loss_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">is_target</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss.out(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, int ignore_index=-100, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nll_loss_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="o">=</span><span class="mi">-100</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss.out(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, int ignore_index=-100, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nll_loss_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss_nd(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, int ignore_index=-100) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nll_loss_nd</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="o">=</span><span class="mi">-100</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss_nd</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, int ignore_index=-100) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nll_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="o">=</span><span class="mi">-100</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss_forward.output(Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, *, Tensor(a!) output, Tensor(b!) total_weight) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">nll_loss_forward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss_forward.output(Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, *, Tensor(a!) output, Tensor(b!) total_weight) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">nll_loss_forward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss_forward(Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index) -&gt; (Tensor output, Tensor total_weight)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">nll_loss_forward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss_forward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, Tensor total_weight, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nll_loss_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, Tensor total_weight, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nll_loss_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss_backward(Tensor grad_output, Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, Tensor total_weight) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nll_loss_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss2d.out(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, int ignore_index=-100, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nll_loss2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="o">=</span><span class="mi">-100</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss2d.out(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, int ignore_index=-100, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nll_loss2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss2d(Tensor self, Tensor target, Tensor? weight=None, int reduction=Mean, int ignore_index=-100) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nll_loss2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="o">=</span><span class="mi">-100</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss2d_forward.output(Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, *, Tensor(a!) output, Tensor(b!) total_weight) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">nll_loss2d_forward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss2d_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss2d_forward.output(Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, *, Tensor(a!) output, Tensor(b!) total_weight) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">nll_loss2d_forward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss2d_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss2d_forward(Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index) -&gt; (Tensor output, Tensor total_weight)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">nll_loss2d_forward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss2d_forward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, Tensor total_weight, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nll_loss2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, Tensor total_weight, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">nll_loss2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nll_loss2d_backward(Tensor grad_output, Tensor self, Tensor target, Tensor? weight, int reduction, int ignore_index, Tensor total_weight) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">nll_loss2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">total_weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nll_loss2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">ignore_index</span><span class="p">,</span> <span class="n">total_weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::smooth_l1_loss.out(Tensor self, Tensor target, int reduction=Mean, float beta=1.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">smooth_l1_loss_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">smooth_l1_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::smooth_l1_loss.out(Tensor self, Tensor target, int reduction=Mean, float beta=1.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">smooth_l1_loss_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">smooth_l1_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::smooth_l1_loss(Tensor self, Tensor target, int reduction=Mean, float beta=1.0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">smooth_l1_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">smooth_l1_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">beta</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::smooth_l1_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, float beta, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">smooth_l1_loss_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">smooth_l1_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::smooth_l1_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, float beta, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">smooth_l1_loss_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">smooth_l1_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::smooth_l1_loss_backward(Tensor grad_output, Tensor self, Tensor target, int reduction, float beta) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">smooth_l1_loss_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">double</span> <span class="n">beta</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">smooth_l1_loss_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">beta</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::huber_loss.out(Tensor self, Tensor target, int reduction=Mean, float delta=1.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">huber_loss_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">huber_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::huber_loss.out(Tensor self, Tensor target, int reduction=Mean, float delta=1.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">huber_loss_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">double</span> <span class="n">delta</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">huber_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::huber_loss(Tensor self, Tensor target, int reduction=Mean, float delta=1.0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">huber_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">,</span> <span class="kt">double</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">huber_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">delta</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::huber_loss_backward.out(Tensor grad_output, Tensor self, Tensor target, int reduction, float delta, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">huber_loss_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">double</span> <span class="n">delta</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">huber_loss_backward_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::huber_loss_backward.out(Tensor grad_output, Tensor self, Tensor target, int reduction, float delta, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">huber_loss_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">double</span> <span class="n">delta</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">huber_loss_backward_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::huber_loss_backward(Tensor grad_output, Tensor self, Tensor target, int reduction, float delta) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">huber_loss_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="kt">double</span> <span class="n">delta</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">huber_loss_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">delta</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::soft_margin_loss.out(Tensor self, Tensor target, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">soft_margin_loss_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">soft_margin_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::soft_margin_loss.out(Tensor self, Tensor target, int reduction=Mean, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">soft_margin_loss_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">soft_margin_loss_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::soft_margin_loss(Tensor self, Tensor target, int reduction=Mean) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">soft_margin_loss</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="o">=</span><span class="n">at</span><span class="o">::</span><span class="n">Reduction</span><span class="o">::</span><span class="n">Mean</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">soft_margin_loss</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::soft_margin_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">soft_margin_loss_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">soft_margin_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::soft_margin_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">soft_margin_loss_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">soft_margin_loss_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::soft_margin_loss_backward(Tensor grad_output, Tensor self, Tensor target, int reduction) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">soft_margin_loss_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">target</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">reduction</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">soft_margin_loss_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::elu.out(Tensor self, Scalar alpha=1, Scalar scale=1, Scalar input_scale=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elu_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">input_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">elu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::elu.out(Tensor self, Scalar alpha=1, Scalar scale=1, Scalar input_scale=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elu_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">input_scale</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">elu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::elu(Tensor self, Scalar alpha=1, Scalar scale=1, Scalar input_scale=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">elu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">input_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">elu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::elu_backward.grad_input(Tensor grad_output, Scalar alpha, Scalar scale, Scalar input_scale, bool is_result, Tensor self_or_result, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elu_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">input_scale</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">is_result</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self_or_result</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">elu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">,</span> <span class="n">is_result</span><span class="p">,</span> <span class="n">self_or_result</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::elu_backward.grad_input(Tensor grad_output, Scalar alpha, Scalar scale, Scalar input_scale, bool is_result, Tensor self_or_result, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elu_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">input_scale</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">is_result</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self_or_result</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">elu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">,</span> <span class="n">is_result</span><span class="p">,</span> <span class="n">self_or_result</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::elu_backward(Tensor grad_output, Scalar alpha, Scalar scale, Scalar input_scale, bool is_result, Tensor self_or_result) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">elu_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">input_scale</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">is_result</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self_or_result</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">elu_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">,</span> <span class="n">is_result</span><span class="p">,</span> <span class="n">self_or_result</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::elu_(Tensor(a!) self, Scalar alpha=1, Scalar scale=1, Scalar input_scale=1) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">elu_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">input_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">elu_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::glu.out(Tensor self, int dim=-1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">glu_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">glu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::glu.out(Tensor self, int dim=-1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">glu_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">glu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::glu(Tensor self, int dim=-1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">glu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">glu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::glu_backward.grad_input(Tensor grad_output, Tensor self, int dim, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">glu_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">glu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::glu_backward.grad_input(Tensor grad_output, Tensor self, int dim, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">glu_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">glu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::glu_backward(Tensor grad_output, Tensor self, int dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">glu_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">glu_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardsigmoid.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardsigmoid_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardsigmoid_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardsigmoid.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardsigmoid_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardsigmoid_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardsigmoid(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hardsigmoid</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardsigmoid</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardsigmoid_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardsigmoid_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardsigmoid_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardsigmoid_backward.grad_input(Tensor grad_output, Tensor self, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardsigmoid_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardsigmoid_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardsigmoid_backward.grad_input(Tensor grad_output, Tensor self, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardsigmoid_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardsigmoid_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardsigmoid_backward(Tensor grad_output, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hardsigmoid_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardsigmoid_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardtanh.out(Tensor self, Scalar min_val=-1, Scalar max_val=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardtanh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min_val</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max_val</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardtanh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardtanh.out(Tensor self, Scalar min_val=-1, Scalar max_val=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardtanh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min_val</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max_val</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardtanh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardtanh(Tensor self, Scalar min_val=-1, Scalar max_val=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hardtanh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min_val</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max_val</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardtanh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardtanh_backward.grad_input(Tensor grad_output, Tensor self, Scalar min_val, Scalar max_val, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardtanh_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min_val</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max_val</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardtanh_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardtanh_backward.grad_input(Tensor grad_output, Tensor self, Scalar min_val, Scalar max_val, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardtanh_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min_val</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max_val</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardtanh_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardtanh_backward(Tensor grad_output, Tensor self, Scalar min_val, Scalar max_val) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hardtanh_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min_val</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max_val</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardtanh_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardtanh_(Tensor(a!) self, Scalar min_val=-1, Scalar max_val=1) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardtanh_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">min_val</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">max_val</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardtanh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardswish.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardswish_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardswish_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardswish.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardswish_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardswish_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardswish(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hardswish</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardswish</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardswish_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">hardswish_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardswish_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardswish_backward(Tensor grad_output, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">hardswish_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardswish_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::leaky_relu.out(Tensor self, Scalar negative_slope=0.01, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">leaky_relu_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">leaky_relu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::leaky_relu.out(Tensor self, Scalar negative_slope=0.01, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">leaky_relu_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">leaky_relu_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::leaky_relu(Tensor self, Scalar negative_slope=0.01) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">leaky_relu</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">leaky_relu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::leaky_relu_backward.grad_input(Tensor grad_output, Tensor self, Scalar negative_slope, bool self_is_result, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">leaky_relu_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">self_is_result</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">leaky_relu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="n">self_is_result</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::leaky_relu_backward.grad_input(Tensor grad_output, Tensor self, Scalar negative_slope, bool self_is_result, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">leaky_relu_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">self_is_result</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">leaky_relu_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="n">self_is_result</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::leaky_relu_backward(Tensor grad_output, Tensor self, Scalar negative_slope, bool self_is_result) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">leaky_relu_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">self_is_result</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">leaky_relu_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">,</span> <span class="n">self_is_result</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::leaky_relu_(Tensor(a!) self, Scalar negative_slope=0.01) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">leaky_relu_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">leaky_relu_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_sigmoid.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_sigmoid_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_sigmoid_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_sigmoid.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_sigmoid_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_sigmoid_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_sigmoid(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">log_sigmoid</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_sigmoid</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_sigmoid_forward.output(Tensor self, *, Tensor(a!) output, Tensor(b!) buffer) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">log_sigmoid_forward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">buffer</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_sigmoid_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">buffer</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_sigmoid_forward.output(Tensor self, *, Tensor(a!) output, Tensor(b!) buffer) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">log_sigmoid_forward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">buffer</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_sigmoid_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">buffer</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_sigmoid_forward(Tensor self) -&gt; (Tensor output, Tensor buffer)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">log_sigmoid_forward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_sigmoid_forward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_sigmoid_backward.grad_input(Tensor grad_output, Tensor self, Tensor buffer, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_sigmoid_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">buffer</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_sigmoid_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_sigmoid_backward.grad_input(Tensor grad_output, Tensor self, Tensor buffer, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">log_sigmoid_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_sigmoid_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_sigmoid_backward(Tensor grad_output, Tensor self, Tensor buffer) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">log_sigmoid_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">buffer</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_sigmoid_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">buffer</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rrelu_with_noise.out(Tensor self, Tensor noise, Scalar lower=0.125, Scalar upper=0.3333333333333333, bool training=False, Generator? generator=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rrelu_with_noise_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">noise</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.125</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.3333333333333333</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rrelu_with_noise_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rrelu_with_noise.out(Tensor self, Tensor noise, Scalar lower=0.125, Scalar upper=0.3333333333333333, bool training=False, Generator? generator=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rrelu_with_noise_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">noise</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lower</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">upper</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rrelu_with_noise_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rrelu_with_noise(Tensor self, Tensor noise, Scalar lower=0.125, Scalar upper=0.3333333333333333, bool training=False, Generator? generator=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rrelu_with_noise</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">noise</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.125</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.3333333333333333</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rrelu_with_noise</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rrelu_with_noise_backward(Tensor grad_output, Tensor self, Tensor noise, Scalar lower, Scalar upper, bool training, bool self_is_result) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">rrelu_with_noise_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">noise</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lower</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">upper</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">self_is_result</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rrelu_with_noise_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">self_is_result</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rrelu_with_noise_(Tensor(a!) self, Tensor noise, Scalar lower=0.125, Scalar upper=0.3333333333333333, bool training=False, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rrelu_with_noise_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">noise</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.125</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.3333333333333333</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">training</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span> <span class="n">generator</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rrelu_with_noise_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softplus.out(Tensor self, Scalar beta=1, Scalar threshold=20, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">softplus_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softplus_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softplus.out(Tensor self, Scalar beta=1, Scalar threshold=20, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">softplus_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softplus_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softplus(Tensor self, Scalar beta=1, Scalar threshold=20) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">softplus</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softplus</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">threshold</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softplus_backward.grad_input(Tensor grad_output, Tensor self, Scalar beta, Scalar threshold, Tensor output, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">softplus_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softplus_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softplus_backward.grad_input(Tensor grad_output, Tensor self, Scalar beta, Scalar threshold, Tensor output, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">softplus_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softplus_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softplus_backward(Tensor grad_output, Tensor self, Scalar beta, Scalar threshold, Tensor output) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">softplus_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">beta</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">threshold</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softplus_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">output</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softshrink.out(Tensor self, Scalar lambd=0.5, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">softshrink_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softshrink_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softshrink.out(Tensor self, Scalar lambd=0.5, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">softshrink_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softshrink_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softshrink(Tensor self, Scalar lambd=0.5) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">softshrink</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softshrink</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softshrink_backward.grad_input(Tensor grad_output, Tensor self, Scalar lambd, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">softshrink_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softshrink_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softshrink_backward.grad_input(Tensor grad_output, Tensor self, Scalar lambd, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">softshrink_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softshrink_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softshrink_backward(Tensor grad_output, Tensor self, Scalar lambd) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">softshrink_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">lambd</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softshrink_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_avg_pool2d.out(Tensor self, int[2] output_size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_avg_pool2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_avg_pool2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_avg_pool2d.out(Tensor self, int[2] output_size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_avg_pool2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_avg_pool2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_avg_pool2d(Tensor self, int[2] output_size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">adaptive_avg_pool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_avg_pool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_adaptive_avg_pool2d(Tensor self, int[2] output_size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_adaptive_avg_pool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_adaptive_avg_pool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mkldnn_adaptive_avg_pool2d_backward(Tensor grad_output, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">mkldnn_adaptive_avg_pool2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mkldnn_adaptive_avg_pool2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_adaptive_avg_pool2d(Tensor self, int[2] output_size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_adaptive_avg_pool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_adaptive_avg_pool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_adaptive_avg_pool2d_backward(Tensor grad_output, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_adaptive_avg_pool2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_adaptive_avg_pool2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_avg_pool3d.out(Tensor self, int[3] output_size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_avg_pool3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_avg_pool3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_avg_pool3d.out(Tensor self, int[3] output_size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_avg_pool3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_avg_pool3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_avg_pool3d(Tensor self, int[3] output_size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">adaptive_avg_pool3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_avg_pool3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_adaptive_avg_pool3d(Tensor self, int[3] output_size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_adaptive_avg_pool3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_adaptive_avg_pool3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_avg_pool3d_backward.grad_input(Tensor grad_output, Tensor self, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_avg_pool3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_avg_pool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_avg_pool3d_backward.grad_input(Tensor grad_output, Tensor self, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_avg_pool3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_avg_pool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_adaptive_avg_pool3d_backward(Tensor grad_output, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_adaptive_avg_pool3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_adaptive_avg_pool3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool2d.out(Tensor self, int[2] output_size, *, Tensor(a!) out, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">adaptive_max_pool2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool2d.out(Tensor self, int[2] output_size, *, Tensor(a!) out, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">adaptive_max_pool2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool2d(Tensor self, int[2] output_size) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">adaptive_max_pool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_max_pool2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_max_pool2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool2d_backward(Tensor grad_output, Tensor self, Tensor indices) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">adaptive_max_pool2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool3d.out(Tensor self, int[3] output_size, *, Tensor(a!) out, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">adaptive_max_pool3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool3d.out(Tensor self, int[3] output_size, *, Tensor(a!) out, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">adaptive_max_pool3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool3d(Tensor self, int[3] output_size) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">adaptive_max_pool3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool3d_backward.grad_input(Tensor grad_output, Tensor self, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_max_pool3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool3d_backward.grad_input(Tensor grad_output, Tensor self, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">adaptive_max_pool3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::adaptive_max_pool3d_backward(Tensor grad_output, Tensor self, Tensor indices) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">adaptive_max_pool3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adaptive_max_pool3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool2d.out(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, bool ceil_mode=False, bool count_include_pad=True, int? divisor_override=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">avg_pool2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool2d.out(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, bool ceil_mode=False, bool count_include_pad=True, int? divisor_override=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">avg_pool2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool2d(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, bool ceil_mode=False, bool count_include_pad=True, int? divisor_override=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">avg_pool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool2d_backward.grad_input(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] stride, int[2] padding, bool ceil_mode, bool count_include_pad, int? divisor_override, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">avg_pool2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool2d_backward.grad_input(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] stride, int[2] padding, bool ceil_mode, bool count_include_pad, int? divisor_override, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">avg_pool2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool2d_backward(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] stride, int[2] padding, bool ceil_mode, bool count_include_pad, int? divisor_override) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">avg_pool2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool3d.out(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, bool ceil_mode=False, bool count_include_pad=True, int? divisor_override=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">avg_pool3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool3d.out(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, bool ceil_mode=False, bool count_include_pad=True, int? divisor_override=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">avg_pool3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool3d(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, bool ceil_mode=False, bool count_include_pad=True, int? divisor_override=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">avg_pool3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool3d_backward.grad_input(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] stride, int[3] padding, bool ceil_mode, bool count_include_pad, int? divisor_override, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">avg_pool3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool3d_backward.grad_input(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] stride, int[3] padding, bool ceil_mode, bool count_include_pad, int? divisor_override, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">avg_pool3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::avg_pool3d_backward(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] stride, int[3] padding, bool ceil_mode, bool count_include_pad, int? divisor_override) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">avg_pool3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">divisor_override</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">avg_pool3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">,</span> <span class="n">divisor_override</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool2d.output(Tensor self, int[2] kernel_size, int[2] output_size, Tensor random_samples, *, Tensor(a!) output, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">fractional_max_pool2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">random_samples</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool2d_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">random_samples</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool2d.output(Tensor self, int[2] kernel_size, int[2] output_size, Tensor random_samples, *, Tensor(a!) output, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">fractional_max_pool2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">random_samples</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool2d_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">random_samples</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool2d(Tensor self, int[2] kernel_size, int[2] output_size, Tensor random_samples) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">fractional_max_pool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">random_samples</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">random_samples</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool2d_backward.grad_input(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] output_size, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fractional_max_pool2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool2d_backward.grad_input(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] output_size, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fractional_max_pool2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool2d_backward(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] output_size, Tensor indices) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fractional_max_pool2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool3d.output(Tensor self, int[3] kernel_size, int[3] output_size, Tensor random_samples, *, Tensor(a!) output, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">fractional_max_pool3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">random_samples</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool3d_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">random_samples</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool3d.output(Tensor self, int[3] kernel_size, int[3] output_size, Tensor random_samples, *, Tensor(a!) output, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">fractional_max_pool3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">random_samples</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool3d_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">random_samples</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool3d(Tensor self, int[3] kernel_size, int[3] output_size, Tensor random_samples) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">fractional_max_pool3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">random_samples</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">random_samples</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool3d_backward.grad_input(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] output_size, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fractional_max_pool3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool3d_backward.grad_input(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] output_size, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fractional_max_pool3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fractional_max_pool3d_backward(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] output_size, Tensor indices) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fractional_max_pool3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fractional_max_pool3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool2d_with_indices.out(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False, *, Tensor(a!) out, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">max_pool2d_with_indices_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool2d_with_indices_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool2d_with_indices.out(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False, *, Tensor(a!) out, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">max_pool2d_with_indices_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool2d_with_indices_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool2d_with_indices(Tensor self, int[2] kernel_size, int[2] stride=[], int[2] padding=0, int[2] dilation=1, bool ceil_mode=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">max_pool2d_with_indices</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool2d_with_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool2d_with_indices_backward.grad_input(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] stride, int[2] padding, int[2] dilation, bool ceil_mode, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_pool2d_with_indices_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool2d_with_indices_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool2d_with_indices_backward.grad_input(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] stride, int[2] padding, int[2] dilation, bool ceil_mode, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_pool2d_with_indices_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool2d_with_indices_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool2d_with_indices_backward(Tensor grad_output, Tensor self, int[2] kernel_size, int[2] stride, int[2] padding, int[2] dilation, bool ceil_mode, Tensor indices) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max_pool2d_with_indices_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool2d_with_indices_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool3d_with_indices.out(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, int[3] dilation=1, bool ceil_mode=False, *, Tensor(a!) out, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">max_pool3d_with_indices_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool3d_with_indices_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool3d_with_indices.out(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, int[3] dilation=1, bool ceil_mode=False, *, Tensor(a!) out, Tensor(b!) indices) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">max_pool3d_with_indices_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool3d_with_indices_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool3d_with_indices(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, int[3] dilation=1, bool ceil_mode=False) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">max_pool3d_with_indices</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool3d_with_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool3d_with_indices_backward.grad_input(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] stride, int[3] padding, int[3] dilation, bool ceil_mode, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_pool3d_with_indices_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool3d_with_indices_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool3d_with_indices_backward.grad_input(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] stride, int[3] padding, int[3] dilation, bool ceil_mode, Tensor indices, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_pool3d_with_indices_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool3d_with_indices_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_pool3d_with_indices_backward(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] stride, int[3] padding, int[3] dilation, bool ceil_mode, Tensor indices) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max_pool3d_with_indices_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_pool3d_with_indices_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool2d.out(Tensor self, Tensor indices, int[2] output_size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_unpool2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool2d.out(Tensor self, Tensor indices, int[2] output_size, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_unpool2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool2d(Tensor self, Tensor indices, int[2] output_size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max_unpool2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor indices, int[2] output_size, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_unpool2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor indices, int[2] output_size, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_unpool2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool2d_backward(Tensor grad_output, Tensor self, Tensor indices, int[2] output_size) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max_unpool2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool3d.out(Tensor self, Tensor indices, int[3] output_size, int[3] stride, int[3] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_unpool3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool3d.out(Tensor self, Tensor indices, int[3] output_size, int[3] stride, int[3] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_unpool3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool3d(Tensor self, Tensor indices, int[3] output_size, int[3] stride, int[3] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max_unpool3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool3d_backward.grad_input(Tensor grad_output, Tensor self, Tensor indices, int[3] output_size, int[3] stride, int[3] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_unpool3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool3d_backward.grad_input(Tensor grad_output, Tensor self, Tensor indices, int[3] output_size, int[3] stride, int[3] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">max_unpool3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max_unpool3d_backward(Tensor grad_output, Tensor self, Tensor indices, int[3] output_size, int[3] stride, int[3] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">max_unpool3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_unpool3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad1d.out(Tensor self, int[2] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad1d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad1d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad1d.out(Tensor self, int[2] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad1d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad1d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad1d(Tensor self, int[2] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">reflection_pad1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad1d_backward.grad_input(Tensor grad_output, Tensor self, int[2] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad1d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad1d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad1d_backward.grad_input(Tensor grad_output, Tensor self, int[2] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad1d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad1d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad1d_backward(Tensor grad_output, Tensor self, int[2] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">reflection_pad1d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad1d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad2d.out(Tensor self, int[4] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad2d.out(Tensor self, int[4] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad2d(Tensor self, int[4] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">reflection_pad2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad2d_backward.grad_input(Tensor grad_output, Tensor self, int[4] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad2d_backward.grad_input(Tensor grad_output, Tensor self, int[4] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad2d_backward(Tensor grad_output, Tensor self, int[4] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">reflection_pad2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad3d.out(Tensor self, int[6] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad3d.out(Tensor self, int[6] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad3d(Tensor self, int[6] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">reflection_pad3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad3d_backward.grad_input(Tensor grad_output, Tensor self, int[6] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad3d_backward.grad_input(Tensor grad_output, Tensor self, int[6] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">reflection_pad3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reflection_pad3d_backward(Tensor grad_output, Tensor self, int[6] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">reflection_pad3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reflection_pad3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad1d.out(Tensor self, int[2] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad1d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad1d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad1d.out(Tensor self, int[2] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad1d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad1d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad1d(Tensor self, int[2] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">replication_pad1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad1d_backward.grad_input(Tensor grad_output, Tensor self, int[2] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad1d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad1d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad1d_backward.grad_input(Tensor grad_output, Tensor self, int[2] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad1d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad1d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad1d_backward(Tensor grad_output, Tensor self, int[2] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">replication_pad1d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad1d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad2d.out(Tensor self, int[4] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad2d.out(Tensor self, int[4] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad2d(Tensor self, int[4] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">replication_pad2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad2d_backward.grad_input(Tensor grad_output, Tensor self, int[4] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad2d_backward.grad_input(Tensor grad_output, Tensor self, int[4] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad2d_backward(Tensor grad_output, Tensor self, int[4] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">replication_pad2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad3d.out(Tensor self, int[6] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad3d.out(Tensor self, int[6] padding, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad3d(Tensor self, int[6] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">replication_pad3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad3d_backward.grad_input(Tensor grad_output, Tensor self, int[6] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad3d_backward.grad_input(Tensor grad_output, Tensor self, int[6] padding, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">replication_pad3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::replication_pad3d_backward(Tensor grad_output, Tensor self, int[6] padding) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">replication_pad3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">replication_pad3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_linear1d.vec(Tensor input, int[]? output_size, bool align_corners, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_linear1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_linear1d_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_linear1d_backward.vec(Tensor grad_output, int[]? output_size, int[] input_size, bool align_corners, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_linear1d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_linear1d_backward_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bilinear2d.vec(Tensor input, int[]? output_size, bool align_corners, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_bilinear2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bilinear2d_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bilinear2d_backward.vec(Tensor grad_output, int[]? output_size, int[] input_size, bool align_corners, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_bilinear2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bilinear2d_backward_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_trilinear3d.vec(Tensor input, int[]? output_size, bool align_corners, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_trilinear3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_trilinear3d_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_trilinear3d_backward.vec(Tensor grad_output, int[]? output_size, int[] input_size, bool align_corners, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_trilinear3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_trilinear3d_backward_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bicubic2d.vec(Tensor input, int[]? output_size, bool align_corners, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_bicubic2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bicubic2d_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bicubic2d_backward.vec(Tensor grad_output, int[]? output_size, int[] input_size, bool align_corners, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_bicubic2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bicubic2d_backward_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest1d.vec(Tensor input, int[]? output_size, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest1d_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest1d_backward.vec(Tensor grad_output, int[]? output_size, int[] input_size, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest1d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest1d_backward_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest2d.vec(Tensor input, int[]? output_size, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest2d_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest2d_backward.vec(Tensor grad_output, int[]? output_size, int[] input_size, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest2d_backward_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest3d.vec(Tensor input, int[]? output_size, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest3d_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest3d_backward.vec(Tensor grad_output, int[]? output_size, int[] input_size, float[]? scale_factors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">scale_factors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest3d_backward_vec</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scale_factors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_linear1d.out(Tensor self, int[1] output_size, bool align_corners, float? scales=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_linear1d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_linear1d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_linear1d.out(Tensor self, int[1] output_size, bool align_corners, float? scales=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_linear1d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_linear1d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_linear1d(Tensor self, int[1] output_size, bool align_corners, float? scales=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_linear1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_linear1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_linear1d_backward.grad_input(Tensor grad_output, int[1] output_size, int[3] input_size, bool align_corners, float? scales=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_linear1d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_linear1d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_linear1d_backward.grad_input(Tensor grad_output, int[1] output_size, int[3] input_size, bool align_corners, float? scales=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_linear1d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_linear1d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_linear1d_backward(Tensor grad_output, int[1] output_size, int[3] input_size, bool align_corners, float? scales=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_linear1d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_linear1d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bilinear2d.out(Tensor self, int[2] output_size, bool align_corners, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_bilinear2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bilinear2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bilinear2d.out(Tensor self, int[2] output_size, bool align_corners, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_bilinear2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bilinear2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bilinear2d(Tensor self, int[2] output_size, bool align_corners, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_bilinear2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bilinear2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bilinear2d_backward.grad_input(Tensor grad_output, int[2] output_size, int[4] input_size, bool align_corners, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_bilinear2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bilinear2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bilinear2d_backward.grad_input(Tensor grad_output, int[2] output_size, int[4] input_size, bool align_corners, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_bilinear2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bilinear2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bilinear2d_backward(Tensor grad_output, int[2] output_size, int[4] input_size, bool align_corners, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_bilinear2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bilinear2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bicubic2d.out(Tensor self, int[2] output_size, bool align_corners, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_bicubic2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bicubic2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bicubic2d.out(Tensor self, int[2] output_size, bool align_corners, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_bicubic2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bicubic2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bicubic2d(Tensor self, int[2] output_size, bool align_corners, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_bicubic2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bicubic2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bicubic2d_backward.grad_input(Tensor grad_output, int[2] output_size, int[4] input_size, bool align_corners, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_bicubic2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bicubic2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bicubic2d_backward.grad_input(Tensor grad_output, int[2] output_size, int[4] input_size, bool align_corners, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_bicubic2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bicubic2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_bicubic2d_backward(Tensor grad_output, int[2] output_size, int[4] input_size, bool align_corners, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_bicubic2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_bicubic2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_trilinear3d.out(Tensor self, int[3] output_size, bool align_corners, float? scales_d=None, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_trilinear3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_trilinear3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_trilinear3d.out(Tensor self, int[3] output_size, bool align_corners, float? scales_d=None, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_trilinear3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_trilinear3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_trilinear3d(Tensor self, int[3] output_size, bool align_corners, float? scales_d=None, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_trilinear3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_trilinear3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_trilinear3d_backward.grad_input(Tensor grad_output, int[3] output_size, int[5] input_size, bool align_corners, float? scales_d=None, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_trilinear3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_trilinear3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_trilinear3d_backward.grad_input(Tensor grad_output, int[3] output_size, int[5] input_size, bool align_corners, float? scales_d=None, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_trilinear3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_trilinear3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_trilinear3d_backward(Tensor grad_output, int[3] output_size, int[5] input_size, bool align_corners, float? scales_d=None, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_trilinear3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_trilinear3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest1d.out(Tensor self, int[1] output_size, float? scales=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest1d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest1d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest1d.out(Tensor self, int[1] output_size, float? scales=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest1d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest1d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest1d(Tensor self, int[1] output_size, float? scales=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest1d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest1d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scales</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest1d_backward.grad_input(Tensor grad_output, int[1] output_size, int[3] input_size, float? scales=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest1d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest1d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest1d_backward.grad_input(Tensor grad_output, int[1] output_size, int[3] input_size, float? scales=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest1d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest1d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest1d_backward(Tensor grad_output, int[1] output_size, int[3] input_size, float? scales=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest1d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest1d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scales</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest2d.out(Tensor self, int[2] output_size, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest2d.out(Tensor self, int[2] output_size, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest2d(Tensor self, int[2] output_size, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest2d_backward.grad_input(Tensor grad_output, int[2] output_size, int[4] input_size, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest2d_backward.grad_input(Tensor grad_output, int[2] output_size, int[4] input_size, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest2d_backward(Tensor grad_output, int[2] output_size, int[4] input_size, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest3d.out(Tensor self, int[3] output_size, float? scales_d=None, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest3d.out(Tensor self, int[3] output_size, float? scales_d=None, float? scales_h=None, float? scales_w=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest3d(Tensor self, int[3] output_size, float? scales_d=None, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest3d_backward.grad_input(Tensor grad_output, int[3] output_size, int[5] input_size, float? scales_d=None, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest3d_backward.grad_input(Tensor grad_output, int[3] output_size, int[5] input_size, float? scales_d=None, float? scales_h=None, float? scales_w=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">upsample_nearest3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::upsample_nearest3d_backward(Tensor grad_output, int[3] output_size, int[5] input_size, float? scales_d=None, float? scales_h=None, float? scales_w=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">upsample_nearest3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_d</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_h</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">scales_w</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">upsample_nearest3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">scales_d</span><span class="p">,</span> <span class="n">scales_h</span><span class="p">,</span> <span class="n">scales_w</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sigmoid_backward.grad_input(Tensor grad_output, Tensor output, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sigmoid_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sigmoid_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sigmoid_backward.grad_input(Tensor grad_output, Tensor output, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sigmoid_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sigmoid_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sigmoid_backward(Tensor grad_output, Tensor output) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">sigmoid_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sigmoid_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logit_backward.grad_input(Tensor grad_output, Tensor self, float? eps=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logit_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logit_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logit_backward.grad_input(Tensor grad_output, Tensor self, float? eps=None, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logit_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logit_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logit_backward(Tensor grad_output, Tensor self, float? eps=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">logit_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logit_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tanh_backward.grad_input(Tensor grad_output, Tensor output, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tanh_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tanh_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tanh_backward.grad_input(Tensor grad_output, Tensor output, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tanh_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tanh_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tanh_backward(Tensor grad_output, Tensor output) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">tanh_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tanh_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">output</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose2d.out(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] output_padding=0, int[2] dilation=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">slow_conv_transpose2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose2d.out(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] output_padding=0, int[2] dilation=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">slow_conv_transpose2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] output_padding=0, int[2] dilation=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">slow_conv_transpose2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose2d_backward.grad_output(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, int[2] output_padding, int[2] dilation, Tensor columns, Tensor ones, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">slow_conv_transpose2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">columns</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ones</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose2d_backward_grad_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">ones</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose2d_backward.grad_output(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, int[2] output_padding, int[2] dilation, Tensor columns, Tensor ones, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">slow_conv_transpose2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">columns</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ones</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose2d_backward_grad_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">ones</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose2d_backward.output_mask(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, int[2] output_padding, int[2] dilation, Tensor columns, Tensor ones, bool[3] output_mask) -&gt; (Tensor grad_input, Tensor grad_weight, Tensor grad_bias)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">slow_conv_transpose2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">columns</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ones</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose2d_backward_output_mask</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">ones</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose3d.out(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias=None, int[3] stride=1, int[3] padding=0, int[3] output_padding=0, int[3] dilation=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">slow_conv_transpose3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose3d.out(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias=None, int[3] stride=1, int[3] padding=0, int[3] output_padding=0, int[3] dilation=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">slow_conv_transpose3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose3d(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias=None, int[3] stride=1, int[3] padding=0, int[3] output_padding=0, int[3] dilation=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">slow_conv_transpose3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose3d_backward.grad_output(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, int[3] output_padding, int[3] dilation, Tensor finput, Tensor fgrad_input, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">slow_conv_transpose3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose3d_backward_grad_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose3d_backward.grad_output(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, int[3] output_padding, int[3] dilation, Tensor finput, Tensor fgrad_input, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">slow_conv_transpose3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose3d_backward_grad_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_transpose3d_backward.output_mask(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, int[3] output_padding, int[3] dilation, Tensor finput, Tensor fgrad_input, bool[3] output_mask) -&gt; (Tensor grad_input, Tensor grad_weight, Tensor grad_bias)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">slow_conv_transpose3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_transpose3d_backward_output_mask</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv2d.out(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">thnn_conv2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv2d.out(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">thnn_conv2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">thnn_conv2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv2d_forward.output(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding, *, Tensor(a!) output, Tensor(b!) finput, Tensor(c!) fgrad_input) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">thnn_conv2d_forward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv2d_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv2d_forward.output(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding, *, Tensor(a!) output, Tensor(b!) finput, Tensor(c!) fgrad_input) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">thnn_conv2d_forward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv2d_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding) -&gt; (Tensor output, Tensor finput, Tensor fgrad_input)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">thnn_conv2d_forward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv2d_forward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, Tensor finput, Tensor fgrad_input, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">thnn_conv2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, Tensor finput, Tensor fgrad_input, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">thnn_conv2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv2d_backward.output_mask(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, Tensor finput, Tensor fgrad_input, bool[3] output_mask) -&gt; (Tensor grad_input, Tensor grad_weight, Tensor grad_bias)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">thnn_conv2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv2d_backward_output_mask</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv_depthwise2d.out(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] dilation=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">thnn_conv_depthwise2d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv_depthwise2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv_depthwise2d.out(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] dilation=1, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">thnn_conv_depthwise2d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv_depthwise2d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv_depthwise2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] dilation=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">thnn_conv_depthwise2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv_depthwise2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv_depthwise2d_forward.out(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding, int[2] dilation, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">thnn_conv_depthwise2d_forward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv_depthwise2d_forward_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv_depthwise2d_forward.out(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding, int[2] dilation, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">thnn_conv_depthwise2d_forward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv_depthwise2d_forward_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv_depthwise2d_forward(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias, int[2] stride, int[2] padding, int[2] dilation) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">thnn_conv_depthwise2d_forward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv_depthwise2d_forward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv_depthwise2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, int[2] dilation, *, Tensor(a!) grad_input, Tensor(b!) grad_weight) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">thnn_conv_depthwise2d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv_depthwise2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv_depthwise2d_backward.grad_input(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, int[2] dilation, *, Tensor(a!) grad_input, Tensor(b!) grad_weight) -&gt; (Tensor(a!), Tensor(b!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">thnn_conv_depthwise2d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv_depthwise2d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::thnn_conv_depthwise2d_backward.output_mask(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, int[2] dilation, bool[2] output_mask) -&gt; (Tensor grad_input, Tensor grad_weight)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">thnn_conv_depthwise2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">2</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">thnn_conv_depthwise2d_backward_output_mask</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv_depthwise3d(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias, int[3] stride, int[3] padding, int[3] dilation) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">conv_depthwise3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv_depthwise3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv_depthwise3d_backward.grad_input(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, int[3] dilation, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">conv_depthwise3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv_depthwise3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv_depthwise3d_backward.grad_input(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, int[3] dilation, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">conv_depthwise3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv_depthwise3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::conv_depthwise3d_backward.output_mask(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, int[3] dilation, bool[3] output_mask) -&gt; (Tensor grad_input, Tensor grad_weight, Tensor grad_bias)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">conv_depthwise3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conv_depthwise3d_backward_output_mask</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv3d.out(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias=None, int[3] stride=1, int[3] padding=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">slow_conv3d_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv3d.out(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias=None, int[3] stride=1, int[3] padding=0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">slow_conv3d_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv3d_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv3d(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias=None, int[3] stride=1, int[3] padding=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">slow_conv3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv3d_forward.output(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias, int[3] stride, int[3] padding, *, Tensor(a!) output, Tensor(b!) finput, Tensor(c!) fgrad_input) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">slow_conv3d_forward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv3d_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv3d_forward.output(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias, int[3] stride, int[3] padding, *, Tensor(a!) output, Tensor(b!) finput, Tensor(c!) fgrad_input) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">slow_conv3d_forward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv3d_forward_output</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv3d_forward(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias, int[3] stride, int[3] padding) -&gt; (Tensor output, Tensor finput, Tensor fgrad_input)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">slow_conv3d_forward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv3d_forward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv3d_backward.grad_input(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, Tensor finput, Tensor fgrad_input, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">slow_conv3d_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv3d_backward.grad_input(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, Tensor finput, Tensor fgrad_input, *, Tensor(a!) grad_input, Tensor(b!) grad_weight, Tensor(c!) grad_bias) -&gt; (Tensor(a!), Tensor(b!), Tensor(c!))</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">slow_conv3d_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_bias</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv3d_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_weight</span><span class="p">,</span> <span class="n">grad_bias</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv3d_backward.output_mask(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, Tensor finput, Tensor fgrad_input, bool[3] output_mask) -&gt; (Tensor grad_input, Tensor grad_weight, Tensor grad_bias)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">slow_conv3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">finput</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv3d_backward_output_mask</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">finput</span><span class="p">,</span> <span class="n">fgrad_input</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_dilated2d(Tensor self, Tensor weight, int[2] kernel_size, Tensor? bias=None, int[2] stride=1, int[2] padding=0, int[2] dilation=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">slow_conv_dilated2d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_dilated2d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_dilated2d_backward(Tensor grad_output, Tensor self, Tensor weight, int[2] kernel_size, int[2] stride, int[2] padding, int[2] dilation, bool[3] output_mask) -&gt; (Tensor grad_input, Tensor grad_weight, Tensor grad_bias)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">slow_conv_dilated2d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_dilated2d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_dilated3d(Tensor self, Tensor weight, int[3] kernel_size, Tensor? bias=None, int[3] stride=1, int[3] padding=0, int[3] dilation=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">slow_conv_dilated3d</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">bias</span><span class="o">=</span><span class="p">{},</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_dilated3d</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slow_conv_dilated3d_backward(Tensor grad_output, Tensor self, Tensor weight, int[3] kernel_size, int[3] stride, int[3] padding, int[3] dilation, bool[3] output_mask) -&gt; (Tensor grad_input, Tensor grad_weight, Tensor grad_bias)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">slow_conv_dilated3d_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">weight</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="mi">3</span><span class="o">&gt;</span> <span class="n">output_mask</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slow_conv_dilated3d_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::col2im.out(Tensor self, int[2] output_size, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col2im_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">col2im_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::col2im.out(Tensor self, int[2] output_size, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col2im_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">col2im_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::col2im(Tensor self, int[2] output_size, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">col2im</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">col2im</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::col2im_backward.grad_input(Tensor grad_output, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col2im_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">col2im_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::col2im_backward.grad_input(Tensor grad_output, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">col2im_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">col2im_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::col2im_backward(Tensor grad_output, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">col2im_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">col2im_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::column_stack(Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">column_stack</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">column_stack</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::column_stack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">column_stack_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">column_stack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::column_stack.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">column_stack_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">column_stack_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::im2col.out(Tensor self, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">im2col_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">im2col_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::im2col.out(Tensor self, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">im2col_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">im2col_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::im2col(Tensor self, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">im2col</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">im2col</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::im2col_backward.grad_input(Tensor grad_output, int[2] input_size, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">im2col_backward_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">im2col_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::im2col_backward.grad_input(Tensor grad_output, int[2] input_size, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride, *, Tensor(a!) grad_input) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">im2col_backward_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">im2col_backward_grad_input</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::im2col_backward(Tensor grad_output, int[2] input_size, int[2] kernel_size, int[2] dilation, int[2] padding, int[2] stride) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">im2col_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad_output</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">padding</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">im2col_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isfinite(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isfinite</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isfinite</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isinf(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isinf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isinf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isposinf(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isposinf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isposinf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isposinf.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isposinf_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isposinf_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isposinf.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isposinf_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isposinf_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isneginf(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">isneginf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isneginf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isneginf.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isneginf_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isneginf_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isneginf.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">isneginf_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isneginf_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_add_batch_dim(Tensor self, int batch_dim, int level) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_add_batch_dim</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">batch_dim</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">level</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_add_batch_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch_dim</span><span class="p">,</span> <span class="n">level</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_remove_batch_dim(Tensor self, int level, int batch_size, int out_dim) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_remove_batch_dim</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">level</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">batch_size</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">out_dim</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_remove_batch_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">level</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_entr(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_entr</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_entr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_entr.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_entr_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_entr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_entr.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_entr_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_entr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_ndtri(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_ndtri</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_ndtri</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_ndtri.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_ndtri_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_ndtri_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_ndtri.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_ndtri_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_ndtri_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_expm1(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_expm1</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_expm1</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_expm1.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_expm1_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_expm1_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_expm1.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_expm1_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_expm1_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_exp2(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_exp2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_exp2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_exp2.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_exp2_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_exp2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_exp2.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_exp2_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_exp2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_psi(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_psi</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_psi</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_psi.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_psi_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_psi_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_psi.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_psi_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_psi_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_digamma(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_digamma</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_digamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_digamma.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_digamma_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_digamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_digamma.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_digamma_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_digamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_gammaln(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_gammaln</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_gammaln</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_gammaln.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_gammaln_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_gammaln_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_gammaln.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_gammaln_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_gammaln_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erf(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_erf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erf.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_erf_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erf_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erf.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_erf_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erf_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erfc(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_erfc</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erfc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erfc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_erfc_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erfc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erfc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_erfc_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erfc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erfcx(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_erfcx</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erfcx</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erfcx.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_erfcx_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erfcx_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erfcx.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_erfcx_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erfcx_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erfinv(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_erfinv</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erfinv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erfinv.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_erfinv_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erfinv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_erfinv.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_erfinv_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_erfinv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_ndtr(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_ndtr</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_ndtr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_ndtr.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_ndtr_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_ndtr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_ndtr.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_ndtr_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_ndtr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlog1py(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_xlog1py</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlog1py</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlog1py.self_scalar(Scalar self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_xlog1py</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlog1py_self_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlog1py.other_scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_xlog1py</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlog1py_other_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlog1py.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlog1py_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlog1py_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlog1py.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlog1py_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlog1py_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlog1py.self_scalar_out(Scalar self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlog1py_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlog1py_self_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlog1py.self_scalar_out(Scalar self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlog1py_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlog1py_self_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlog1py.other_scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlog1py_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlog1py_other_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlog1py.other_scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlog1py_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlog1py_other_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlogy(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_xlogy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlogy</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlogy.self_scalar(Scalar self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_xlogy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlogy_self_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlogy.other_scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_xlogy</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlogy_other_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlogy.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlogy_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlogy_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlogy.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlogy_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlogy_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlogy.self_scalar_out(Scalar self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlogy_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlogy_self_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlogy.self_scalar_out(Scalar self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlogy_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlogy_self_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlogy.other_scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlogy_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlogy_other_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_xlogy.other_scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_xlogy_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_xlogy_other_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_zeta(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_zeta</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_zeta</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_zeta.self_scalar(Scalar self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_zeta</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_zeta_self_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_zeta.other_scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_zeta</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_zeta_other_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_zeta.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_zeta_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_zeta_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_zeta.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_zeta_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_zeta_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_zeta.self_scalar_out(Scalar self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_zeta_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_zeta_self_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_zeta.self_scalar_out(Scalar self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_zeta_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_zeta_self_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_zeta.other_scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_zeta_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_zeta_other_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_zeta.other_scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_zeta_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_zeta_other_scalar_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i0(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_i0</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i0</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i0.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_i0_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i0_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i0.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_i0_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i0_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i0e(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_i0e</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i0e</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i0e.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_i0e_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i0e_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i0e.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_i0e_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i0e_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i1(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_i1</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i1</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i1.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_i1_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i1_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i1.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_i1_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i1_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i1e(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_i1e</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i1e</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i1e.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_i1e_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i1e_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_i1e.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_i1e_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_i1e_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_logit(Tensor self, float? eps=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_logit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_logit</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_logit.out(Tensor self, float? eps=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_logit_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_logit_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_logit.out(Tensor self, float? eps=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_logit_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">eps</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_logit_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_polygamma(int n, Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_polygamma</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_polygamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_polygamma.out(int n, Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_polygamma_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_polygamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_polygamma.out(int n, Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_polygamma_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_polygamma_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_logsumexp(Tensor self, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_logsumexp</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_logsumexp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_logsumexp.out(Tensor self, int[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_logsumexp_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_logsumexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_logsumexp.out(Tensor self, int[1] dim, bool keepdim=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_logsumexp_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_logsumexp_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_expit(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_expit</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_expit</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_expit.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_expit_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_expit_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_expit.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_expit_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_expit_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_sinc(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_sinc</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_sinc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_sinc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_sinc_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_sinc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_sinc.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_sinc_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_sinc_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_round(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_round</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_round</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_round.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_round_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_round_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_round.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_round_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_round_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_log1p(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_log1p</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_log1p</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_log1p.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_log1p_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_log1p_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_log1p.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_log1p_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_log1p_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_log_softmax(Tensor self, int dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_log_softmax</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_log_softmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_multigammaln(Tensor self, int p) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">special_multigammaln</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_multigammaln</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_multigammaln.out(Tensor self, int p, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_multigammaln_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_multigammaln_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::special_multigammaln.out(Tensor self, int p, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">special_multigammaln_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">special_multigammaln_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fft(Tensor self, int? n=None, int dim=-1, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_fft</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_fft_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_fft_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifft(Tensor self, int? n=None, int dim=-1, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_ifft</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_ifft_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_ifft_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfft(Tensor self, int? n=None, int dim=-1, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_rfft</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_rfft_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_rfft_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_irfft(Tensor self, int? n=None, int dim=-1, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_irfft</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_irfft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_irfft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_irfft_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_irfft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_irfft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_irfft_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_irfft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_hfft(Tensor self, int? n=None, int dim=-1, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_hfft</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_hfft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_hfft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_hfft_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_hfft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_hfft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_hfft_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_hfft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ihfft(Tensor self, int? n=None, int dim=-1, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_ihfft</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ihfft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ihfft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_ihfft_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ihfft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ihfft.out(Tensor self, int? n=None, int dim=-1, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_ihfft_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ihfft_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fft2(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_fft2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fft2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fft2.out(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_fft2_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fft2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fft2.out(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_fft2_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fft2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifft2(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_ifft2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifft2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifft2.out(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_ifft2_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifft2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifft2.out(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_ifft2_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifft2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfft2(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_rfft2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfft2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfft2.out(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_rfft2_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfft2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfft2.out(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_rfft2_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfft2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_irfft2(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_irfft2</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_irfft2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_irfft2.out(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_irfft2_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_irfft2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_irfft2.out(Tensor self, int[1]? s=None, int[1] dim=[-2,-1], str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_irfft2_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_irfft2_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fftn(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_fftn</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fftn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fftn.out(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_fftn_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fftn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fftn.out(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_fftn_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fftn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifftn(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_ifftn</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifftn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifftn.out(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_ifftn_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifftn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifftn.out(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_ifftn_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifftn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfftn(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_rfftn</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfftn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfftn.out(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_rfftn_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfftn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfftn.out(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_rfftn_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfftn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_irfftn(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_irfftn</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_irfftn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_irfftn.out(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_irfftn_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_irfftn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_irfftn.out(Tensor self, int[1]? s=None, int[1]? dim=None, str? norm=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_irfftn_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">s</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">norm</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_irfftn_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fftfreq(int n, float d=1.0, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_fftfreq</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">double</span> <span class="n">d</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fftfreq</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fftfreq(int n, float d=1.0, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_fftfreq</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">double</span> <span class="n">d</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fftfreq</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fftfreq.out(int n, float d=1.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_fftfreq_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">double</span> <span class="n">d</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fftfreq_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fftfreq.out(int n, float d=1.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_fftfreq_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">double</span> <span class="n">d</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fftfreq_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfftfreq(int n, float d=1.0, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_rfftfreq</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">double</span> <span class="n">d</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span> <span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfftfreq</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span> <span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfftfreq(int n, float d=1.0, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_rfftfreq</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">double</span> <span class="n">d</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span> <span class="n">layout</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span> <span class="n">pin_memory</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfftfreq</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">layout</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfftfreq.out(int n, float d=1.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_rfftfreq_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">double</span> <span class="n">d</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfftfreq_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_rfftfreq.out(int n, float d=1.0, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">fft_rfftfreq_outf</span><span class="p">(</span><span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">double</span> <span class="n">d</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_rfftfreq_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_fftshift(Tensor self, int[1]? dim=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_fftshift</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_fftshift</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fft_ifftshift(Tensor self, int[1]? dim=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">fft_ifftshift</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fft_ifftshift</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cholesky_ex(Tensor self, *, bool check_errors=False) -&gt; (Tensor L, Tensor info)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">linalg_cholesky_ex</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">check_errors</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cholesky_ex</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">check_errors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cholesky_ex.L(Tensor self, *, bool check_errors=False, Tensor(a!) L, Tensor(b!) info) -&gt; (Tensor(a!) L, Tensor(b!) info)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_cholesky_ex_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">L</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">info</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">check_errors</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cholesky_ex_L</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">check_errors</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">info</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cholesky_ex.L(Tensor self, *, bool check_errors=False, Tensor(a!) L, Tensor(b!) info) -&gt; (Tensor(a!) L, Tensor(b!) info)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_cholesky_ex_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">check_errors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">L</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">info</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cholesky_ex_L</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">check_errors</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">info</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cholesky(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_cholesky</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cholesky</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cholesky.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_cholesky_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cholesky_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cholesky.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_cholesky_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cholesky_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_det(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_det</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_det</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_det.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_det_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_det_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_det.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_det_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_det_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::det(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">det</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">det</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_det_lu_based_helper(Tensor self) -&gt; (Tensor det, Tensor lu, Tensor pivs)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_det_lu_based_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_det_lu_based_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_det_lu_based_helper_backward_helper(Tensor det_grad, Tensor det, Tensor self, Tensor lu, Tensor pivs) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_det_lu_based_helper_backward_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">det_grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">det</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">lu</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">pivs</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_det_lu_based_helper_backward_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">det_grad</span><span class="p">,</span> <span class="n">det</span><span class="p">,</span> <span class="n">self</span><span class="p">,</span> <span class="n">lu</span><span class="p">,</span> <span class="n">pivs</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_lstsq(Tensor self, Tensor b, float? rcond=None, *, str? driver=None) -&gt; (Tensor solution, Tensor residuals, Tensor rank, Tensor singular_values)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">linalg_lstsq</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">rcond</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">driver</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_lstsq</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">driver</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_lstsq.out(Tensor self, Tensor b, float? rcond=None, *, str? driver=None, Tensor(a!) solution, Tensor(b!) residuals, Tensor(c!) rank, Tensor(d!) singular_values) -&gt; (Tensor(a!) solution, Tensor(b!) residuals, Tensor(c!) rank, Tensor(d!) singular_values)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_lstsq_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">solution</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rank</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">singular_values</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">rcond</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">driver</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_lstsq_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">driver</span><span class="p">,</span> <span class="n">solution</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">singular_values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_lstsq.out(Tensor self, Tensor b, float? rcond=None, *, str? driver=None, Tensor(a!) solution, Tensor(b!) residuals, Tensor(c!) rank, Tensor(d!) singular_values) -&gt; (Tensor(a!) solution, Tensor(b!) residuals, Tensor(c!) rank, Tensor(d!) singular_values)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_lstsq_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span> <span class="n">driver</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">solution</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rank</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">singular_values</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_lstsq_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">driver</span><span class="p">,</span> <span class="n">solution</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">singular_values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_slogdet(Tensor self) -&gt; (Tensor sign, Tensor logabsdet)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">linalg_slogdet</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_slogdet</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_slogdet.out(Tensor self, *, Tensor(a!) sign, Tensor(b!) logabsdet) -&gt; (Tensor(a!) sign, Tensor(b!) logabsdet)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_slogdet_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sign</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logabsdet</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_slogdet_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sign</span><span class="p">,</span> <span class="n">logabsdet</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_slogdet.out(Tensor self, *, Tensor(a!) sign, Tensor(b!) logabsdet) -&gt; (Tensor(a!) sign, Tensor(b!) logabsdet)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_slogdet_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">sign</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">logabsdet</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_slogdet_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sign</span><span class="p">,</span> <span class="n">logabsdet</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eig(Tensor self) -&gt; (Tensor eigenvalues, Tensor eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">linalg_eig</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eig</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eig.out(Tensor self, *, Tensor(a!) eigenvalues, Tensor(b!) eigenvectors) -&gt; (Tensor(a!) eigenvalues, Tensor(b!) eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_eig_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eigenvalues</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eigenvectors</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eig_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eig.out(Tensor self, *, Tensor(a!) eigenvalues, Tensor(b!) eigenvectors) -&gt; (Tensor(a!) eigenvalues, Tensor(b!) eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_eig_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eigenvalues</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eigenvectors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eig_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eigvals(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_eigvals</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eigvals</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eigvals.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_eigvals_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eigvals_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eigvals.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_eigvals_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eigvals_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eigh(Tensor self, str UPLO=&quot;L&quot;) -&gt; (Tensor eigenvalues, Tensor eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">linalg_eigh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">UPLO</span><span class="o">=</span><span class="s">&quot;L&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eigh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">UPLO</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eigh.eigvals(Tensor self, str UPLO=&quot;L&quot;, *, Tensor(a!) eigvals, Tensor(b!) eigvecs) -&gt; (Tensor(a!) eigenvalues, Tensor(b!) eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_eigh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eigvals</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eigvecs</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">UPLO</span><span class="o">=</span><span class="s">&quot;L&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eigh_eigvals</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">UPLO</span><span class="p">,</span> <span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eigh.eigvals(Tensor self, str UPLO=&quot;L&quot;, *, Tensor(a!) eigvals, Tensor(b!) eigvecs) -&gt; (Tensor(a!) eigenvalues, Tensor(b!) eigenvectors)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_eigh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">UPLO</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eigvals</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">eigvecs</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eigh_eigvals</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">UPLO</span><span class="p">,</span> <span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eigvalsh(Tensor self, str UPLO=&quot;L&quot;) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_eigvalsh</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">UPLO</span><span class="o">=</span><span class="s">&quot;L&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eigvalsh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">UPLO</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eigvalsh.out(Tensor self, str UPLO=&#39;L&#39;, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_eigvalsh_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">UPLO</span><span class="o">=</span><span class="s">&quot;L&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eigvalsh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">UPLO</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_eigvalsh.out(Tensor self, str UPLO=&#39;L&#39;, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_eigvalsh_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">UPLO</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_eigvalsh_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">UPLO</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_householder_product(Tensor input, Tensor tau) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_householder_product</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tau</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_householder_product</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tau</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_householder_product.out(Tensor input, Tensor tau, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_householder_product_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tau</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_householder_product_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_householder_product.out(Tensor input, Tensor tau, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_householder_product_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tau</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_householder_product_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_linalg_inv_out_helper_(Tensor(a!) self, Tensor(b!) infos_lu, Tensor(c!) infos_getri) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">_linalg_inv_out_helper_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">infos_lu</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">infos_getri</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_linalg_inv_out_helper_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">infos_lu</span><span class="p">,</span> <span class="n">infos_getri</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_inv_ex(Tensor self, *, bool check_errors=False) -&gt; (Tensor inverse, Tensor info)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">linalg_inv_ex</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">check_errors</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_inv_ex</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">check_errors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_inv_ex.inverse(Tensor self, *, bool check_errors=False, Tensor(a!) inverse, Tensor(b!) info) -&gt; (Tensor(a!) inverse, Tensor(b!) info)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_inv_ex_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">inverse</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">info</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">check_errors</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_inv_ex_inverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">check_errors</span><span class="p">,</span> <span class="n">inverse</span><span class="p">,</span> <span class="n">info</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_inv_ex.inverse(Tensor self, *, bool check_errors=False, Tensor(a!) inverse, Tensor(b!) info) -&gt; (Tensor(a!) inverse, Tensor(b!) info)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_inv_ex_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">check_errors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">inverse</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">info</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_inv_ex_inverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">check_errors</span><span class="p">,</span> <span class="n">inverse</span><span class="p">,</span> <span class="n">info</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_inv(Tensor self) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_inv</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_inv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_inv.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_inv_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_inv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_inv.out(Tensor self, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_inv_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_inv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::inner(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">inner</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">inner</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::inner.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">inner_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">inner_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::inner.out(Tensor self, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">inner_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">inner_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::outer(Tensor self, Tensor vec2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">outer</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">outer</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::outer.out(Tensor self, Tensor vec2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">outer_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">outer_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::outer.out(Tensor self, Tensor vec2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">outer_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">outer_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ger(Tensor self, Tensor vec2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">ger</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ger</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ger.out(Tensor self, Tensor vec2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ger_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ger_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ger.out(Tensor self, Tensor vec2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">ger_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ger_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_norm(Tensor self, Scalar? ord=None, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">ord</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_norm.ord_str(Tensor self, str ord, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">ord</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_norm_ord_str</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_norm.out(Tensor self, Scalar? ord=None, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">ord</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_norm.out(Tensor self, Scalar? ord=None, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">ord</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_norm.ord_str_out(Tensor self, str ord, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">ord</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_norm_ord_str_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_norm.ord_str_out(Tensor self, str ord, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">ord</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_norm_ord_str_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_vector_norm(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_vector_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_vector_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_vector_norm.out(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_vector_norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_vector_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_vector_norm.out(Tensor self, Scalar ord=2, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_vector_norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">ord</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_vector_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_norm(Tensor self, Scalar ord, int[] dim=[-2,-1], bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_matrix_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">ord</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_norm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_norm.out(Tensor self, Scalar ord, int[] dim=[-2,-1], bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">ord</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_norm.out(Tensor self, Scalar ord, int[] dim=[-2,-1], bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">ord</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_norm_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_norm.str_ord(Tensor self, str ord=&#39;fro&#39;, int[] dim=[-2,-1], bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_matrix_norm</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">ord</span><span class="o">=</span><span class="s">&quot;fro&quot;</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_norm_str_ord</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_norm.str_ord_out(Tensor self, str ord=&#39;fro&#39;, int[] dim=[-2,-1], bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_norm_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">ord</span><span class="o">=</span><span class="s">&quot;fro&quot;</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="o">=</span><span class="p">{</span><span class="mi">-2</span><span class="p">,</span><span class="mi">-1</span><span class="p">},</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_norm_str_ord_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_norm.str_ord_out(Tensor self, str ord=&#39;fro&#39;, int[] dim=[-2,-1], bool keepdim=False, *, ScalarType? dtype=None, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_norm_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">ord</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span> <span class="n">dim</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_norm_str_ord_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ord</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_svd.U(Tensor self, bool full_matrices=True, *, Tensor(a!) U, Tensor(b!) S, Tensor(c!) Vh) -&gt; (Tensor(a!) U, Tensor(b!) S, Tensor(c!) Vh)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_svd_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">U</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">S</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">Vh</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">full_matrices</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_svd_U</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">full_matrices</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_svd.U(Tensor self, bool full_matrices=True, *, Tensor(a!) U, Tensor(b!) S, Tensor(c!) Vh) -&gt; (Tensor(a!) U, Tensor(b!) S, Tensor(c!) Vh)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_svd_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">full_matrices</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">U</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">S</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">Vh</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_svd_U</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">full_matrices</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vh</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_svd(Tensor self, bool full_matrices=True) -&gt; (Tensor U, Tensor S, Tensor Vh)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">linalg_svd</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">full_matrices</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_svd</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">full_matrices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_svdvals(Tensor input) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_svdvals</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_svdvals</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_svdvals.out(Tensor input, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_svdvals_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_svdvals_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_svdvals.out(Tensor input, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_svdvals_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_svdvals_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cond(Tensor self, Scalar? p=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_cond</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cond</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cond.out(Tensor self, Scalar? p=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_cond_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cond_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cond.out(Tensor self, Scalar? p=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_cond_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cond_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cond.p_str(Tensor self, str p) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_cond</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cond_p_str</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cond.p_str_out(Tensor self, str p, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_cond_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cond_p_str_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_cond.p_str_out(Tensor self, str p, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_cond_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">p</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_cond_p_str_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_pinv(Tensor self, float rcond=1e-15, bool hermitian=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_pinv</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">rcond</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_pinv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_pinv.rcond_tensor(Tensor self, Tensor rcond, bool hermitian=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_pinv</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rcond</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_pinv_rcond_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_pinv.out(Tensor self, float rcond=1e-15, bool hermitian=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_pinv_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">rcond</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_pinv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_pinv.out(Tensor self, float rcond=1e-15, bool hermitian=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_pinv_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">double</span> <span class="n">rcond</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_pinv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_pinv.out_rcond_tensor(Tensor self, Tensor rcond, bool hermitian=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_pinv_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rcond</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_pinv_out_rcond_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_pinv.out_rcond_tensor(Tensor self, Tensor rcond, bool hermitian=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_pinv_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">rcond</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_pinv_out_rcond_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">rcond</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_solve(Tensor input, Tensor other) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_solve</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_solve</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_solve.out(Tensor input, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_solve_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_solve_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_solve.out(Tensor input, Tensor other, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_solve_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_solve_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_tensorinv(Tensor self, int ind=2) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_tensorinv</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ind</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_tensorinv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_tensorinv.out(Tensor self, int ind=2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_tensorinv_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ind</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_tensorinv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_tensorinv.out(Tensor self, int ind=2, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_tensorinv_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">ind</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_tensorinv_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_tensorsolve(Tensor self, Tensor other, int[]? dims=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_tensorsolve</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dims</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_tensorsolve</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_tensorsolve.out(Tensor self, Tensor other, int[]? dims=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_tensorsolve_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dims</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_tensorsolve_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_tensorsolve.out(Tensor self, Tensor other, int[]? dims=None, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_tensorsolve_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">dims</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_tensorsolve_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_qr(Tensor self, str mode=&#39;reduced&#39;) -&gt; (Tensor Q, Tensor R)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">linalg_qr</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">mode</span><span class="o">=</span><span class="s">&quot;reduced&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_qr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_qr.out(Tensor self, str mode=&#39;reduced&#39;, *, Tensor(a!) Q, Tensor(b!) R) -&gt; (Tensor(a!) Q, Tensor(b!) R)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_qr_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">Q</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">R</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">mode</span><span class="o">=</span><span class="s">&quot;reduced&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_qr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">R</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_qr.out(Tensor self, str mode=&#39;reduced&#39;, *, Tensor(a!) Q, Tensor(b!) R) -&gt; (Tensor(a!) Q, Tensor(b!) R)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;&gt;</span> <span class="n">linalg_qr_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">mode</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">Q</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">R</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_qr_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">R</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_linalg_qr_helper(Tensor self, str mode) -&gt; (Tensor, Tensor)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">_linalg_qr_helper</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">mode</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_linalg_qr_helper</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_power(Tensor self, int n) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_matrix_power</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_power</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_power.out(Tensor self, int n, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_power_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_power_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_power.out(Tensor self, int n, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_power_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">n</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_power_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_rank(Tensor self, float? tol=None, bool hermitian=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_matrix_rank</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">tol</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_rank</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_rank.out(Tensor self, float? tol=None, bool hermitian=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_rank_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">tol</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_rank_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_rank.out(Tensor self, float? tol=None, bool hermitian=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_rank_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">tol</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_rank_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_rank.tol_tensor(Tensor input, Tensor tol, bool hermitian=False) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_matrix_rank</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tol</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_rank_tol_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_rank.out_tol_tensor(Tensor input, Tensor tol, bool hermitian=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_rank_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tol</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_rank_out_tol_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_matrix_rank.out_tol_tensor(Tensor input, Tensor tol, bool hermitian=False, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_matrix_rank_outf</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">input</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">tol</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_matrix_rank_out_tol_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">hermitian</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_multi_dot(Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">linalg_multi_dot</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_multi_dot</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_multi_dot.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_multi_dot_out</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_multi_dot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::linalg_multi_dot.out(Tensor[] tensors, *, Tensor(a!) out) -&gt; Tensor(a!)</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">linalg_multi_dot_outf</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">linalg_multi_dot_out</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_test_serialization_subcmul(Tensor self, Tensor other, Scalar alpha=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_test_serialization_subcmul</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">other</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Scalar</span> <span class="o">&amp;</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_test_serialization_subcmul</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_test_optional_intlist(Tensor values, int[]? addends) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_test_optional_intlist</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">addends</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_test_optional_intlist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">addends</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_test_optional_filled_intlist(Tensor values, int[2]? addends) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_test_optional_filled_intlist</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">addends</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_test_optional_filled_intlist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">addends</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_test_optional_floatlist(Tensor values, float[]? addends) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_test_optional_floatlist</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span> <span class="n">addends</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_test_optional_floatlist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">addends</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_test_string_default(Tensor dummy, str a=&quot;\&quot;&#39;\\&quot;, str b=&#39;&quot;\&#39;\\&#39;) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_test_string_default</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dummy</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">a</span><span class="o">=</span><span class="s">&quot;</span><span class="se">\&quot;</span><span class="s">&#39;</span><span class="se">\\</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">b</span><span class="o">=</span><span class="s">&quot;</span><span class="se">\&quot;</span><span class="s">&#39;</span><span class="se">\\</span><span class="s">&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_test_string_default</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_test_ambiguous_defaults.a(Tensor dummy, int a=1, int b=1) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_test_ambiguous_defaults</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dummy</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_test_ambiguous_defaults_a</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_test_ambiguous_defaults.b(Tensor dummy, int a=2, str b=&quot;2&quot;) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_test_ambiguous_defaults</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">dummy</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">a</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">b</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_test_ambiguous_defaults_b</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::segment_reduce(Tensor data, str reduce, *, Tensor? lengths=None, Tensor? indices=None, int axis=0, bool unsafe=False, Scalar? initial=None) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">segment_reduce</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">data</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">reduce</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">lengths</span><span class="o">=</span><span class="p">{},</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">indices</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">unsafe</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">initial</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">segment_reduce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">unsafe</span><span class="p">,</span> <span class="n">initial</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_segment_reduce_backward(Tensor grad, Tensor output, Tensor data, str reduce, *, Tensor? lengths=None, int axis=0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">_segment_reduce_backward</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">grad</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">output</span><span class="p">,</span> <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">data</span><span class="p">,</span> <span class="n">c10</span><span class="o">::</span><span class="n">string_view</span> <span class="n">reduce</span><span class="p">,</span> <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span> <span class="n">lengths</span><span class="o">=</span><span class="p">{},</span> <span class="kt">int64_t</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_segment_reduce_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">axis</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pad_sequence(Tensor[] sequences, bool batch_first=False, float padding_value=0.0) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">pad_sequence</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">sequences</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">batch_first</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span> <span class="kt">double</span> <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pad_sequence</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flatten_dense_tensors(Tensor[] tensors) -&gt; Tensor</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">flatten_dense_tensors</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flatten_dense_tensors</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unflatten_dense_tensors(Tensor flat, Tensor[] tensors) -&gt; Tensor[]</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">unflatten_dense_tensors</span><span class="p">(</span><span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="o">&amp;</span> <span class="n">flat</span><span class="p">,</span> <span class="n">at</span><span class="o">::</span><span class="n">TensorList</span> <span class="n">tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unflatten_dense_tensors</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">flat</span><span class="p">,</span> <span class="n">tensors</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// Special C++ only overloads for std()-like functions (See gh-40287)</span>
<span class="c1">// These are needed because int -&gt; bool conversion takes precedence over int -&gt; IntArrayRef</span>
<span class="c1">// So, for example std(0) would select the std(unbiased=False) overload</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">Tensor</span> <span class="n">var</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">var</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">IntArrayRef</span><span class="p">{</span><span class="n">dim</span><span class="p">});</span>
<span class="p">}</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">var_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">var_mean</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">IntArrayRef</span><span class="p">{</span><span class="n">dim</span><span class="p">});</span>
<span class="p">}</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">Tensor</span> <span class="n">std</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">std</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">IntArrayRef</span><span class="p">{</span><span class="n">dim</span><span class="p">});</span>
<span class="p">}</span>
<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">std_mean</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">self</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">at</span><span class="o">::</span><span class="n">std_mean</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">IntArrayRef</span><span class="p">{</span><span class="n">dim</span><span class="p">});</span>
<span class="p">}</span>

<span class="k">namespace</span> <span class="nn">detail</span> <span class="p">{</span>

<span class="n">TORCH_API</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="n">noopDelete</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span> <span class="p">{}</span>

<span class="p">}</span> <span class="c1">// namespace detail</span>

<span class="k">class</span> <span class="nc">TORCH_API</span> <span class="n">TensorMaker</span> <span class="p">{</span>
  <span class="k">friend</span> <span class="n">TensorMaker</span> <span class="nf">for_blob</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="n">IntArrayRef</span> <span class="n">sizes</span><span class="p">)</span> <span class="k">noexcept</span><span class="p">;</span>

 <span class="k">public</span><span class="o">:</span>
  <span class="k">using</span> <span class="n">ContextDeleter</span> <span class="o">=</span> <span class="n">DeleterFnPtr</span><span class="p">;</span>

  <span class="n">TensorMaker</span><span class="o">&amp;</span> <span class="nf">strides</span><span class="p">(</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">value</span><span class="p">)</span> <span class="k">noexcept</span> <span class="p">{</span>
    <span class="n">strides_</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>

    <span class="k">return</span> <span class="o">*</span><span class="k">this</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">TensorMaker</span><span class="o">&amp;</span> <span class="nf">deleter</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&gt;</span> <span class="n">value</span><span class="p">)</span> <span class="k">noexcept</span> <span class="p">{</span>
    <span class="n">deleter_</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">value</span><span class="p">);</span>

    <span class="k">return</span> <span class="o">*</span><span class="k">this</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">TensorMaker</span><span class="o">&amp;</span> <span class="nf">context</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">value</span><span class="p">,</span> <span class="n">ContextDeleter</span> <span class="n">deleter</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">)</span> <span class="k">noexcept</span> <span class="p">{</span>
    <span class="n">ctx_</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">,</span> <span class="n">ContextDeleter</span><span class="o">&gt;</span><span class="p">{</span>
        <span class="n">value</span><span class="p">,</span> <span class="n">deleter</span> <span class="o">!=</span> <span class="k">nullptr</span> <span class="o">?</span> <span class="nl">deleter</span> <span class="p">:</span> <span class="n">detail</span><span class="o">::</span><span class="n">noopDelete</span><span class="p">};</span>

    <span class="k">return</span> <span class="o">*</span><span class="k">this</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">TensorMaker</span><span class="o">&amp;</span> <span class="nf">target_device</span><span class="p">(</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">value</span><span class="p">)</span> <span class="k">noexcept</span> <span class="p">{</span>
    <span class="n">device_</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>

    <span class="k">return</span> <span class="o">*</span><span class="k">this</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">TensorMaker</span><span class="o">&amp;</span> <span class="nf">options</span><span class="p">(</span><span class="n">TensorOptions</span> <span class="n">value</span><span class="p">)</span> <span class="k">noexcept</span> <span class="p">{</span>
    <span class="n">opts_</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>

    <span class="k">return</span> <span class="o">*</span><span class="k">this</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">Tensor</span> <span class="nf">make_tensor</span><span class="p">();</span>

 <span class="k">private</span><span class="o">:</span>
  <span class="k">explicit</span> <span class="n">TensorMaker</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="n">IntArrayRef</span> <span class="n">sizes</span><span class="p">)</span> <span class="k">noexcept</span>
      <span class="o">:</span> <span class="n">data_</span><span class="p">{</span><span class="n">data</span><span class="p">},</span> <span class="n">sizes_</span><span class="p">{</span><span class="n">sizes</span><span class="p">}</span> <span class="p">{}</span>

  <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">computeStorageSize</span><span class="p">()</span> <span class="k">const</span> <span class="k">noexcept</span><span class="p">;</span>

  <span class="n">DataPtr</span> <span class="nf">makeDataPtrFromDeleter</span><span class="p">()</span> <span class="k">const</span><span class="p">;</span>

  <span class="n">DataPtr</span> <span class="nf">makeDataPtrFromContext</span><span class="p">()</span> <span class="k">noexcept</span><span class="p">;</span>

  <span class="n">IntArrayRef</span> <span class="nf">makeTempSizes</span><span class="p">()</span> <span class="k">const</span> <span class="k">noexcept</span><span class="p">;</span>

  <span class="kt">void</span><span class="o">*</span> <span class="n">data_</span><span class="p">;</span>
  <span class="n">IntArrayRef</span> <span class="n">sizes_</span><span class="p">;</span>
  <span class="n">optional</span><span class="o">&lt;</span><span class="n">IntArrayRef</span><span class="o">&gt;</span> <span class="n">strides_</span><span class="p">{};</span>
  <span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&gt;</span> <span class="n">deleter_</span><span class="p">{};</span>
  <span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">,</span> <span class="n">ContextDeleter</span><span class="o">&gt;</span> <span class="n">ctx_</span><span class="p">{</span><span class="k">nullptr</span><span class="p">,</span> <span class="n">detail</span><span class="o">::</span><span class="n">noopDelete</span><span class="p">};</span>
  <span class="n">optional</span><span class="o">&lt;</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">device_</span><span class="p">{};</span>
  <span class="n">TensorOptions</span> <span class="n">opts_</span><span class="p">{};</span>
<span class="p">};</span>

<span class="kr">inline</span> <span class="n">TensorMaker</span> <span class="nf">for_blob</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="n">IntArrayRef</span> <span class="n">sizes</span><span class="p">)</span> <span class="k">noexcept</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">TensorMaker</span><span class="p">{</span><span class="n">data</span><span class="p">,</span> <span class="n">sizes</span><span class="p">};</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="n">Tensor</span> <span class="nf">from_blob</span><span class="p">(</span>
    <span class="kt">void</span><span class="o">*</span> <span class="n">data</span><span class="p">,</span>
    <span class="n">IntArrayRef</span> <span class="n">sizes</span><span class="p">,</span>
    <span class="n">IntArrayRef</span> <span class="n">strides</span><span class="p">,</span>
    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&gt;&amp;</span> <span class="n">deleter</span><span class="p">,</span>
    <span class="k">const</span> <span class="n">TensorOptions</span><span class="o">&amp;</span> <span class="n">options</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">Device</span><span class="o">&gt;</span> <span class="n">target_device</span> <span class="o">=</span> <span class="n">c10</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">for_blob</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sizes</span><span class="p">)</span>
      <span class="p">.</span><span class="n">strides</span><span class="p">(</span><span class="n">strides</span><span class="p">)</span>
      <span class="p">.</span><span class="n">deleter</span><span class="p">(</span><span class="n">deleter</span><span class="p">)</span>
      <span class="p">.</span><span class="n">options</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>
      <span class="p">.</span><span class="n">target_device</span><span class="p">(</span><span class="n">target_device</span><span class="p">)</span>
      <span class="p">.</span><span class="n">make_tensor</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="n">Tensor</span> <span class="n">from_blob</span><span class="p">(</span>
    <span class="kt">void</span><span class="o">*</span> <span class="n">data</span><span class="p">,</span>
    <span class="n">IntArrayRef</span> <span class="n">sizes</span><span class="p">,</span>
    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&gt;&amp;</span> <span class="n">deleter</span><span class="p">,</span>
    <span class="k">const</span> <span class="n">TensorOptions</span><span class="o">&amp;</span> <span class="n">options</span> <span class="o">=</span> <span class="p">{})</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">for_blob</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sizes</span><span class="p">)</span>
      <span class="p">.</span><span class="n">deleter</span><span class="p">(</span><span class="n">deleter</span><span class="p">)</span>
      <span class="p">.</span><span class="n">options</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>
      <span class="p">.</span><span class="n">make_tensor</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="n">Tensor</span> <span class="n">from_blob</span><span class="p">(</span>
    <span class="kt">void</span><span class="o">*</span> <span class="n">data</span><span class="p">,</span>
    <span class="n">IntArrayRef</span> <span class="n">sizes</span><span class="p">,</span>
    <span class="n">IntArrayRef</span> <span class="n">strides</span><span class="p">,</span>
    <span class="k">const</span> <span class="n">TensorOptions</span><span class="o">&amp;</span> <span class="n">options</span> <span class="o">=</span> <span class="p">{})</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">for_blob</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sizes</span><span class="p">)</span>
      <span class="p">.</span><span class="n">strides</span><span class="p">(</span><span class="n">strides</span><span class="p">)</span>
      <span class="p">.</span><span class="n">options</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>
      <span class="p">.</span><span class="n">make_tensor</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="n">Tensor</span> <span class="n">from_blob</span><span class="p">(</span>
    <span class="kt">void</span><span class="o">*</span> <span class="n">data</span><span class="p">,</span>
    <span class="n">IntArrayRef</span> <span class="n">sizes</span><span class="p">,</span>
    <span class="k">const</span> <span class="n">TensorOptions</span><span class="o">&amp;</span> <span class="n">options</span> <span class="o">=</span> <span class="p">{})</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">for_blob</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sizes</span><span class="p">).</span><span class="n">options</span><span class="p">(</span><span class="n">options</span><span class="p">).</span><span class="n">make_tensor</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">numel</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">numel</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">size</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="kt">int64_t</span> <span class="n">stride</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">,</span> <span class="kt">int64_t</span> <span class="n">dim</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">stride</span><span class="p">(</span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_complex</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">is_complex</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_floating_point</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">is_floating_point</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_signed</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">is_signed</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_inference</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">is_inference</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_conj</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">is_conj</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="n">Tensor</span> <span class="n">conj</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">conj</span><span class="p">();</span>
<span class="p">}</span>

<span class="kr">inline</span> <span class="kt">bool</span> <span class="n">is_neg</span><span class="p">(</span><span class="k">const</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">.</span><span class="n">is_neg</span><span class="p">();</span>
<span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Program Listing for File Functions.h</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/language_data.js"></script>
         <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
         <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>